{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2\n",
      "accuracy    = 0.664\n",
      "0.664\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "from rocket_functions import generate_kernels, apply_kernels\n",
    "\n",
    "dataset = \"Computers\"\n",
    "\n",
    "training_data = np.loadtxt(f\"../Univariate_arff/{dataset}/{dataset}_TRAIN.txt\")\n",
    "Y_training, X_training = training_data[:, 0].astype(int), training_data[:, 1:]\n",
    "\n",
    "# generate \"dummy\" kernels -> compiles *generate_kernels(...)*\n",
    "_ = generate_kernels(100, 10)\n",
    "\n",
    "# apply \"dummy\" kernels to \"dummy\" data -> compiles *apply_kernels(...)*\n",
    "_ = apply_kernels(np.zeros_like(training_data)[:, 1:], _)\n",
    "\n",
    "kernels = generate_kernels(X_training.shape[1], 100)\n",
    "\n",
    "X_training_transform = apply_kernels(X_training, kernels)\n",
    "\n",
    "classifier = RidgeClassifierCV(alphas = np.logspace(-3, 3, 10))\n",
    "classifier.fit(X_training_transform, Y_training)\n",
    "\n",
    "print(end = \"\") # suppress print output of classifier.fit(...)\n",
    "\n",
    "test_data = np.loadtxt(f\"../Univariate_arff/{dataset}/{dataset}_TEST.txt\")\n",
    "Y_test, X_test = test_data[:, 0].astype(int), test_data[:, 1:]\n",
    "\n",
    "X_test_transform = apply_kernels(X_test, kernels)\n",
    "\n",
    "predictions = classifier.predict(X_test_transform)\n",
    "\n",
    "print(f\"predictions = {', '.join(predictions.astype(str))}\")\n",
    "print(f\"accuracy    = {(predictions == Y_test).mean()}\") \n",
    "print(classifier.score(X_test_transform, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mio Codice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predizioni nel test set: [1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 2 1 1 2 2 1 1 2\n",
      " 2 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 2 1 2 2 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 2 1 1 1 2 2 2 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1\n",
      " 2 1 2 1 1 1 1 1 2 1 1 2 1 1 2 2 2 1 1 1 2 2 2 2 1 1 1 1 2 2 2 2 1 2 1 2 1\n",
      " 2 1 1 1 2 2 2 1 2 1 1 1 1 2 2 1 1 1 1 1 2 1 1 1 2 1 2 1 2 2 1 1 1 2 1 2 1\n",
      " 2 2 2 2 2 1 1 1 2 2 1 1 2 2 1 2 1 1 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 1 2 1\n",
      " 1 2 2 2 2 2 2 2 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2]\n",
      "Metriche di valutazione:\n",
      " {'Accuracy': 0.684, 'Precision': 0.692, 'Recall': 0.684, 'F1': 0.681, 'MCC': 0.376, 'AUC_PR': 0.36, 'AUC_ROC': 0.748}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from numba import njit, prange\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, average_precision_score, roc_auc_score\n",
    "from pyod.utils.data import precision_n_scores\n",
    "from scipy.special import softmax\n",
    "\n",
    "@njit(\"Tuple((float64[:],int32[:],float64[:],int32[:],int32[:]))(int64,int64)\")\n",
    "def generate_kernels(input_length, num_kernels):\n",
    "\n",
    "    candidate_lengths = np.array((7, 9, 11), dtype = np.int32)\n",
    "    lengths = np.random.choice(candidate_lengths, num_kernels)\n",
    "\n",
    "    weights = np.zeros(lengths.sum(), dtype = np.float64)\n",
    "    biases = np.zeros(num_kernels, dtype = np.float64)\n",
    "    dilations = np.zeros(num_kernels, dtype = np.int32)\n",
    "    paddings = np.zeros(num_kernels, dtype = np.int32)\n",
    "\n",
    "    a1 = 0\n",
    "\n",
    "    for i in range(num_kernels):\n",
    "\n",
    "        _length = lengths[i]\n",
    "\n",
    "        _weights = np.random.normal(0, 1, _length)\n",
    "\n",
    "        b1 = a1 + _length\n",
    "        weights[a1:b1] = _weights - _weights.mean()\n",
    "\n",
    "        biases[i] = np.random.uniform(-1, 1)\n",
    "\n",
    "        dilation = 2 ** np.random.uniform(0, np.log2((input_length - 1) / (_length - 1)))\n",
    "        dilation = np.int32(dilation)\n",
    "        dilations[i] = dilation\n",
    "\n",
    "        padding = ((_length - 1) * dilation) // 2 if np.random.randint(2) == 1 else 0\n",
    "        paddings[i] = padding\n",
    "\n",
    "        a1 = b1\n",
    "\n",
    "    return weights, lengths, biases, dilations, paddings\n",
    "\n",
    "@njit(fastmath = True)\n",
    "def apply_kernel(X, weights, length, bias, dilation, padding):\n",
    "\n",
    "    input_length = len(X)\n",
    "\n",
    "    output_length = (input_length + (2 * padding)) - ((length - 1) * dilation)\n",
    "\n",
    "    _ppv = 0\n",
    "    _max = np.NINF\n",
    "\n",
    "    end = (input_length + padding) - ((length - 1) * dilation)\n",
    "\n",
    "    for i in range(-padding, end):\n",
    "\n",
    "        _sum = bias\n",
    "\n",
    "        index = i\n",
    "\n",
    "        for j in range(length):\n",
    "\n",
    "            if index > -1 and index < input_length:\n",
    "\n",
    "                _sum = _sum + weights[j] * X[index]\n",
    "\n",
    "            index = index + dilation\n",
    "\n",
    "        if _sum > _max:\n",
    "            _max = _sum\n",
    "\n",
    "        if _sum > 0:\n",
    "            _ppv += 1\n",
    "\n",
    "    return _ppv / output_length, _max\n",
    "\n",
    "@njit(\"float64[:,:](float64[:,:],Tuple((float64[::1],int32[:],float64[:],int32[:],int32[:])))\", parallel = True, fastmath = True)\n",
    "def apply_kernels(X, kernels):\n",
    "\n",
    "    weights, lengths, biases, dilations, paddings = kernels\n",
    "\n",
    "    num_examples, _ = X.shape\n",
    "    num_kernels = len(lengths)\n",
    "\n",
    "    _X = np.zeros((num_examples, num_kernels * 2), dtype = np.float64) # 2 features per kernel\n",
    "\n",
    "    for i in prange(num_examples):\n",
    "\n",
    "        a1 = 0 # for weights\n",
    "        a2 = 0 # for features\n",
    "\n",
    "        for j in range(num_kernels):\n",
    "\n",
    "            b1 = a1 + lengths[j]\n",
    "            b2 = a2 + 2\n",
    "\n",
    "            _X[i, a2:b2] = \\\n",
    "            apply_kernel(X[i], weights[a1:b1], lengths[j], biases[j], dilations[j], paddings[j])\n",
    "\n",
    "            a1 = b1\n",
    "            a2 = b2\n",
    "\n",
    "    return _X\n",
    "\n",
    "    res = {\n",
    "        \"Accuracy\": round(accuracy_score(y_test, y_pred), digits),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average='weighted').round(digits),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average='weighted').round(digits),\n",
    "        \"F1\": f1_score(y_test, y_pred, average='weighted').round(digits),\n",
    "        \"MCC\": round(matthews_corrcoef(y_test, y_pred), ndigits=digits)\n",
    "    }\n",
    "    if y_proba is not None:\n",
    "        res[\"AUC_ROC\"] = roc_auc_score(y_test, y_proba, multi_class='ovr', average='weighted').round(digits)\n",
    "    return res\n",
    "\n",
    "def evaluate_metrics(y_test, y_pred, y_proba=None, digits=3):\n",
    "    res = {\"Accuracy\": round(accuracy_score(y_test, y_pred), digits),\n",
    "           \"Precision\": precision_score(y_test, y_pred, average='weighted').round(digits),\n",
    "            \"Recall\": recall_score(y_test, y_pred, average='weighted').round(digits),\n",
    "            \"F1\": f1_score(y_test, y_pred, average='weighted').round(digits),\n",
    "           \"MCC\": round(matthews_corrcoef(y_test, y_pred), ndigits=digits)}\n",
    "    if y_proba is not None:\n",
    "        res[\"AUC_PR\"] = average_precision_score(y_test, y_proba).round(digits)\n",
    "        res[\"AUC_ROC\"] = roc_auc_score(y_test, y_proba, multi_class='ovr', average='weighted').round(digits)\n",
    "    return res\n",
    "\n",
    "# Genera kernel convoluzionali casuali\n",
    "input_length = X_training.shape[1]\n",
    "num_kernels = 1000\n",
    "kernels = generate_kernels(input_length, num_kernels)\n",
    "\n",
    "# Applica i kernel alle serie temporali\n",
    "features_train = apply_kernels(X_training, kernels)\n",
    "features_test = apply_kernels(X_test, kernels)\n",
    "\n",
    "\n",
    "# Addestramento del modello supervisionato\n",
    "model = RidgeClassifierCV(alphas = np.logspace(-3, 3, 10))\n",
    "model.fit(features_train, Y_training)\n",
    "\n",
    "# Predizione delle anomalie nei dati di test\n",
    "y_pred = model.predict(features_test)\n",
    "if  len(np.unique(Y_test)) > 2:\n",
    "    y_proba = softmax(model.decision_function(features_test), axis=1)\n",
    "else:\n",
    "    y_proba = softmax(model.decision_function(features_test), axis=0)\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "print(\"Predizioni nel test set:\", y_pred)\n",
    "\n",
    "# Eseguiamo la valutazione delle metriche\n",
    "metrics = evaluate_metrics(Y_test, y_pred, y_proba)\n",
    "print(\"Metriche di valutazione:\\n\", metrics)\n",
    "# {'Accuracy': 0.977, 'Precision': 0.972, 'Recall': 0.92, 'F1': 0.945, 'MCC': 0.932, 'AUC_PR': 0.962, 'AUC_ROC': 0.984, 'PREC_N_SCORES': 0.929}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
