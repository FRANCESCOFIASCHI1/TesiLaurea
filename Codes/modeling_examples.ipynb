{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e613346-c162-4bf8-908d-8e6a5cff0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef, average_precision_score\n",
    "from pyod.utils.data import precision_n_scores\n",
    "from pyod.models.iforest import IForest\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Per l'uso della memoria degli algoritmi\n",
    "from memory_profiler import memory_usage\n",
    "# Per la metrica sul tempo di Addestramento e Inferenza\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba180484-282d-4605-990e-bf354cf53bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(y_test, y_pred, y_proba=None, digits=3):\n",
    "    res = {\"Accuracy\": round(accuracy_score(y_test, y_pred), digits),\n",
    "           \"Precision\": precision_score(y_test, y_pred).round(digits),\n",
    "           \"Recall\": recall_score(y_test, y_pred).round(digits),\n",
    "           \"F1\": f1_score(y_test, y_pred).round(digits),\n",
    "           \"MCC\": round(matthews_corrcoef(y_test, y_pred), ndigits=digits)}\n",
    "    if y_proba is not None:\n",
    "        res[\"AUC_PR\"] = average_precision_score(y_test, y_proba).round(digits)\n",
    "        res[\"AUC_ROC\"] = roc_auc_score(y_test, y_proba).round(digits)\n",
    "        res[\"PREC_N_SCORES\"] = precision_n_scores(y_test, y_proba).round(digits)\n",
    "    return res\n",
    "\n",
    "\n",
    "def set_seed_numpy(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc90bc09-5125-4641-bf52-cd0d4cc7a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"mean\", \"var\", \"std\", \"len\", \"duration\", \"len_weighted\", \"gaps_squared\", \"n_peaks\",\n",
    "    \"smooth10_n_peaks\", \"smooth20_n_peaks\", \"var_div_duration\", \"var_div_len\",\n",
    "    \"diff_peaks\", \"diff2_peaks\", \"diff_var\", \"diff2_var\", \"kurtosis\", \"skew\",\n",
    "]\n",
    "SEED = 2137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fffebd2-36a4-4c5f-82e0-3b9e4f6c3ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (584, 15)\n",
      "Test set: (147, 15)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/dataset.csv\", index_col=\"segment\")\n",
    "\n",
    "X_train, y_train = df.loc[df.train==1, features], df.loc[df.train==1, \"anomaly\"]\n",
    "X_test, y_test = df.loc[df.train==0, features], df.loc[df.train==0, \"anomaly\"]\n",
    "X_train_nominal = df.loc[(df.anomaly==0)&(df.train==1), features]\n",
    "\n",
    "prep = StandardScaler()\n",
    "X_train_nominal2 = prep.fit_transform(X_train_nominal)\n",
    "X_train2 = prep.transform(X_train)\n",
    "X_test2 = prep.transform(X_test)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Dataset NASA -> SOlar Orbiter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "featuresNASA = [\n",
    "    \"Radial Distance from Sun(AU)\", \n",
    "    \"Electronic Box Temperature(DegC)\",\n",
    "    \"Out Board Sensor Temperature(DegC)\",\n",
    "    \"In Board Sensor Temperature(DegC)\",\n",
    "    \"Search Coil Magnetometers Temperature(DegC)\",\n",
    "    \"Solar Array Angle(Deg)\",\n",
    "    \"High Gain Antenna azimuth(Deg)\",\n",
    "    \"High Gain Antenna Elevation(Deg)\",\n",
    "    \"IBS_R\",\n",
    "    \"IBS_T\",\n",
    "    \"IBS_N\",\n",
    "    \"IBS_time\",\n",
    "    \"OBS_R\",\n",
    "    \"OBS_T\",\n",
    "    \"OBS_N\"\n",
    "]\n",
    "\n",
    "dNASA = pd.read_csv(\"data/Solar_Orbiter.csv\", index_col=\"Date\")\n",
    "\n",
    "# Filtraggio delle colonne specificate\n",
    "X = dNASA[featuresNASA]\n",
    "\n",
    "# Rimozione delle righe con valori mancanti (opzionale)\n",
    "X_cleaned = X.dropna()\n",
    "\n",
    "# Divisione dei dati in training e test set\n",
    "X_trainNASA, X_testNASA = train_test_split(X, test_size=0.2, random_state=42)\n",
    "# Output dei risultati\n",
    "print(\"Train set:\", X_trainNASA.shape)\n",
    "print(\"Test set:\", X_testNASA.shape)\n",
    "\n",
    "X_trainNASA = X_trainNASA.fillna(X_trainNASA.mean())\n",
    "X_testNASA = X_testNASA.fillna(X_trainNASA.mean())\n",
    "\n",
    "prep.fit(X_trainNASA)  # Calcolo delle statistiche (media, deviazione standard)\n",
    "X_trainNASA2 = prep.transform(X_trainNASA)\n",
    "X_testNASA2 = prep.transform(X_testNASA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5cb2f65-dba5-431f-a7c1-dc4db5d1fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed_numpy(SEED) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938333f9",
   "metadata": {},
   "source": [
    "# Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "396d74e0-6e0c-40c2-beaf-ea856b6a22d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(random_state=2137) \n",
      " {'Accuracy': 0.934, 'Precision': 0.89, 'Recall': 0.788, 'F1': 0.836, 'MCC': 0.797, 'AUC_PR': 0.923, 'AUC_ROC': 0.962, 'PREC_N_SCORES': 0.841}\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(random_state=SEED)\n",
    "model.fit(X_train2, y_train)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e8e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=50, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=2137, ...) \n",
      " {'Accuracy': 0.957, 'Precision': 0.959, 'Recall': 0.832, 'F1': 0.891, 'MCC': 0.867, 'AUC_PR': 0.961, 'AUC_ROC': 0.986, 'PREC_N_SCORES': 0.876}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "y_train_np = y_train\n",
    "\n",
    "model = xgb.XGBClassifier (\n",
    "    n_estimators=50,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    random_state=SEED\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "# Previsioni e probabilità di previsione\n",
    "y_predicted = model.predict(X_test)\n",
    "y_predicted_score = model.predict_proba(X_test)[:, 1]  # Probabilità per la classe positiva\n",
    "# Questa è la probabilità che la classificazione sia corretta\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa6aa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method DataIter._next_wrapper of <xgboost.data.SingleBatchInternalIter object at 0x00000200C0ED3C80>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 591, in _next_wrapper\n",
      "    @require_keyword_args(True)\n",
      "     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 707, in throw_if\n",
      "    @wraps(func)\n",
      "     ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\functools.py\", line 56, in update_wrapper\n",
      "    setattr(wrapper, attr, value)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "y_train_np = y_train\n",
    "\n",
    "model = xgb.XGBClassifier (\n",
    "    n_estimators=50,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.1,\n",
    "    random_state=SEED\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "# Previsioni e probabilità di previsione\n",
    "y_predicted = model.predict(X_test_scaled)\n",
    "y_predicted_score = model.predict_proba(X_test_scaled)[:, 1]  # Probabilità per la classe positiva\n",
    "# Questa è la probabilità che la classificazione sia corretta\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f258319c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.928, 'Precision': 0.921, 'Recall': 0.726, 'F1': 0.812, 'MCC': 0.777, 'AUC_PR': 0.949, 'AUC_ROC': 0.976, 'PREC_N_SCORES': 0.867}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Inizializza e addestra il modello\n",
    "model = LinearSVC()\n",
    "model.fit(X_train2, y_train)\n",
    "\n",
    "# Predizione\n",
    "y_test_scores = model.decision_function(X_test2)\n",
    "# Previsioni e probabilità di previsione\n",
    "y_predicted = model.predict(X_test2)\n",
    "\n",
    "# Questa è la probabilità che la classificazione sia corretta\n",
    "print(evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90807a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.924, 'Precision': 0.92, 'Recall': 0.708, 'F1': 0.8, 'MCC': 0.764, 'AUC_PR': 0.949, 'AUC_ROC': 0.976, 'PREC_N_SCORES': 0.867}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Inizializza e addestra il modello\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train2, y_train)\n",
    "\n",
    "# Predizione\n",
    "y_test_scores = model.decision_function(X_test2)\n",
    "# Previsioni e probabilità di previsione\n",
    "y_predicted = model.predict(X_test2)\n",
    "\n",
    "# Questa è la probabilità che la classificazione sia corretta\n",
    "print(evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5f6a6",
   "metadata": {},
   "source": [
    "## Unsupervised Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b5d242",
   "metadata": {},
   "source": [
    "MO_GAAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d742e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 60\n",
      "Epoch 2 of 60\n",
      "Epoch 3 of 60\n",
      "Epoch 4 of 60\n",
      "Epoch 5 of 60\n",
      "Epoch 6 of 60\n",
      "Epoch 7 of 60\n",
      "Epoch 8 of 60\n",
      "Epoch 9 of 60\n",
      "Epoch 10 of 60\n",
      "Epoch 11 of 60\n",
      "Epoch 12 of 60\n",
      "Epoch 13 of 60\n",
      "Epoch 14 of 60\n",
      "Epoch 15 of 60\n",
      "Epoch 16 of 60\n",
      "Epoch 17 of 60\n",
      "Epoch 18 of 60\n",
      "Epoch 19 of 60\n",
      "Epoch 20 of 60\n",
      "Epoch 21 of 60\n",
      "Epoch 22 of 60\n",
      "Epoch 23 of 60\n",
      "Epoch 24 of 60\n",
      "Epoch 25 of 60\n",
      "Epoch 26 of 60\n",
      "Epoch 27 of 60\n",
      "Epoch 28 of 60\n",
      "Epoch 29 of 60\n",
      "Epoch 30 of 60\n",
      "Epoch 31 of 60\n",
      "Epoch 32 of 60\n",
      "Epoch 33 of 60\n",
      "Epoch 34 of 60\n",
      "Epoch 35 of 60\n",
      "Epoch 36 of 60\n",
      "Epoch 37 of 60\n",
      "Epoch 38 of 60\n",
      "Epoch 39 of 60\n",
      "Epoch 40 of 60\n",
      "Epoch 41 of 60\n",
      "Epoch 42 of 60\n",
      "Epoch 43 of 60\n",
      "Epoch 44 of 60\n",
      "Epoch 45 of 60\n",
      "Epoch 46 of 60\n",
      "Epoch 47 of 60\n",
      "Epoch 48 of 60\n",
      "Epoch 49 of 60\n",
      "Epoch 50 of 60\n",
      "Epoch 51 of 60\n",
      "Epoch 52 of 60\n",
      "Epoch 53 of 60\n",
      "Epoch 54 of 60\n",
      "Epoch 55 of 60\n",
      "Epoch 56 of 60\n",
      "Epoch 57 of 60\n",
      "Epoch 58 of 60\n",
      "Epoch 59 of 60\n",
      "Epoch 60 of 60\n",
      "MO_GAAL(contamination=0.1, k=10, lr_d=0.01, lr_g=0.0001, momentum=0.9,\n",
      "    stop_epochs=20) \n",
      " {'Accuracy': 0.892, 'Precision': 0.912, 'Recall': 0.549, 'F1': 0.685, 'MCC': 0.654, 'AUC_PR': 0.699, 'AUC_ROC': 0.759, 'PREC_N_SCORES': 0.602}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.mo_gaal import MO_GAAL\n",
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = 'True'\n",
    "\n",
    "model = MO_GAAL()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))\n",
    " # {'Accuracy': 0.896, 'Precision': 0.939, 'Recall': 0.549, 'F1': 0.693, 'MCC': 0.669, 'AUC_PR': 0.771, 'AUC_ROC': 0.849, 'PREC_N_SCORES': 0.699}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5629a030",
   "metadata": {},
   "source": [
    "ANO-GAAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c80cf4",
   "metadata": {},
   "source": [
    "Non funzionante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5e4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train iter: 1\n",
      "Train iter: 2\n",
      "Train iter: 3\n",
      "Train iter: 4\n",
      "Train iter: 5\n",
      "Train iter: 6\n",
      "Train iter: 7\n",
      "Train iter: 8\n",
      "Train iter: 9\n",
      "Train iter: 10\n",
      "Train iter: 11\n",
      "Train iter: 12\n",
      "Train iter: 13\n",
      "Train iter: 14\n",
      "Train iter: 15\n",
      "Train iter: 16\n",
      "Train iter: 17\n",
      "Train iter: 18\n",
      "Train iter: 19\n",
      "Train iter: 20\n",
      "Train iter: 21\n",
      "Train iter: 22\n",
      "Train iter: 23\n",
      "Train iter: 24\n",
      "Train iter: 25\n",
      "Train iter: 26\n",
      "Train iter: 27\n",
      "Train iter: 28\n",
      "Train iter: 29\n",
      "Train iter: 30\n",
      "Train iter: 31\n",
      "Train iter: 32\n",
      "Train iter: 33\n",
      "Train iter: 34\n",
      "Train iter: 35\n",
      "Train iter: 36\n",
      "Train iter: 37\n",
      "Train iter: 38\n",
      "Train iter: 39\n",
      "Train iter: 40\n",
      "Train iter: 41\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m AnoGAN(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# per stampare più cose\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m y_predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test2)\n\u001b[0;32m     12\u001b[0m y_predicted_score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecision_function(X_test2)\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\anogan.py:327\u001b[0m, in \u001b[0;36mAnoGAN.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    324\u001b[0m loss_D\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    325\u001b[0m optimizer_d\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 327\u001b[0m fake_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m loss_G \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCELoss()(fake_output,\n\u001b[0;32m    329\u001b[0m                       torch\u001b[38;5;241m.\u001b[39mones_like(fake_output))\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    331\u001b[0m optimizer_g\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\anogan.py:87\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1426\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"True\"\n",
    "\n",
    "# Ora importa PyOD e usa AnoGAN come prima\n",
    "from pyod.models.anogan import AnoGAN\n",
    "import tensorflow as tf\n",
    "\n",
    "model = AnoGAN(verbose=1) # per stampare più cose\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34682324",
   "metadata": {},
   "source": [
    "SO_GAAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af6ef79",
   "metadata": {},
   "source": [
    "Non funzionante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3d631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensione X_train: (1594, 18)\n",
      "Dimensione y_train: (1594,)\n",
      "Dimensione X_test: (529, 18)\n",
      "Dimensione y_test: (529,)\n",
      "Epoch 1 of 60\n",
      "Epoch 2 of 60\n",
      "Epoch 3 of 60\n",
      "Epoch 4 of 60\n",
      "Epoch 5 of 60\n",
      "Epoch 6 of 60\n",
      "Epoch 7 of 60\n",
      "Epoch 8 of 60\n",
      "Epoch 9 of 60\n",
      "Epoch 10 of 60\n",
      "Epoch 11 of 60\n",
      "Epoch 12 of 60\n",
      "Epoch 13 of 60\n",
      "Epoch 14 of 60\n",
      "Epoch 15 of 60\n",
      "Epoch 16 of 60\n",
      "Epoch 17 of 60\n",
      "Epoch 18 of 60\n",
      "Epoch 19 of 60\n",
      "Epoch 20 of 60\n",
      "Epoch 21 of 60\n",
      "Epoch 22 of 60\n",
      "Epoch 23 of 60\n",
      "Epoch 24 of 60\n",
      "Epoch 25 of 60\n",
      "Epoch 26 of 60\n",
      "Epoch 27 of 60\n",
      "Epoch 28 of 60\n",
      "Epoch 29 of 60\n",
      "Epoch 30 of 60\n",
      "Epoch 31 of 60\n",
      "Epoch 32 of 60\n",
      "Epoch 33 of 60\n",
      "Epoch 34 of 60\n",
      "Epoch 35 of 60\n",
      "Epoch 36 of 60\n",
      "Epoch 37 of 60\n",
      "Epoch 38 of 60\n",
      "Epoch 39 of 60\n",
      "Epoch 40 of 60\n",
      "Epoch 41 of 60\n",
      "Epoch 42 of 60\n",
      "Epoch 43 of 60\n",
      "Epoch 44 of 60\n",
      "Epoch 45 of 60\n",
      "Epoch 46 of 60\n",
      "Epoch 47 of 60\n",
      "Epoch 48 of 60\n",
      "Epoch 49 of 60\n",
      "Epoch 50 of 60\n",
      "Epoch 51 of 60\n",
      "Epoch 52 of 60\n",
      "Epoch 53 of 60\n",
      "Epoch 54 of 60\n",
      "Epoch 55 of 60\n",
      "Epoch 56 of 60\n",
      "Epoch 57 of 60\n",
      "Epoch 58 of 60\n",
      "Epoch 59 of 60\n",
      "Epoch 60 of 60\n",
      "SO_GAAL(contamination=0.1, lr_d=0.01, lr_g=0.0001, momentum=0.9,\n",
      "    stop_epochs=20) \n",
      " {'Accuracy': 0.89, 'Precision': 0.937, 'Recall': 0.522, 'F1': 0.67, 'MCC': 0.649, 'AUC_PR': 0.858, 'AUC_ROC': 0.919, 'PREC_N_SCORES': 0.761}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.so_gaal import SO_GAAL\n",
    "\n",
    "# Verifica le dimensioni dei dati generati\n",
    "print(\"Dimensione X_train:\", X_train.shape)\n",
    "print(\"Dimensione y_train:\", y_train.shape)\n",
    "print(\"Dimensione X_test:\", X_test.shape)\n",
    "print(\"Dimensione y_test:\", y_test.shape)\n",
    "\n",
    "model = SO_GAAL()\n",
    "model.fit(X_train2[:len(X_train2) // 500 * 500])\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "# Valutazione del modello\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fb4017",
   "metadata": {},
   "source": [
    "RF+ICCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b046e91",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Inizializza e addestra il modello\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Previsioni e probabilità di previsione\u001b[39;00m\n\u001b[0;32m      8\u001b[0m y_predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Inizializza e addestra il modello\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Previsioni e probabilità di previsione\n",
    "y_predicted = model.predict(X_test)\n",
    "# Predizione\n",
    "y_test_scores = model.predict_proba(X_test)\n",
    "\n",
    "# Questa è la probabilità che la classificazione sia corretta\n",
    "print(evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae849e",
   "metadata": {},
   "source": [
    "Linear+L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 0.902, 'Precision': 0.969, 'Recall': 0.558, 'F1': 0.708, 'MCC': 0.69, 'AUC_PR': 0.889, 'AUC_ROC': 0.95, 'PREC_N_SCORES': 0.814}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "# Inizializza e addestra il modello Ridge Classifier (Linear + L2)\n",
    "model = RidgeClassifier(alpha=1.0)  # 'alpha' è il parametro di regolarizzazione L2\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predizione delle etichette di classe\n",
    "y_predicted = model.predict(X_test)\n",
    "\n",
    "# Ottieni le probabilità della classe positiva per AUC (si utilizza decision_function per ottenere punteggi di decisione)\n",
    "y_test_scores = model.decision_function(X_test)\n",
    "\n",
    "# Calcola e stampa le metriche\n",
    "metrics = evaluate_metrics(y_test, y_predicted, y_test_scores)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21ed48a",
   "metadata": {},
   "source": [
    "Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a69cca-f485-4810-b146-d00d216c01cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IForest(behaviour='old', bootstrap=False, contamination=0.2, max_features=1.0,\n",
      "    max_samples='auto', n_estimators=100, n_jobs=1, random_state=2137,\n",
      "    verbose=0) \n",
      " {'Accuracy': 0.701, 'Precision': 0.297, 'Recall': 0.292, 'F1': 0.295, 'MCC': 0.105, 'AUC_PR': 0.347, 'AUC_ROC': 0.635, 'PREC_N_SCORES': 0.301}\n"
     ]
    }
   ],
   "source": [
    "model = IForest(random_state=SEED, contamination=.2)\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7f31c8",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3608e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN(algorithm='auto', contamination=0.1, leaf_size=30, method='largest',\n",
      "  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "  radius=1.0) \n",
      " {'Accuracy': 0.849, 'Precision': 0.78, 'Recall': 0.407, 'F1': 0.535, 'MCC': 0.489, 'AUC_PR': 0.658, 'AUC_ROC': 0.852, 'PREC_N_SCORES': 0.593}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.knn import KNN\n",
    "\n",
    "model = KNN()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28682eb3",
   "metadata": {},
   "source": [
    "OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77bba73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCSVM(cache_size=200, coef0=0.0, contamination=0.1, degree=3, gamma='auto',\n",
      "   kernel='rbf', max_iter=-1, nu=0.5, shrinking=True, tol=0.001,\n",
      "   verbose=False) \n",
      " {'Accuracy': 0.837, 'Precision': 0.721, 'Recall': 0.389, 'F1': 0.506, 'MCC': 0.447, 'AUC_PR': 0.659, 'AUC_ROC': 0.788, 'PREC_N_SCORES': 0.655}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.ocsvm import OCSVM\n",
    "\n",
    "model = OCSVM()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f40d2e",
   "metadata": {},
   "source": [
    "ABOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e3a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABOD(contamination=0.1, method='fast', n_neighbors=5) \n",
      " {'Accuracy': 0.845, 'Precision': 0.782, 'Recall': 0.381, 'F1': 0.512, 'MCC': 0.472, 'AUC_PR': 0.644, 'AUC_ROC': 0.843, 'PREC_N_SCORES': 0.584}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.abod import ABOD\n",
    "\n",
    "model = ABOD()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03191a05",
   "metadata": {},
   "source": [
    "INNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19321ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INNE(contamination=0.1, max_samples='auto', n_estimators=200,\n",
      "   random_state=None) \n",
      " {'Accuracy': 0.832, 'Precision': 0.694, 'Recall': 0.381, 'F1': 0.491, 'MCC': 0.427, 'AUC_PR': 0.636, 'AUC_ROC': 0.805, 'PREC_N_SCORES': 0.655}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.inne import INNE\n",
    "\n",
    "model = INNE()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b5366a",
   "metadata": {},
   "source": [
    "ALAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e0764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALAD(activation_hidden_disc='tanh', activation_hidden_gen='tanh',\n",
      "   add_disc_zz_loss=True, add_recon_loss=False, batch_size=32,\n",
      "   contamination=0.1, dec_layers=[5, 10, 25], device=device(type='cpu'),\n",
      "   disc_xx_layers=[25, 10, 5], disc_xz_layers=[25, 10, 5],\n",
      "   disc_zz_layers=[25, 10, 5], dropout_rate=0.2, enc_layers=[25, 10, 5],\n",
      "   epochs=200, lambda_recon_loss=0.1, latent_dim=2,\n",
      "   learning_rate_disc=0.0001, learning_rate_gen=0.0001,\n",
      "   output_activation=None, preprocessing=False,\n",
      "   spectral_normalization=False, verbose=0) \n",
      " {'Accuracy': 0.783, 'Precision': 0.485, 'Recall': 0.283, 'F1': 0.358, 'MCC': 0.25, 'AUC_PR': 0.426, 'AUC_ROC': 0.626, 'PREC_N_SCORES': 0.407}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.alad import ALAD\n",
    "\n",
    "model = ALAD()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff966da",
   "metadata": {},
   "source": [
    "LMDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMDD(contamination=0.1, dis_measure='aad', n_iter=50, random_state=None) \n",
      " {'Accuracy': 0.822, 'Precision': 1.0, 'Recall': 0.168, 'F1': 0.288, 'MCC': 0.37, 'AUC_PR': 0.624, 'AUC_ROC': 0.765, 'PREC_N_SCORES': 0.663}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.lmdd import LMDD\n",
    "\n",
    "model = LMDD()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfca5e0",
   "metadata": {},
   "source": [
    "SOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f82998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOD(alpha=0.8, contamination=0.1, n_neighbors=20, ref_set=10) \n",
      " {'Accuracy': 0.826, 'Precision': 0.611, 'Recall': 0.513, 'F1': 0.558, 'MCC': 0.453, 'AUC_PR': 0.621, 'AUC_ROC': 0.797, 'PREC_N_SCORES': 0.549}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.sod import SOD\n",
    "\n",
    "model = SOD()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42df12fb",
   "metadata": {},
   "source": [
    "COF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578deac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COF(contamination=0.1, method='fast', n_neighbors=20) \n",
      " {'Accuracy': 0.834, 'Precision': 0.667, 'Recall': 0.442, 'F1': 0.532, 'MCC': 0.449, 'AUC_PR': 0.603, 'AUC_ROC': 0.774, 'PREC_N_SCORES': 0.593}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.cof import COF\n",
    "\n",
    "model = COF()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35130602",
   "metadata": {},
   "source": [
    "LODA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12782922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LODA(contamination=0.1, n_bins=10, n_random_cuts=100) \n",
      " {'Accuracy': 0.83, 'Precision': 0.689, 'Recall': 0.372, 'F1': 0.483, 'MCC': 0.418, 'AUC_PR': 0.549, 'AUC_ROC': 0.692, 'PREC_N_SCORES': 0.522}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.loda import LODA\n",
    "\n",
    "model = LODA()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b9f73c",
   "metadata": {},
   "source": [
    "LUNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b6391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUNAR(contamination=0.1, epsilon=0.1, lr=0.001, model_type='WEIGHT',\n",
      "   n_epochs=200, n_neighbours=5, negative_sampling='MIXED', proportion=1.0,\n",
      "   scaler=MinMaxScaler(), val_size=0.1, verbose=0, wd=0.1) \n",
      " {'Accuracy': 0.815, 'Precision': 0.742, 'Recall': 0.204, 'F1': 0.319, 'MCC': 0.322, 'AUC_PR': 0.539, 'AUC_ROC': 0.796, 'PREC_N_SCORES': 0.451}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.lunar import LUNAR\n",
    "\n",
    "model = LUNAR()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134d43ae",
   "metadata": {},
   "source": [
    "CBLOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d31d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBLOF(alpha=0.9, beta=5, check_estimator=False, clustering_estimator=None,\n",
      "   contamination=0.1, n_clusters=8, n_jobs=None, random_state=None,\n",
      "   use_weights=False) \n",
      " {'Accuracy': 0.802, 'Precision': 0.569, 'Recall': 0.292, 'F1': 0.386, 'MCC': 0.304, 'AUC_PR': 0.45, 'AUC_ROC': 0.574, 'PREC_N_SCORES': 0.372}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.cblof import CBLOF\n",
    "\n",
    "model = CBLOF()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e78d538",
   "metadata": {},
   "source": [
    "DIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664e4d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIF(batch_size=1000, contamination=0.1, device=device(type='cpu'),\n",
      "  hidden_activation='tanh', hidden_neurons=[500, 100], max_samples=256,\n",
      "  n_ensemble=50, n_estimators=6, random_state=None, representation_dim=20,\n",
      "  skip_connection=False) \n",
      " {'Accuracy': 0.786, 'Precision': 0.5, 'Recall': 0.009, 'F1': 0.017, 'MCC': 0.043, 'AUC_PR': 0.541, 'AUC_ROC': 0.836, 'PREC_N_SCORES': 0.584}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.dif import DIF\n",
    "\n",
    "model = DIF()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.predict_proba(X_test2)[:,1]\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d12a8b",
   "metadata": {},
   "source": [
    "VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322caf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 30/30 [00:11<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE(batch_norm=False, batch_size=32, beta=1.0, capacity=0.0,\n",
      "  compile_mode='default', contamination=0.1,\n",
      "  decoder_neuron_list=[32, 64, 128], device=device(type='cpu'),\n",
      "  dropout_rate=0.2, encoder_neuron_list=[128, 64, 32], epoch_num=30,\n",
      "  hidden_activation_name='relu', latent_dim=2, lr=0.001,\n",
      "  optimizer_name='adam', optimizer_params={'weight_decay': 1e-05},\n",
      "  output_activation_name='sigmoid', preprocessing=True, random_state=42,\n",
      "  use_compile=False, verbose=1) \n",
      " {'Accuracy': 0.794, 'Precision': 0.532, 'Recall': 0.292, 'F1': 0.377, 'MCC': 0.283, 'AUC_PR': 0.446, 'AUC_ROC': 0.687, 'PREC_N_SCORES': 0.513}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.vae import VAE\n",
    "\n",
    "model = VAE()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842c38a",
   "metadata": {},
   "source": [
    "GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b603e181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM(contamination=0.1, covariance_type='full', init_params='kmeans',\n",
      "  max_iter=100, means_init=None, n_components=1, n_init=1,\n",
      "  precisions_init=None, random_state=None, reg_covar=1e-06, tol=0.001,\n",
      "  warm_start=False, weights_init=None) \n",
      " {'Accuracy': 0.783, 'Precision': 0.482, 'Recall': 0.239, 'F1': 0.32, 'MCC': 0.225, 'AUC_PR': 0.426, 'AUC_ROC': 0.713, 'PREC_N_SCORES': 0.389}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.gmm import GMM\n",
    "\n",
    "model = GMM()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c8a4e4",
   "metadata": {},
   "source": [
    "DeepSVDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f094a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 36.17359483242035\n",
      "Epoch 2/100, Loss: 36.19166633486748\n",
      "Epoch 3/100, Loss: 36.2466336786747\n",
      "Epoch 4/100, Loss: 36.13528761267662\n",
      "Epoch 5/100, Loss: 36.165921211242676\n",
      "Epoch 6/100, Loss: 36.13916572928429\n",
      "Epoch 7/100, Loss: 36.189294904470444\n",
      "Epoch 8/100, Loss: 36.17238187789917\n",
      "Epoch 9/100, Loss: 36.2117395401001\n",
      "Epoch 10/100, Loss: 36.185857594013214\n",
      "Epoch 11/100, Loss: 36.13321906328201\n",
      "Epoch 12/100, Loss: 36.1584706902504\n",
      "Epoch 13/100, Loss: 36.17630282044411\n",
      "Epoch 14/100, Loss: 36.17380636930466\n",
      "Epoch 15/100, Loss: 36.25334322452545\n",
      "Epoch 16/100, Loss: 36.1712027490139\n",
      "Epoch 17/100, Loss: 36.12485006451607\n",
      "Epoch 18/100, Loss: 36.4436274766922\n",
      "Epoch 19/100, Loss: 36.22374951839447\n",
      "Epoch 20/100, Loss: 36.2115415930748\n",
      "Epoch 21/100, Loss: 36.16678577661514\n",
      "Epoch 22/100, Loss: 36.20809951424599\n",
      "Epoch 23/100, Loss: 36.228652626276016\n",
      "Epoch 24/100, Loss: 36.154085248708725\n",
      "Epoch 25/100, Loss: 36.138443648815155\n",
      "Epoch 26/100, Loss: 36.5161928832531\n",
      "Epoch 27/100, Loss: 36.136161506175995\n",
      "Epoch 28/100, Loss: 36.181707948446274\n",
      "Epoch 29/100, Loss: 36.141745775938034\n",
      "Epoch 30/100, Loss: 36.1334473490715\n",
      "Epoch 31/100, Loss: 36.193426355719566\n",
      "Epoch 32/100, Loss: 36.15622678399086\n",
      "Epoch 33/100, Loss: 36.199489802122116\n",
      "Epoch 34/100, Loss: 36.11734637618065\n",
      "Epoch 35/100, Loss: 36.160643100738525\n",
      "Epoch 36/100, Loss: 36.1936252117157\n",
      "Epoch 37/100, Loss: 36.16784855723381\n",
      "Epoch 38/100, Loss: 36.19024500250816\n",
      "Epoch 39/100, Loss: 36.2072534263134\n",
      "Epoch 40/100, Loss: 36.19248494505882\n",
      "Epoch 41/100, Loss: 36.18511536717415\n",
      "Epoch 42/100, Loss: 36.156825214624405\n",
      "Epoch 43/100, Loss: 36.18466040492058\n",
      "Epoch 44/100, Loss: 36.14989456534386\n",
      "Epoch 45/100, Loss: 36.18341547250748\n",
      "Epoch 46/100, Loss: 36.13255634903908\n",
      "Epoch 47/100, Loss: 36.44247457385063\n",
      "Epoch 48/100, Loss: 36.20795226097107\n",
      "Epoch 49/100, Loss: 36.16933789849281\n",
      "Epoch 50/100, Loss: 36.155869632959366\n",
      "Epoch 51/100, Loss: 36.17461675405502\n",
      "Epoch 52/100, Loss: 36.14994007349014\n",
      "Epoch 53/100, Loss: 36.176823407411575\n",
      "Epoch 54/100, Loss: 36.16330271959305\n",
      "Epoch 55/100, Loss: 36.18516033887863\n",
      "Epoch 56/100, Loss: 36.17514684796333\n",
      "Epoch 57/100, Loss: 36.11868315935135\n",
      "Epoch 58/100, Loss: 36.16933134198189\n",
      "Epoch 59/100, Loss: 36.193585991859436\n",
      "Epoch 60/100, Loss: 36.30585631728172\n",
      "Epoch 61/100, Loss: 36.124624133110046\n",
      "Epoch 62/100, Loss: 36.41590037941933\n",
      "Epoch 63/100, Loss: 36.16250681877136\n",
      "Epoch 64/100, Loss: 36.13125276565552\n",
      "Epoch 65/100, Loss: 36.290554732084274\n",
      "Epoch 66/100, Loss: 36.19485479593277\n",
      "Epoch 67/100, Loss: 36.192596822977066\n",
      "Epoch 68/100, Loss: 36.19311338663101\n",
      "Epoch 69/100, Loss: 36.15330824255943\n",
      "Epoch 70/100, Loss: 36.15977245569229\n",
      "Epoch 71/100, Loss: 36.17040690779686\n",
      "Epoch 72/100, Loss: 36.20549160242081\n",
      "Epoch 73/100, Loss: 36.14463156461716\n",
      "Epoch 74/100, Loss: 36.23132652044296\n",
      "Epoch 75/100, Loss: 36.14879962801933\n",
      "Epoch 76/100, Loss: 36.246677339076996\n",
      "Epoch 77/100, Loss: 36.14988797903061\n",
      "Epoch 78/100, Loss: 36.13583964109421\n",
      "Epoch 79/100, Loss: 36.220797061920166\n",
      "Epoch 80/100, Loss: 36.12322652339935\n",
      "Epoch 81/100, Loss: 36.13682180643082\n",
      "Epoch 82/100, Loss: 36.136348247528076\n",
      "Epoch 83/100, Loss: 36.21580085158348\n",
      "Epoch 84/100, Loss: 36.154904037714005\n",
      "Epoch 85/100, Loss: 36.17132344841957\n",
      "Epoch 86/100, Loss: 36.27107375860214\n",
      "Epoch 87/100, Loss: 36.149519234895706\n",
      "Epoch 88/100, Loss: 36.13255423307419\n",
      "Epoch 89/100, Loss: 36.17941099405289\n",
      "Epoch 90/100, Loss: 36.24904045462608\n",
      "Epoch 91/100, Loss: 36.19086942076683\n",
      "Epoch 92/100, Loss: 36.16237214207649\n",
      "Epoch 93/100, Loss: 36.12625986337662\n",
      "Epoch 94/100, Loss: 36.16925394535065\n",
      "Epoch 95/100, Loss: 36.25732374191284\n",
      "Epoch 96/100, Loss: 36.15719136595726\n",
      "Epoch 97/100, Loss: 36.21809810400009\n",
      "Epoch 98/100, Loss: 36.19173404574394\n",
      "Epoch 99/100, Loss: 36.41532385349274\n",
      "Epoch 100/100, Loss: 36.2065212726593\n",
      "DeepSVDD(batch_size=32, c=0.0, contamination=0.1, dropout_rate=0.2,\n",
      "     epochs=100, hidden_activation='relu', hidden_neurons=[64, 32],\n",
      "     l2_regularizer=0.1, n_features=18, optimizer='adam',\n",
      "     output_activation='sigmoid', preprocessing=True, random_state=None,\n",
      "     use_ae=False, validation_size=0.1, verbose=1) \n",
      " {'Accuracy': 0.76, 'Precision': 0.394, 'Recall': 0.23, 'F1': 0.291, 'MCC': 0.166, 'AUC_PR': 0.333, 'AUC_ROC': 0.598, 'PREC_N_SCORES': 0.319}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.deep_svdd import DeepSVDD\n",
    "\n",
    "# Determina il numero di feature\n",
    "n_features = X_train2.shape[1]\n",
    "\n",
    "model = DeepSVDD(n_features=n_features)\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba48687c",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d99bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(contamination=0.1, copy=True, iterated_power='auto', n_components=None,\n",
      "  n_selected_components=None, random_state=None, standardization=True,\n",
      "  svd_solver='auto', tol=0.0, weighted=True, whiten=False) \n",
      " {'Accuracy': 0.779, 'Precision': 0.464, 'Recall': 0.23, 'F1': 0.308, 'MCC': 0.21, 'AUC_PR': 0.373, 'AUC_ROC': 0.612, 'PREC_N_SCORES': 0.363}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.pca import PCA\n",
    "\n",
    "model = PCA()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9980f4ce",
   "metadata": {},
   "source": [
    "COPOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e4963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COPOD(contamination=0.1, n_jobs=1) \n",
      " {'Accuracy': 0.767, 'Precision': 0.4, 'Recall': 0.177, 'F1': 0.245, 'MCC': 0.147, 'AUC_PR': 0.328, 'AUC_ROC': 0.627, 'PREC_N_SCORES': 0.257}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.copod import COPOD\n",
    "\n",
    "model = COPOD()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b78adc",
   "metadata": {},
   "source": [
    "SOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea353c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOS(contamination=0.1, eps=1e-05, metric='euclidean', perplexity=4.5) \n",
      " {'Accuracy': 0.758, 'Precision': 0.364, 'Recall': 0.177, 'F1': 0.238, 'MCC': 0.125, 'AUC_PR': 0.308, 'AUC_ROC': 0.524, 'PREC_N_SCORES': 0.274}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.sos import SOS\n",
    "\n",
    "model = SOS()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203a345",
   "metadata": {},
   "source": [
    "ECOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e207f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECOD(contamination=0.1, n_jobs=1) \n",
      " {'Accuracy': 0.767, 'Precision': 0.396, 'Recall': 0.168, 'F1': 0.236, 'MCC': 0.14, 'AUC_PR': 0.34, 'AUC_ROC': 0.637, 'PREC_N_SCORES': 0.345}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.ecod import ECOD\n",
    "\n",
    "model = ECOD()\n",
    "model.fit(X_train2)\n",
    "\n",
    "y_predicted = model.predict(X_test2)\n",
    "y_predicted_score = model.decision_function(X_test2)\n",
    "\n",
    "print(model, '\\n', evaluate_metrics(y_test, y_predicted, y_predicted_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140e0d61",
   "metadata": {},
   "source": [
    "## XGBOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf9dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [21:32:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOD(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "   colsample_bytree=1,\n",
      "   estimator_list=[KNN(algorithm='auto', contamination=0.1, leaf_size=30, method='largest',\n",
      "  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "  radius=1.0), LOF(algorithm='auto', contamination=0.1, leaf_size=30, metric='minkowski',\n",
      "  metric_params=None, n_jobs=1, n_neighbors=1, no...ax_features=1.0,\n",
      "    max_samples='auto', n_estimators=200, n_jobs=1, random_state=0,\n",
      "    verbose=0)],\n",
      "   gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "   min_child_weight=1, n_estimators=100, n_jobs=1, nthread=None,\n",
      "   objective='binary:logistic', random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "   scale_pos_weight=1, silent=True,\n",
      "   standardization_flag_list=[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False],\n",
      "   subsample=1) {'Accuracy': 0.968, 'Precision': 0.953, 'Recall': 0.894, 'F1': 0.922, 'MCC': 0.903, 'AUC_PR': 0.969, 'AUC_ROC': 0.99, 'PREC_N_SCORES': 0.912}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.xgbod import XGBOD\n",
    "\n",
    "# Inizializza e addestra XGBOD\n",
    "model = XGBOD()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prevedi gli outlier nel dataset di test\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_predicted_score = model.decision_function(X_test_scaled)\n",
    "# Eseguiamo la valutazione delle metriche\n",
    "metrics = evaluate_metrics(y_test, y_pred, y_predicted_score)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(model, metrics)\n",
    "\n",
    "#n_estimators=50,\n",
    "#max_depth=3,\n",
    "#learning_rate=0.1,\n",
    "#random_state=SEED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3705d61e",
   "metadata": {},
   "source": [
    "#### Con metiche di Memoria e Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82d45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "from pyod.models.xgbod import XGBOD\n",
    "\n",
    "# Inizializza e addestra XGBOD\n",
    "model = XGBOD(n_estimators=50, max_depth=3, learning_rate=0.1, random_state=SEED)\n",
    "\n",
    "def train_model():\n",
    "    start_time = time.time()\n",
    "    mem_usage = memory_usage((model.fit, (X_train_scaled, y_train)))\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\n Tempo di addestramento: {training_time} secondi\")\n",
    "    print(f\"Uso della memoria durante l'addestramento: {max(mem_usage)} MiB\")\n",
    "    return training_time, mem_usage\n",
    "\n",
    "def inference_model():\n",
    "    start_time = time.time()\n",
    "    mem_usage_inference = memory_usage((model.predict, (X_test_scaled,)))\n",
    "    inference_time = time.time() - start_time\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    print(f\"\\n Tempo di inferenza: {inference_time} secondi\")\n",
    "    print(f\"Uso della memoria durante l'inferenza: {max(mem_usage_inference)} MiB\")\n",
    "    return y_pred, inference_time, mem_usage_inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5595e73b",
   "metadata": {},
   "source": [
    "### XGBOD più modelli unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b09d455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOD(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "   colsample_bytree=1,\n",
      "   estimator_list=[KNN(algorithm='auto', contamination=0.1, leaf_size=30, method='largest',\n",
      "  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "  radius=1.0), LOF(algorithm='auto', contamination=0.1, leaf_size=30, metric='minkowski',\n",
      "  metric_params=None, n_jobs=1, n_neighbors=20, n...3, gamma='auto',\n",
      "   kernel='rbf', max_iter=-1, nu=0.5, shrinking=True, tol=0.001,\n",
      "   verbose=False)],\n",
      "   gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "   min_child_weight=1, n_estimators=100, n_jobs=1, nthread=None,\n",
      "   objective='binary:logistic', random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "   scale_pos_weight=1, silent=True,\n",
      "   standardization_flag_list=[True, True, True, True], subsample=1) {'Accuracy': 0.968, 'Precision': 0.944, 'Recall': 0.903, 'F1': 0.923, 'MCC': 0.903, 'AUC_PR': 0.974, 'AUC_ROC': 0.991, 'PREC_N_SCORES': 0.92}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.xgbod import XGBOD\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "\n",
    "# Definizione dei modelli unsupervised\n",
    "unsupervised_models = [ KNN(),\n",
    "                       LOF(),\n",
    "                       ABOD(),\n",
    "                        OCSVM()\n",
    "                    ]\n",
    "# Inizializza e addestra XGBOD\n",
    "model = XGBOD(estimator_list=unsupervised_models)\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prevedi gli outlier nel dataset di test\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_predicted_score = model.decision_function(X_test_scaled)\n",
    "# Eseguiamo la valutazione delle metriche\n",
    "metrics = evaluate_metrics(y_test, y_pred, y_predicted_score)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(model, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c6d685",
   "metadata": {},
   "source": [
    "#### Con Metriche di Tempo e Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d2966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:13:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tempo di addestramento: 2.3419463634490967 secondi\n",
      "Uso della memoria durante l'addestramento: 815.8125 MiB\n",
      "\n",
      " Tempo di inferenza: 1.605494499206543 secondi\n",
      "Uso della memoria durante l'inferenza: 815.79296875 MiB\n",
      "XGBOD(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "   colsample_bytree=1,\n",
      "   estimator_list=[KNN(algorithm='auto', contamination=0.1, leaf_size=30, method='largest',\n",
      "  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "  radius=1.0), LOF(algorithm='auto', contamination=0.1, leaf_size=30, metric='minkowski',\n",
      "  metric_params=None, n_jobs=1, n_neighbors=20, n...3, gamma='auto',\n",
      "   kernel='rbf', max_iter=-1, nu=0.5, shrinking=True, tol=0.001,\n",
      "   verbose=False)],\n",
      "   gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "   min_child_weight=1, n_estimators=100, n_jobs=1, nthread=None,\n",
      "   objective='binary:logistic', random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "   scale_pos_weight=1, silent=True,\n",
      "   standardization_flag_list=[True, True, True, True], subsample=1) {'Accuracy': 0.968, 'Precision': 0.944, 'Recall': 0.903, 'F1': 0.923, 'MCC': 0.903, 'AUC_PR': 0.974, 'AUC_ROC': 0.991, 'PREC_N_SCORES': 0.92}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "from pyod.models.xgbod import XGBOD\n",
    "\n",
    "# Definizione dei modelli unsupervised\n",
    "unsupervised_models = [ KNN(),\n",
    "                       LOF(),\n",
    "                       ABOD(),\n",
    "                        OCSVM()\n",
    "                    ]\n",
    "# Inizializza e addestra XGBOD\n",
    "model = XGBOD(estimator_list=unsupervised_models)\n",
    "\n",
    "def train_model():\n",
    "    start_time = time.time()\n",
    "    mem_usage = memory_usage((model.fit, (X_train_scaled, y_train)))\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\n Tempo di addestramento: {training_time} secondi\")\n",
    "    print(f\"Uso della memoria durante l'addestramento: {max(mem_usage)} MiB\")\n",
    "    return training_time, mem_usage\n",
    "\n",
    "def inference_model():\n",
    "    start_time = time.time()\n",
    "    mem_usage_inference = memory_usage((model.predict, (X_test_scaled,)))\n",
    "    inference_time = time.time() - start_time\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    print(f\"\\n Tempo di inferenza: {inference_time} secondi\")\n",
    "    print(f\"Uso della memoria durante l'inferenza: {max(mem_usage_inference)} MiB\")\n",
    "    return y_pred, inference_time, mem_usage_inference\n",
    "\n",
    "# Addestramento del modello e monitoraggio delle metriche di efficientamento\n",
    "training_time, mem_usage = train_model()\n",
    "\n",
    "# Inferenza del modello e monitoraggio delle metriche di efficientamento\n",
    "y_pred, inference_time, mem_usage_inference = inference_model()\n",
    "\n",
    "# Calcola i punteggi di decisione\n",
    "y_predicted_score = model.decision_function(X_test_scaled)\n",
    "\n",
    "# Eseguiamo la valutazione delle metriche con le nuove metriche di efficientamento\n",
    "metrics = evaluate_metrics(y_test, y_pred, y_predicted_score)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(model, metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a13a44",
   "metadata": {},
   "source": [
    "### XGBOD più modelli unsupervised e Parametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7899936c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'Accuracy': 0.97, 'Precision': 0.945, 'Recall': 0.912, 'F1': 0.928, 'MCC': 0.909, 'AUC_PR': 0.973, 'AUC_ROC': 0.992, 'PREC_N_SCORES': 0.92}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.xgbod import XGBOD\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "\n",
    "# Definizione dei modelli unsupervised\n",
    "unsupervised_models = [ KNN(),\n",
    "                       LOF(),\n",
    "                       ABOD(),\n",
    "                        OCSVM()\n",
    "                    ]\n",
    "\n",
    "# Inizializza e addestra XGBOD\n",
    "model = XGBOD(estimator_list=unsupervised_models,\n",
    "              n_estimators=100,\n",
    "              max_depth=3,\n",
    "              learning_rate=0.2,\n",
    "              n_jobs=-1,\n",
    "              random_state=SEED\n",
    "            )\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prevedi gli outlier nel dataset di test\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_predicted_score = model.decision_function(X_test_scaled)\n",
    "\n",
    "# Eseguiamo la valutazione delle metriche\n",
    "metrics = evaluate_metrics(y_test, y_pred, y_predicted_score)\n",
    "print(\"\")\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796179ff",
   "metadata": {},
   "source": [
    "#### Con Metriche di Tempo e Memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f2d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:14:04] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tempo di addestramento: 2.611022472381592 secondi\n",
      "Uso della memoria durante l'addestramento: 816.11328125 MiB\n",
      "\n",
      " Tempo di inferenza: 1.9620587825775146 secondi\n",
      "Uso della memoria durante l'inferenza: 816.078125 MiB\n",
      "XGBOD(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "   colsample_bytree=1,\n",
      "   estimator_list=[KNN(algorithm='auto', contamination=0.1, leaf_size=30, method='largest',\n",
      "  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "  radius=1.0), LOF(algorithm='auto', contamination=0.1, leaf_size=30, metric='minkowski',\n",
      "  metric_params=None, n_jobs=1, n_neighbors=20, n...3, gamma='auto',\n",
      "   kernel='rbf', max_iter=-1, nu=0.5, shrinking=True, tol=0.001,\n",
      "   verbose=False)],\n",
      "   gamma=0, learning_rate=0.2, max_delta_step=0, max_depth=3,\n",
      "   min_child_weight=1, n_estimators=100, n_jobs=1, nthread=None,\n",
      "   objective='binary:logistic', random_state=2137, reg_alpha=0,\n",
      "   reg_lambda=1, scale_pos_weight=1, silent=True,\n",
      "   standardization_flag_list=[True, True, True, True], subsample=1) {'Accuracy': 0.97, 'Precision': 0.945, 'Recall': 0.912, 'F1': 0.928, 'MCC': 0.909, 'AUC_PR': 0.973, 'AUC_ROC': 0.992, 'PREC_N_SCORES': 0.92}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from memory_profiler import memory_usage\n",
    "from pyod.models.xgbod import XGBOD\n",
    "\n",
    "# Definizione dei modelli unsupervised\n",
    "unsupervised_models = [ KNN(),\n",
    "                       LOF(),\n",
    "                       ABOD(),\n",
    "                        OCSVM()\n",
    "                    ]\n",
    "# Inizializza e addestra XGBOD\n",
    "model = XGBOD(estimator_list=unsupervised_models, n_estimators=100, max_depth=3, learning_rate=0.2, random_state=SEED)\n",
    "\n",
    "def train_model():\n",
    "    start_time = time.time()\n",
    "    mem_usage = memory_usage((model.fit, (X_train_scaled, y_train)))\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\n Tempo di addestramento: {training_time} secondi\")\n",
    "    print(f\"Uso della memoria durante l'addestramento: {max(mem_usage)} MiB\")\n",
    "    return training_time, mem_usage\n",
    "\n",
    "def inference_model():\n",
    "    start_time = time.time()\n",
    "    mem_usage_inference = memory_usage((model.predict, (X_test_scaled,)))\n",
    "    inference_time = time.time() - start_time\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    print(f\"\\n Tempo di inferenza: {inference_time} secondi\")\n",
    "    print(f\"Uso della memoria durante l'inferenza: {max(mem_usage_inference)} MiB\")\n",
    "    return y_pred, inference_time, mem_usage_inference\n",
    "\n",
    "# Addestramento del modello e monitoraggio delle metriche di efficientamento\n",
    "training_time, mem_usage = train_model()\n",
    "\n",
    "# Inferenza del modello e monitoraggio delle metriche di efficientamento\n",
    "y_pred, inference_time, mem_usage_inference = inference_model()\n",
    "\n",
    "# Calcola i punteggi di decisione\n",
    "y_predicted_score = model.decision_function(X_test_scaled)\n",
    "\n",
    "# Eseguiamo la valutazione delle metriche con le nuove metriche di efficientamento\n",
    "metrics = evaluate_metrics(y_test, y_pred, y_predicted_score)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(model, metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39459cc5",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Termina l'esecuzione anticipatamente se per un numero prestabilito di round non migliorano più i parametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0157b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:46] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:47] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:51] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:09:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at iteration 12\n",
      "\n",
      "{'Accuracy': 0.97, 'Precision': 0.971, 'Recall': 0.885, 'F1': 0.926, 'MCC': 0.909, 'AUC_PR': 0.969, 'AUC_ROC': 0.99, 'PREC_N_SCORES': 0.912}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pyod.models.xgbod import XGBOD\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "\n",
    "# Definizione dei modelli unsupervised\n",
    "unsupervised_models = [ KNN(),\n",
    "                       LOF(),\n",
    "                       ABOD(),\n",
    "                        OCSVM()\n",
    "                    ]\n",
    "\n",
    "# Divisione del dataset di allenamento per avere un set di validazione\n",
    "X_train_sub, X_val, y_train_sub, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# Inizializzazione del modello\n",
    "model = XGBOD(estimator_list=unsupervised_models, n_estimators=50, max_depth=3, learning_rate=0.2, n_jobs=-1, random_state=SEED)\n",
    "\n",
    "best_score = -np.inf\n",
    "patience = 10       # Numero di volte che il modello cercherà di migliorarsi\n",
    "patience_counter = 0\n",
    "n_iterations = 100      # Numero massimo di cicli del'allenamento\n",
    "\n",
    "for i in range(n_iterations):  # Numero massimo di iterazioni\n",
    "    model.fit(X_train_sub, y_train_sub)\n",
    "    \n",
    "    # Predizione sul set di validazione\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    val_score = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Controllo early stopping\n",
    "    if val_score > best_score:\n",
    "        best_score = val_score\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at iteration {i}\")\n",
    "            break\n",
    "    model.n_estimators += 1  # Incrementa il numero di stimatori per la prossima iterazione\n",
    "\n",
    "# Predizione sul set di test\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_predicted_score = model.decision_function(X_test_scaled)\n",
    "\n",
    "# Eseguiamo la valutazione delle metriche\n",
    "metrics = evaluate_metrics(y_test, y_pred, y_predicted_score)\n",
    "print(\"\")\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bcc0b0",
   "metadata": {},
   "source": [
    "### XGBOD con ricerca iperparametri con \"grid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c125a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:16:55] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\pyod\\models\\base.py:423: UserWarning: y should not be presented in unsupervised learning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:17:00] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOD(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "   colsample_bytree=1,\n",
      "   estimator_list=[KNN(algorithm='auto', contamination=0.1, leaf_size=30, method='largest',\n",
      "  metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
      "  radius=1.0), LOF(algorithm='auto', contamination=0.1, leaf_size=30, metric='minkowski',\n",
      "  metric_params=None, n_jobs=1, n_neighbors=1, no...ax_features=1.0,\n",
      "    max_samples='auto', n_estimators=200, n_jobs=1, random_state=0,\n",
      "    verbose=0)],\n",
      "   gamma=0, learning_rate=0.01, max_delta_step=0, max_depth=3,\n",
      "   min_child_weight=1, n_estimators=50, n_jobs=1, nthread=None,\n",
      "   objective='binary:logistic', random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "   scale_pos_weight=1, silent=True,\n",
      "   standardization_flag_list=[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False],\n",
      "   subsample=1) {'Accuracy': 0.947, 'Precision': 0.989, 'Recall': 0.761, 'F1': 0.86, 'MCC': 0.839, 'AUC_PR': 0.898, 'AUC_ROC': 0.945, 'PREC_N_SCORES': 0.967}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pyod.models.xgbod import XGBOD\n",
    "import numpy as np\n",
    "\n",
    "# Definizione della griglia di parametri\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Inizializza il modello\n",
    "model = XGBOD()\n",
    "\n",
    "# Randomized search con meno iterazioni e parallelizzazione\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10, cv=3, scoring='roc_auc', random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Migliori parametri trovati\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Riaddestramento del modello con i migliori parametri\n",
    "model = XGBOD(**best_params)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prevedi gli outlier nel dataset di test\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_predicted_score = model.decision_function(X_test_scaled)\n",
    "\n",
    "# Eseguiamo la valutazione delle metriche\n",
    "metrics = evaluate_metrics(y_test, y_pred, y_predicted_score)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(model, metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b35867",
   "metadata": {},
   "source": [
    "### FCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad2c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8006 - loss: 0.4877 - val_accuracy: 0.8885 - val_loss: 0.2546\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9154 - loss: 0.2390 - val_accuracy: 0.9244 - val_loss: 0.1969\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9334 - loss: 0.1862 - val_accuracy: 0.9168 - val_loss: 0.1949\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9408 - loss: 0.1831 - val_accuracy: 0.9452 - val_loss: 0.1793\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9474 - loss: 0.1629 - val_accuracy: 0.9471 - val_loss: 0.1570\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9424 - loss: 0.1595 - val_accuracy: 0.9546 - val_loss: 0.1572\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9514 - loss: 0.1251 - val_accuracy: 0.9509 - val_loss: 0.1471\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9561 - loss: 0.1225 - val_accuracy: 0.9546 - val_loss: 0.1322\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9428 - loss: 0.1436 - val_accuracy: 0.9565 - val_loss: 0.1249\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9612 - loss: 0.1117 - val_accuracy: 0.9622 - val_loss: 0.1135\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "<Sequential name=sequential, built=True> {'Accuracy': 0.962, 'Precision': 0.927, 'Recall': 0.894, 'F1': 0.91, 'MCC': 0.886, 'AUC_PR': 0.966, 'AUC_ROC': 0.984, 'PREC_N_SCORES': 0.903}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definisci il modello FCNN\n",
    "model = Sequential([\n",
    "    Conv1D(64, 3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(128, 3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Poiché si tratta di una classificazione binaria\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Addestra il modello\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "# Prevedi gli outlier nel dataset di test\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(\"int32\")\n",
    "y_predicted_score = model.predict(X_test_scaled)\n",
    "\n",
    "metrics = evaluate_metrics(y_test, y_pred, y_predicted_score)\n",
    "\n",
    "# Stampa i risultati\n",
    "print(model, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f797308e",
   "metadata": {},
   "source": [
    "# Rocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d67943",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Il numero di campioni non corrisponde!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m features \u001b[38;5;241m=\u001b[39m rocket\u001b[38;5;241m.\u001b[39mtransform(X_train_scaled)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Verifica che il numero di campioni di features e y_test sia lo stesso\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m y_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIl numero di campioni non corrisponde!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 3. Rilevamento delle anomalie\u001b[39;00m\n\u001b[0;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBOD(contamination\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \u001b[38;5;66;03m# Modello non supervisionato\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Il numero di campioni non corrisponde!"
     ]
    }
   ],
   "source": [
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from pyod.models.xgbod import XGBOD\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 2. Applica ROCKET\n",
    "rocket = Rocket(num_kernels=10000)\n",
    "rocket.fit(X_train_scaled, y_train)\n",
    "features = rocket.transform(X_train_scaled)\n",
    "# Verifica che il numero di campioni di features e y_test sia lo stesso\n",
    "assert features.shape[0] == y_test.shape[0], \"Il numero di campioni non corrisponde!\"\n",
    "\n",
    "\n",
    "# 3. Rilevamento delle anomalie\n",
    "model = XGBOD(contamination=0.01, random_state=42)  # Modello non supervisionato\n",
    "anomaly_scores = model.fit_predict(features, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1007c0",
   "metadata": {},
   "source": [
    "## Rocket Normale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae4273bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalie rilevate nel training set: [1 0 0 ... 0 0 0]\n",
      "Anomalie rilevate nel test set: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Metriche di valutazione sul test set:\n",
      " {'Accuracy': 0.832, 'Precision': 0.962, 'Recall': 0.221, 'F1': 0.36, 'MCC': 0.415, 'AUC_PR': 0.726, 'AUC_ROC': 0.772, 'PREC_N_SCORES': 0.646}\n"
     ]
    }
   ],
   "source": [
    "from rocket_functions import generate_kernels, apply_kernels\n",
    "\n",
    "def detect_anomalies_with_threshold(scores, threshold):\n",
    "    return (scores > threshold).astype(int)\n",
    "\n",
    "# Genera kernel convoluzionali casuali\n",
    "input_length = X_train.shape[1]\n",
    "num_kernels = 10000\n",
    "kernels = generate_kernels(input_length, num_kernels)\n",
    "\n",
    "# Applica i kernel alle serie temporali\n",
    "features_train = apply_kernels(X_train2, kernels)\n",
    "features_test = apply_kernels(X_test2, kernels)\n",
    "\n",
    "# Sintesi delle caratteristiche per esempio\n",
    "anomaly_scores_train = np.mean(features_train, axis=1)  # Media\n",
    "anomaly_scores_test = np.mean(features_test, axis=1)  # Media\n",
    "\n",
    "# Rilevamento delle anomalie\n",
    "threshold = np.percentile(anomaly_scores_train , 95)\n",
    "anomaly_labels_train = detect_anomalies_with_threshold(anomaly_scores_train , threshold)\n",
    "anomaly_labels_test = detect_anomalies_with_threshold(anomaly_scores_test , threshold)\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "print(\"Anomalie rilevate nel training set:\", anomaly_labels_train)\n",
    "print(\"Anomalie rilevate nel test set:\", anomaly_labels_test)\n",
    "\n",
    "# Eseguiamo la valutazione delle metriche\n",
    "metrics = evaluate_metrics(y_test, anomaly_labels_test, y_proba=anomaly_scores_test)\n",
    "print(\"Metriche di valutazione sul test set:\\n\", metrics)\n",
    "# {'Accuracy': 0.832, 'Precision': 0.962, 'Recall': 0.221, 'F1': 0.36, 'MCC': 0.415, 'AUC_PR': 0.726, 'AUC_ROC': 0.772, 'PREC_N_SCORES': 0.646}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ed2dc",
   "metadata": {},
   "source": [
    "## Rockad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f89f14d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Train\n",
      "(1, 20)\n",
      "   0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16  17  18  \\\n",
      "0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   \n",
      "\n",
      "   19  \n",
      "0   0  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input X contains infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Predict anomaly scores\u001b[39;00m\n\u001b[0;32m     42\u001b[0m X_test_array \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mto_numpy()\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 43\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mrockad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore: \u001b[39m\u001b[38;5;124m\"\u001b[39m,scores)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Initialize and fit NearestNeigbor One Class Classifier\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\RockadFunction.py:265\u001b[0m, in \u001b[0;36mROCKAD.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28mprint\u001b[39m(Xtp_scaled\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28mprint\u001b[39m((Xtp_scaled\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m100000000\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n\u001b[1;32m--> 265\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mbagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtp_scaled\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m    267\u001b[0m     y_scores[:, idx] \u001b[38;5;241m=\u001b[39m scores\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# Average the scores to get the final score for each time series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\RockadFunction.py:128\u001b[0m, in \u001b[0;36mNN.predict_proba\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 128\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m     scores \u001b[38;5;241m=\u001b[39m scores[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:825\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    823\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1059\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1060\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1061\u001b[0m     )\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m-> 1064\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1072\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1073\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from RockadFunction import ROCKAD, NearestNeighborOCC, NN\n",
    "\n",
    "    \n",
    "# Create the normal dataset (Normal class: Class 1)  \n",
    "#        the anomaly dataset (Anomaly class: Class 2)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "# Initialize and fit ROCKAD\n",
    "\n",
    "# X_train_array = np.array([x.to_numpy().flatten() for x in X_train.iloc[:, 0]])\n",
    "# X_test_array = np.array([x.to_numpy().flatten() for x in X_test.iloc[:, 0]])\n",
    "\n",
    "# Create the normal dataset (Normal class: Class 1)  \n",
    "#        the anomaly dataset (Anomaly class: Class 2)\n",
    "# print(\"X_train2: \", X_train2)\n",
    "# print(\"X_test: \", X_test)\n",
    "# print(\"X_test2: \", X_test2)\n",
    "# print(\"y_train: \", y_train)\n",
    "# print(\"y_test: \", y_test)\n",
    "\n",
    "X_normal_train = X_train[y_train == 0]\n",
    "\n",
    "# X_normal_test = X_test[y_test == '0']\n",
    "# X_anomaly_test = X_test[y_test == '2']\n",
    "# y_normal_test = y_test[y_test == '0']\n",
    "# y_anomaly_test = y_test[y_test == '2']\n",
    "\n",
    "# Merge the test sets \n",
    "# X_test = pd.DataFrame(np.concatenate((X_normal_test, X_anomaly_test), axis=0))\n",
    "# y_test = np.concatenate((y_normal_test, y_anomaly_test), axis=0)\n",
    "\n",
    "# X_test = np.concatenate((X_normal_test, X_anomaly_test), axis=0)\n",
    "# y_test = np.concatenate((y_normal_test, y_anomaly_test), axis=0)\n",
    "\n",
    "rockad = ROCKAD(n_estimators=10, n_kernels=10 ,random_state=RANDOM_STATE,power_transform=False)\n",
    "rockad.fit(X_normal_train)\n",
    "print(\"End Train\")\n",
    "\n",
    "# Predict anomaly scores\n",
    "X_test_array = X_test.to_numpy().astype(np.float32)\n",
    "scores = rockad.predict_proba(X_test_array)\n",
    "\n",
    "print(\"Score: \",scores)\n",
    "\n",
    "# Initialize and fit NearestNeigbor One Class Classifier\n",
    "decision_func = NearestNeighborOCC().fit(scores)\n",
    "\n",
    "# Predict anomalies\n",
    "predictions = decision_func.predict(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f601a68f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mRockadFunction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ROCKAD, NearestNeighborOCC, NN\n\u001b[0;32m      5\u001b[0m features \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manomaly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m ]\n\u001b[1;32m---> 12\u001b[0m dfSegment \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/segments.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m dfSegment:\n\u001b[0;32m     17\u001b[0m     mask \u001b[38;5;241m=\u001b[39m (dfSegment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (dfSegment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchannel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m channel)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from RockadFunction import ROCKAD, NearestNeighborOCC, NN\n",
    "\n",
    "features = [\n",
    "    \"channel\",\n",
    "    \"segment\",\n",
    "    \"value\",\n",
    "    \"anomaly\"\n",
    "]\n",
    "\n",
    "dfSegment = pd.read_csv(\"data/segments.csv\", index_col=\"timestamp\")\n",
    "\n",
    "mask = (dfSegment[\"train\"] == 1) & (dfSegment[\"channel\"] == channel)\n",
    "X_trainS, y_trainS = dfSegment.loc[mask, features], dfSegment.loc[mask, \"anomaly\"]\n",
    "\n",
    "# Filtra ulteriormente Values per ottenere solo le righe con result == 0\n",
    "X_normal_train = X_trainS[y_trainS == 0]\n",
    "# X_normal_train = X_normal_train[[\"segment\", \"value\"]]\n",
    "X_normal_train = X_normal_train[[\"value\"]] # Isola solo i valori di \"value\"\n",
    "X_normal_train = X_normal_train.reset_index(drop=True)  # Reset index, non usare l'indice temporale\n",
    "X_normal_train_values = X_normal_train.values  # Estrai i valori come array numpy\n",
    "\n",
    "# Filtra ulteriormente Values per ottenere solo le righe con result == 0\n",
    "# X_normal_train = X_normal_train[[\"segment\", \"value\"]]\n",
    "X_normal_trainPROBA = X_trainS[[\"value\"]] # Isola solo i valori di \"value\"\n",
    "X_normal_trainPROBA = X_normal_trainPROBA.reset_index(drop=True)  # Reset index, non usare l'indice temporale\n",
    "X_normal_trainPROBA = X_normal_trainPROBA.values  # Estrai i valori come array numpy\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "# Initialize and fit ROCKAD\n",
    "\n",
    "\n",
    "rockad = ROCKAD(n_estimators=10, n_kernels=10 ,random_state=RANDOM_STATE)\n",
    "rockad.fit(X_normal_train_values)\n",
    "print(\"End Train\")\n",
    "\n",
    "# Predict anomaly scores\n",
    "scores = rockad.predict_proba(X_normal_trainPROBA)\n",
    "\n",
    "print(\"Score: \",scores)\n",
    "\n",
    "# Initialize and fit NearestNeigbor One Class Classifier\n",
    "decision_func = NearestNeighborOCC(n_neighbors=1).fit(scores)\n",
    "\n",
    "# Predict anomalies\n",
    "predictions = decision_func.predict(scores)\n",
    "\n",
    "# Optionally, you can print the predictions or evaluate them\n",
    "print(\"Predictions: \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c43f3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for channel: CADC0872, segment: 1\n",
      "End Train for channel: CADC0872, segment: 1\n",
      "Training for channel: CADC0872, segment: 2\n",
      "End Train for channel: CADC0872, segment: 2\n",
      "Training for channel: CADC0872, segment: 3\n",
      "End Train for channel: CADC0872, segment: 3\n",
      "Training for channel: CADC0872, segment: 4\n",
      "End Train for channel: CADC0872, segment: 4\n",
      "Training for channel: CADC0872, segment: 6\n",
      "End Train for channel: CADC0872, segment: 6\n",
      "Training for channel: CADC0872, segment: 8\n",
      "End Train for channel: CADC0872, segment: 8\n",
      "Training for channel: CADC0872, segment: 9\n",
      "End Train for channel: CADC0872, segment: 9\n",
      "Training for channel: CADC0872, segment: 10\n",
      "End Train for channel: CADC0872, segment: 10\n",
      "Training for channel: CADC0872, segment: 11\n",
      "End Train for channel: CADC0872, segment: 11\n",
      "Training for channel: CADC0872, segment: 14\n",
      "End Train for channel: CADC0872, segment: 14\n",
      "Training for channel: CADC0872, segment: 15\n",
      "End Train for channel: CADC0872, segment: 15\n",
      "Training for channel: CADC0872, segment: 16\n",
      "End Train for channel: CADC0872, segment: 16\n",
      "Training for channel: CADC0872, segment: 17\n",
      "End Train for channel: CADC0872, segment: 17\n",
      "Training for channel: CADC0872, segment: 19\n",
      "End Train for channel: CADC0872, segment: 19\n",
      "Training for channel: CADC0872, segment: 22\n",
      "End Train for channel: CADC0872, segment: 22\n",
      "Training for channel: CADC0872, segment: 23\n",
      "End Train for channel: CADC0872, segment: 23\n",
      "Training for channel: CADC0872, segment: 24\n",
      "End Train for channel: CADC0872, segment: 24\n",
      "Training for channel: CADC0872, segment: 25\n",
      "End Train for channel: CADC0872, segment: 25\n",
      "Training for channel: CADC0872, segment: 26\n",
      "End Train for channel: CADC0872, segment: 26\n",
      "Training for channel: CADC0872, segment: 27\n",
      "End Train for channel: CADC0872, segment: 27\n",
      "Training for channel: CADC0872, segment: 29\n",
      "End Train for channel: CADC0872, segment: 29\n",
      "Training for channel: CADC0872, segment: 32\n",
      "End Train for channel: CADC0872, segment: 32\n",
      "Training for channel: CADC0872, segment: 33\n",
      "End Train for channel: CADC0872, segment: 33\n",
      "Training for channel: CADC0872, segment: 34\n",
      "End Train for channel: CADC0872, segment: 34\n",
      "Training for channel: CADC0872, segment: 36\n",
      "End Train for channel: CADC0872, segment: 36\n",
      "Training for channel: CADC0872, segment: 37\n",
      "End Train for channel: CADC0872, segment: 37\n",
      "Training for channel: CADC0872, segment: 38\n",
      "End Train for channel: CADC0872, segment: 38\n",
      "Training for channel: CADC0872, segment: 39\n",
      "End Train for channel: CADC0872, segment: 39\n",
      "Training for channel: CADC0872, segment: 40\n",
      "End Train for channel: CADC0872, segment: 40\n",
      "Training for channel: CADC0872, segment: 41\n",
      "End Train for channel: CADC0872, segment: 41\n",
      "Training for channel: CADC0872, segment: 44\n",
      "End Train for channel: CADC0872, segment: 44\n",
      "Training for channel: CADC0872, segment: 45\n",
      "End Train for channel: CADC0872, segment: 45\n",
      "Training for channel: CADC0872, segment: 46\n",
      "End Train for channel: CADC0872, segment: 46\n",
      "Training for channel: CADC0872, segment: 47\n",
      "End Train for channel: CADC0872, segment: 47\n",
      "Training for channel: CADC0872, segment: 48\n",
      "End Train for channel: CADC0872, segment: 48\n",
      "Training for channel: CADC0872, segment: 49\n",
      "End Train for channel: CADC0872, segment: 49\n",
      "Training for channel: CADC0872, segment: 51\n",
      "End Train for channel: CADC0872, segment: 51\n",
      "Training for channel: CADC0872, segment: 52\n",
      "End Train for channel: CADC0872, segment: 52\n",
      "Training for channel: CADC0872, segment: 53\n",
      "End Train for channel: CADC0872, segment: 53\n",
      "Training for channel: CADC0872, segment: 55\n",
      "End Train for channel: CADC0872, segment: 55\n",
      "Training for channel: CADC0872, segment: 56\n",
      "End Train for channel: CADC0872, segment: 56\n",
      "Training for channel: CADC0872, segment: 57\n",
      "End Train for channel: CADC0872, segment: 57\n",
      "Training for channel: CADC0872, segment: 58\n",
      "End Train for channel: CADC0872, segment: 58\n",
      "Training for channel: CADC0872, segment: 59\n",
      "End Train for channel: CADC0872, segment: 59\n",
      "Training for channel: CADC0872, segment: 60\n",
      "End Train for channel: CADC0872, segment: 60\n",
      "Training for channel: CADC0872, segment: 62\n",
      "End Train for channel: CADC0872, segment: 62\n",
      "Training for channel: CADC0872, segment: 65\n",
      "End Train for channel: CADC0872, segment: 65\n",
      "Training for channel: CADC0872, segment: 67\n",
      "End Train for channel: CADC0872, segment: 67\n",
      "Training for channel: CADC0872, segment: 68\n",
      "End Train for channel: CADC0872, segment: 68\n",
      "Training for channel: CADC0872, segment: 69\n",
      "End Train for channel: CADC0872, segment: 69\n",
      "Training for channel: CADC0872, segment: 70\n",
      "End Train for channel: CADC0872, segment: 70\n",
      "Training for channel: CADC0872, segment: 71\n",
      "End Train for channel: CADC0872, segment: 71\n",
      "Training for channel: CADC0872, segment: 73\n",
      "End Train for channel: CADC0872, segment: 73\n",
      "Training for channel: CADC0872, segment: 74\n",
      "End Train for channel: CADC0872, segment: 74\n",
      "Training for channel: CADC0872, segment: 76\n",
      "End Train for channel: CADC0872, segment: 76\n",
      "Training for channel: CADC0872, segment: 77\n",
      "End Train for channel: CADC0872, segment: 77\n",
      "Training for channel: CADC0872, segment: 78\n",
      "End Train for channel: CADC0872, segment: 78\n",
      "Training for channel: CADC0872, segment: 79\n",
      "End Train for channel: CADC0872, segment: 79\n",
      "Training for channel: CADC0872, segment: 80\n",
      "End Train for channel: CADC0872, segment: 80\n",
      "Training for channel: CADC0872, segment: 82\n",
      "End Train for channel: CADC0872, segment: 82\n",
      "Training for channel: CADC0872, segment: 83\n",
      "End Train for channel: CADC0872, segment: 83\n",
      "Training for channel: CADC0872, segment: 84\n",
      "End Train for channel: CADC0872, segment: 84\n",
      "Training for channel: CADC0872, segment: 85\n",
      "End Train for channel: CADC0872, segment: 85\n",
      "Training for channel: CADC0872, segment: 88\n",
      "End Train for channel: CADC0872, segment: 88\n",
      "Training for channel: CADC0872, segment: 89\n",
      "End Train for channel: CADC0872, segment: 89\n",
      "Training for channel: CADC0872, segment: 90\n",
      "End Train for channel: CADC0872, segment: 90\n",
      "Training for channel: CADC0872, segment: 92\n",
      "End Train for channel: CADC0872, segment: 92\n",
      "Training for channel: CADC0872, segment: 93\n",
      "End Train for channel: CADC0872, segment: 93\n",
      "Training for channel: CADC0872, segment: 95\n",
      "End Train for channel: CADC0872, segment: 95\n",
      "Training for channel: CADC0872, segment: 96\n",
      "End Train for channel: CADC0872, segment: 96\n",
      "Training for channel: CADC0872, segment: 97\n",
      "End Train for channel: CADC0872, segment: 97\n",
      "Training for channel: CADC0872, segment: 98\n",
      "End Train for channel: CADC0872, segment: 98\n",
      "Training for channel: CADC0872, segment: 99\n",
      "End Train for channel: CADC0872, segment: 99\n",
      "Training for channel: CADC0872, segment: 100\n",
      "End Train for channel: CADC0872, segment: 100\n",
      "Training for channel: CADC0872, segment: 101\n",
      "End Train for channel: CADC0872, segment: 101\n",
      "Training for channel: CADC0872, segment: 102\n",
      "End Train for channel: CADC0872, segment: 102\n",
      "Training for channel: CADC0872, segment: 105\n",
      "End Train for channel: CADC0872, segment: 105\n",
      "Training for channel: CADC0872, segment: 106\n",
      "End Train for channel: CADC0872, segment: 106\n",
      "Training for channel: CADC0872, segment: 107\n",
      "End Train for channel: CADC0872, segment: 107\n",
      "Training for channel: CADC0872, segment: 109\n",
      "End Train for channel: CADC0872, segment: 109\n",
      "Training for channel: CADC0872, segment: 111\n",
      "End Train for channel: CADC0872, segment: 111\n",
      "Training for channel: CADC0872, segment: 113\n",
      "End Train for channel: CADC0872, segment: 113\n",
      "Training for channel: CADC0872, segment: 116\n",
      "End Train for channel: CADC0872, segment: 116\n",
      "Training for channel: CADC0872, segment: 117\n",
      "End Train for channel: CADC0872, segment: 117\n",
      "Training for channel: CADC0872, segment: 118\n",
      "End Train for channel: CADC0872, segment: 118\n",
      "Training for channel: CADC0872, segment: 121\n",
      "End Train for channel: CADC0872, segment: 121\n",
      "Training for channel: CADC0872, segment: 122\n",
      "End Train for channel: CADC0872, segment: 122\n",
      "Training for channel: CADC0872, segment: 123\n",
      "End Train for channel: CADC0872, segment: 123\n",
      "Training for channel: CADC0872, segment: 124\n",
      "End Train for channel: CADC0872, segment: 124\n",
      "Training for channel: CADC0872, segment: 125\n",
      "End Train for channel: CADC0872, segment: 125\n",
      "Training for channel: CADC0872, segment: 126\n",
      "End Train for channel: CADC0872, segment: 126\n",
      "Training for channel: CADC0872, segment: 127\n",
      "End Train for channel: CADC0872, segment: 127\n",
      "Training for channel: CADC0872, segment: 128\n",
      "End Train for channel: CADC0872, segment: 128\n",
      "Training for channel: CADC0872, segment: 129\n",
      "End Train for channel: CADC0872, segment: 129\n",
      "Training for channel: CADC0872, segment: 130\n",
      "End Train for channel: CADC0872, segment: 130\n",
      "Training for channel: CADC0872, segment: 133\n",
      "End Train for channel: CADC0872, segment: 133\n",
      "Training for channel: CADC0872, segment: 134\n",
      "End Train for channel: CADC0872, segment: 134\n",
      "Training for channel: CADC0872, segment: 135\n",
      "End Train for channel: CADC0872, segment: 135\n",
      "Training for channel: CADC0872, segment: 136\n",
      "End Train for channel: CADC0872, segment: 136\n",
      "Training for channel: CADC0872, segment: 137\n",
      "End Train for channel: CADC0872, segment: 137\n",
      "Training for channel: CADC0872, segment: 138\n",
      "End Train for channel: CADC0872, segment: 138\n",
      "Training for channel: CADC0872, segment: 139\n",
      "End Train for channel: CADC0872, segment: 139\n",
      "Training for channel: CADC0872, segment: 140\n",
      "End Train for channel: CADC0872, segment: 140\n",
      "Training for channel: CADC0872, segment: 141\n",
      "End Train for channel: CADC0872, segment: 141\n",
      "Training for channel: CADC0872, segment: 143\n",
      "End Train for channel: CADC0872, segment: 143\n",
      "Training for channel: CADC0872, segment: 144\n",
      "End Train for channel: CADC0872, segment: 144\n",
      "Training for channel: CADC0872, segment: 145\n",
      "End Train for channel: CADC0872, segment: 145\n",
      "Training for channel: CADC0872, segment: 146\n",
      "End Train for channel: CADC0872, segment: 146\n",
      "Training for channel: CADC0872, segment: 149\n",
      "End Train for channel: CADC0872, segment: 149\n",
      "Training for channel: CADC0872, segment: 150\n",
      "End Train for channel: CADC0872, segment: 150\n",
      "Training for channel: CADC0872, segment: 151\n",
      "End Train for channel: CADC0872, segment: 151\n",
      "Training for channel: CADC0872, segment: 152\n",
      "End Train for channel: CADC0872, segment: 152\n",
      "Training for channel: CADC0872, segment: 153\n",
      "End Train for channel: CADC0872, segment: 153\n",
      "Training for channel: CADC0872, segment: 154\n",
      "End Train for channel: CADC0872, segment: 154\n",
      "Training for channel: CADC0872, segment: 156\n",
      "End Train for channel: CADC0872, segment: 156\n",
      "Training for channel: CADC0872, segment: 157\n",
      "End Train for channel: CADC0872, segment: 157\n",
      "Training for channel: CADC0872, segment: 158\n",
      "End Train for channel: CADC0872, segment: 158\n",
      "Training for channel: CADC0872, segment: 159\n",
      "End Train for channel: CADC0872, segment: 159\n",
      "Training for channel: CADC0872, segment: 160\n",
      "End Train for channel: CADC0872, segment: 160\n",
      "Training for channel: CADC0872, segment: 161\n",
      "End Train for channel: CADC0872, segment: 161\n",
      "Training for channel: CADC0872, segment: 162\n",
      "End Train for channel: CADC0872, segment: 162\n",
      "Training for channel: CADC0872, segment: 163\n",
      "End Train for channel: CADC0872, segment: 163\n",
      "Training for channel: CADC0872, segment: 164\n",
      "End Train for channel: CADC0872, segment: 164\n",
      "Training for channel: CADC0872, segment: 165\n",
      "End Train for channel: CADC0872, segment: 165\n",
      "Training for channel: CADC0872, segment: 166\n",
      "End Train for channel: CADC0872, segment: 166\n",
      "Training for channel: CADC0872, segment: 168\n",
      "End Train for channel: CADC0872, segment: 168\n",
      "Training for channel: CADC0872, segment: 169\n",
      "End Train for channel: CADC0872, segment: 169\n",
      "Training for channel: CADC0872, segment: 170\n",
      "End Train for channel: CADC0872, segment: 170\n",
      "Training for channel: CADC0872, segment: 171\n",
      "End Train for channel: CADC0872, segment: 171\n",
      "Training for channel: CADC0872, segment: 172\n",
      "End Train for channel: CADC0872, segment: 172\n",
      "Training for channel: CADC0872, segment: 173\n",
      "End Train for channel: CADC0872, segment: 173\n",
      "Training for channel: CADC0872, segment: 174\n",
      "End Train for channel: CADC0872, segment: 174\n",
      "Training for channel: CADC0872, segment: 175\n",
      "End Train for channel: CADC0872, segment: 175\n",
      "Training for channel: CADC0872, segment: 176\n",
      "End Train for channel: CADC0872, segment: 176\n",
      "Training for channel: CADC0872, segment: 177\n",
      "End Train for channel: CADC0872, segment: 177\n",
      "Training for channel: CADC0872, segment: 178\n",
      "End Train for channel: CADC0872, segment: 178\n",
      "Training for channel: CADC0872, segment: 179\n",
      "End Train for channel: CADC0872, segment: 179\n",
      "Training for channel: CADC0872, segment: 180\n",
      "End Train for channel: CADC0872, segment: 180\n",
      "Training for channel: CADC0872, segment: 181\n",
      "End Train for channel: CADC0872, segment: 181\n",
      "Training for channel: CADC0872, segment: 183\n",
      "End Train for channel: CADC0872, segment: 183\n",
      "Training for channel: CADC0872, segment: 185\n",
      "End Train for channel: CADC0872, segment: 185\n",
      "Training for channel: CADC0872, segment: 186\n",
      "End Train for channel: CADC0872, segment: 186\n",
      "Training for channel: CADC0872, segment: 187\n",
      "End Train for channel: CADC0872, segment: 187\n",
      "Training for channel: CADC0872, segment: 188\n",
      "End Train for channel: CADC0872, segment: 188\n",
      "Training for channel: CADC0872, segment: 191\n",
      "End Train for channel: CADC0872, segment: 191\n",
      "Training for channel: CADC0872, segment: 192\n",
      "End Train for channel: CADC0872, segment: 192\n",
      "Training for channel: CADC0872, segment: 193\n",
      "End Train for channel: CADC0872, segment: 193\n",
      "Training for channel: CADC0872, segment: 194\n",
      "End Train for channel: CADC0872, segment: 194\n",
      "Training for channel: CADC0872, segment: 195\n",
      "End Train for channel: CADC0872, segment: 195\n",
      "Training for channel: CADC0872, segment: 196\n",
      "End Train for channel: CADC0872, segment: 196\n",
      "Training for channel: CADC0872, segment: 197\n",
      "End Train for channel: CADC0872, segment: 197\n",
      "Training for channel: CADC0872, segment: 199\n",
      "End Train for channel: CADC0872, segment: 199\n",
      "Training for channel: CADC0872, segment: 200\n",
      "End Train for channel: CADC0872, segment: 200\n",
      "Training for channel: CADC0872, segment: 201\n",
      "End Train for channel: CADC0872, segment: 201\n",
      "Training for channel: CADC0872, segment: 202\n",
      "End Train for channel: CADC0872, segment: 202\n",
      "Training for channel: CADC0872, segment: 203\n",
      "End Train for channel: CADC0872, segment: 203\n",
      "Training for channel: CADC0872, segment: 205\n",
      "End Train for channel: CADC0872, segment: 205\n",
      "Training for channel: CADC0872, segment: 207\n",
      "End Train for channel: CADC0872, segment: 207\n",
      "Training for channel: CADC0872, segment: 208\n",
      "End Train for channel: CADC0872, segment: 208\n",
      "Training for channel: CADC0872, segment: 210\n",
      "End Train for channel: CADC0872, segment: 210\n",
      "Training for channel: CADC0872, segment: 211\n",
      "End Train for channel: CADC0872, segment: 211\n",
      "Training for channel: CADC0872, segment: 212\n",
      "End Train for channel: CADC0872, segment: 212\n",
      "Training for channel: CADC0872, segment: 213\n",
      "End Train for channel: CADC0872, segment: 213\n",
      "Training for channel: CADC0872, segment: 214\n",
      "End Train for channel: CADC0872, segment: 214\n",
      "Training for channel: CADC0872, segment: 215\n",
      "End Train for channel: CADC0872, segment: 215\n",
      "Training for channel: CADC0872, segment: 216\n",
      "End Train for channel: CADC0872, segment: 216\n",
      "Training for channel: CADC0872, segment: 217\n",
      "End Train for channel: CADC0872, segment: 217\n",
      "Training for channel: CADC0872, segment: 1796\n",
      "End Train for channel: CADC0872, segment: 1796\n",
      "Training for channel: CADC0872, segment: 1797\n",
      "End Train for channel: CADC0872, segment: 1797\n",
      "Training for channel: CADC0872, segment: 1798\n",
      "End Train for channel: CADC0872, segment: 1798\n",
      "Training for channel: CADC0872, segment: 1799\n",
      "End Train for channel: CADC0872, segment: 1799\n",
      "Training for channel: CADC0872, segment: 1800\n",
      "End Train for channel: CADC0872, segment: 1800\n",
      "Training for channel: CADC0872, segment: 1801\n",
      "End Train for channel: CADC0872, segment: 1801\n",
      "Training for channel: CADC0872, segment: 1802\n",
      "End Train for channel: CADC0872, segment: 1802\n",
      "Training for channel: CADC0872, segment: 1804\n",
      "End Train for channel: CADC0872, segment: 1804\n",
      "Training for channel: CADC0872, segment: 1806\n",
      "End Train for channel: CADC0872, segment: 1806\n",
      "Training for channel: CADC0872, segment: 1807\n",
      "End Train for channel: CADC0872, segment: 1807\n",
      "Training for channel: CADC0872, segment: 1808\n",
      "End Train for channel: CADC0872, segment: 1808\n",
      "Training for channel: CADC0872, segment: 1809\n",
      "End Train for channel: CADC0872, segment: 1809\n",
      "Training for channel: CADC0872, segment: 1810\n",
      "End Train for channel: CADC0872, segment: 1810\n",
      "Training for channel: CADC0872, segment: 1811\n",
      "End Train for channel: CADC0872, segment: 1811\n",
      "Training for channel: CADC0872, segment: 1813\n",
      "End Train for channel: CADC0872, segment: 1813\n",
      "Training for channel: CADC0872, segment: 1814\n",
      "End Train for channel: CADC0872, segment: 1814\n",
      "Training for channel: CADC0872, segment: 1815\n",
      "End Train for channel: CADC0872, segment: 1815\n",
      "Training for channel: CADC0872, segment: 1817\n",
      "End Train for channel: CADC0872, segment: 1817\n",
      "Training for channel: CADC0872, segment: 1818\n",
      "End Train for channel: CADC0872, segment: 1818\n",
      "Training for channel: CADC0872, segment: 1819\n",
      "End Train for channel: CADC0872, segment: 1819\n",
      "Training for channel: CADC0872, segment: 1823\n",
      "End Train for channel: CADC0872, segment: 1823\n",
      "Training for channel: CADC0872, segment: 1824\n",
      "End Train for channel: CADC0872, segment: 1824\n",
      "Training for channel: CADC0872, segment: 1825\n",
      "End Train for channel: CADC0872, segment: 1825\n",
      "Training for channel: CADC0872, segment: 1826\n",
      "End Train for channel: CADC0872, segment: 1826\n",
      "Training for channel: CADC0872, segment: 1827\n",
      "End Train for channel: CADC0872, segment: 1827\n",
      "Training for channel: CADC0872, segment: 1829\n",
      "End Train for channel: CADC0872, segment: 1829\n",
      "Training for channel: CADC0872, segment: 1831\n",
      "End Train for channel: CADC0872, segment: 1831\n",
      "Training for channel: CADC0872, segment: 1832\n",
      "End Train for channel: CADC0872, segment: 1832\n",
      "Training for channel: CADC0872, segment: 1834\n",
      "End Train for channel: CADC0872, segment: 1834\n",
      "Training for channel: CADC0872, segment: 1835\n",
      "End Train for channel: CADC0872, segment: 1835\n",
      "Training for channel: CADC0872, segment: 1836\n",
      "End Train for channel: CADC0872, segment: 1836\n",
      "Training for channel: CADC0872, segment: 1837\n",
      "End Train for channel: CADC0872, segment: 1837\n",
      "Training for channel: CADC0872, segment: 1838\n",
      "End Train for channel: CADC0872, segment: 1838\n",
      "Training for channel: CADC0872, segment: 1839\n",
      "End Train for channel: CADC0872, segment: 1839\n",
      "Training for channel: CADC0872, segment: 1840\n",
      "End Train for channel: CADC0872, segment: 1840\n",
      "Training for channel: CADC0872, segment: 1841\n",
      "End Train for channel: CADC0872, segment: 1841\n",
      "Training for channel: CADC0872, segment: 1843\n",
      "End Train for channel: CADC0872, segment: 1843\n",
      "Training for channel: CADC0872, segment: 1844\n",
      "End Train for channel: CADC0872, segment: 1844\n",
      "Training for channel: CADC0872, segment: 1845\n",
      "End Train for channel: CADC0872, segment: 1845\n",
      "Training for channel: CADC0872, segment: 1846\n",
      "End Train for channel: CADC0872, segment: 1846\n",
      "Training for channel: CADC0872, segment: 1847\n",
      "End Train for channel: CADC0872, segment: 1847\n",
      "Training for channel: CADC0872, segment: 1849\n",
      "End Train for channel: CADC0872, segment: 1849\n",
      "Training for channel: CADC0872, segment: 1850\n",
      "End Train for channel: CADC0872, segment: 1850\n",
      "Training for channel: CADC0872, segment: 1851\n",
      "End Train for channel: CADC0872, segment: 1851\n",
      "Training for channel: CADC0872, segment: 1852\n",
      "End Train for channel: CADC0872, segment: 1852\n",
      "Training for channel: CADC0872, segment: 1854\n",
      "End Train for channel: CADC0872, segment: 1854\n",
      "Training for channel: CADC0872, segment: 1855\n",
      "End Train for channel: CADC0872, segment: 1855\n",
      "Training for channel: CADC0872, segment: 1857\n",
      "End Train for channel: CADC0872, segment: 1857\n",
      "Training for channel: CADC0872, segment: 1859\n",
      "End Train for channel: CADC0872, segment: 1859\n",
      "Training for channel: CADC0872, segment: 1861\n",
      "End Train for channel: CADC0872, segment: 1861\n",
      "Training for channel: CADC0872, segment: 1862\n",
      "End Train for channel: CADC0872, segment: 1862\n",
      "Training for channel: CADC0872, segment: 1863\n",
      "End Train for channel: CADC0872, segment: 1863\n",
      "Training for channel: CADC0872, segment: 1864\n",
      "End Train for channel: CADC0872, segment: 1864\n",
      "Training for channel: CADC0872, segment: 1865\n",
      "End Train for channel: CADC0872, segment: 1865\n",
      "Training for channel: CADC0872, segment: 1866\n",
      "End Train for channel: CADC0872, segment: 1866\n",
      "Training for channel: CADC0872, segment: 1870\n",
      "End Train for channel: CADC0872, segment: 1870\n",
      "Training for channel: CADC0872, segment: 1871\n",
      "End Train for channel: CADC0872, segment: 1871\n",
      "Training for channel: CADC0872, segment: 1873\n",
      "End Train for channel: CADC0872, segment: 1873\n",
      "Training for channel: CADC0872, segment: 1874\n",
      "End Train for channel: CADC0872, segment: 1874\n",
      "Training for channel: CADC0872, segment: 1875\n",
      "End Train for channel: CADC0872, segment: 1875\n",
      "Training for channel: CADC0872, segment: 1876\n",
      "End Train for channel: CADC0872, segment: 1876\n",
      "Training for channel: CADC0872, segment: 1877\n",
      "End Train for channel: CADC0872, segment: 1877\n",
      "Training for channel: CADC0872, segment: 1878\n",
      "End Train for channel: CADC0872, segment: 1878\n",
      "Training for channel: CADC0872, segment: 1879\n",
      "End Train for channel: CADC0872, segment: 1879\n",
      "Training for channel: CADC0872, segment: 1880\n",
      "End Train for channel: CADC0872, segment: 1880\n",
      "Training for channel: CADC0872, segment: 1881\n",
      "End Train for channel: CADC0872, segment: 1881\n",
      "Training for channel: CADC0872, segment: 1882\n",
      "End Train for channel: CADC0872, segment: 1882\n",
      "Training for channel: CADC0872, segment: 1883\n",
      "End Train for channel: CADC0872, segment: 1883\n",
      "Training for channel: CADC0872, segment: 1884\n",
      "End Train for channel: CADC0872, segment: 1884\n",
      "Training for channel: CADC0872, segment: 1885\n",
      "End Train for channel: CADC0872, segment: 1885\n",
      "Training for channel: CADC0872, segment: 1886\n",
      "End Train for channel: CADC0872, segment: 1886\n",
      "Training for channel: CADC0872, segment: 1887\n",
      "End Train for channel: CADC0872, segment: 1887\n",
      "Training for channel: CADC0872, segment: 1888\n",
      "End Train for channel: CADC0872, segment: 1888\n",
      "Training for channel: CADC0872, segment: 1889\n",
      "End Train for channel: CADC0872, segment: 1889\n",
      "Training for channel: CADC0872, segment: 1891\n",
      "End Train for channel: CADC0872, segment: 1891\n",
      "Training for channel: CADC0872, segment: 1894\n",
      "End Train for channel: CADC0872, segment: 1894\n",
      "Training for channel: CADC0872, segment: 1896\n",
      "End Train for channel: CADC0872, segment: 1896\n",
      "Training for channel: CADC0872, segment: 1897\n",
      "End Train for channel: CADC0872, segment: 1897\n",
      "Training for channel: CADC0872, segment: 1898\n",
      "End Train for channel: CADC0872, segment: 1898\n",
      "Training for channel: CADC0872, segment: 1899\n",
      "End Train for channel: CADC0872, segment: 1899\n",
      "Training for channel: CADC0872, segment: 1900\n",
      "End Train for channel: CADC0872, segment: 1900\n",
      "Training for channel: CADC0872, segment: 1901\n",
      "End Train for channel: CADC0872, segment: 1901\n",
      "Training for channel: CADC0872, segment: 1902\n",
      "End Train for channel: CADC0872, segment: 1902\n",
      "Training for channel: CADC0872, segment: 1903\n",
      "End Train for channel: CADC0872, segment: 1903\n",
      "Training for channel: CADC0872, segment: 1905\n",
      "End Train for channel: CADC0872, segment: 1905\n",
      "Training for channel: CADC0872, segment: 1907\n",
      "End Train for channel: CADC0872, segment: 1907\n",
      "Training for channel: CADC0872, segment: 1908\n",
      "End Train for channel: CADC0872, segment: 1908\n",
      "Training for channel: CADC0872, segment: 1909\n",
      "End Train for channel: CADC0872, segment: 1909\n",
      "Training for channel: CADC0872, segment: 1910\n",
      "End Train for channel: CADC0872, segment: 1910\n",
      "Training for channel: CADC0872, segment: 1911\n",
      "End Train for channel: CADC0872, segment: 1911\n",
      "Training for channel: CADC0872, segment: 1912\n",
      "End Train for channel: CADC0872, segment: 1912\n",
      "Training for channel: CADC0872, segment: 1916\n",
      "End Train for channel: CADC0872, segment: 1916\n",
      "Training for channel: CADC0872, segment: 1919\n",
      "End Train for channel: CADC0872, segment: 1919\n",
      "Training for channel: CADC0872, segment: 1920\n",
      "End Train for channel: CADC0872, segment: 1920\n",
      "Training for channel: CADC0872, segment: 1922\n",
      "End Train for channel: CADC0872, segment: 1922\n",
      "Training for channel: CADC0872, segment: 1924\n",
      "End Train for channel: CADC0872, segment: 1924\n",
      "Training for channel: CADC0872, segment: 1925\n",
      "End Train for channel: CADC0872, segment: 1925\n",
      "Training for channel: CADC0872, segment: 1926\n",
      "End Train for channel: CADC0872, segment: 1926\n",
      "Training for channel: CADC0872, segment: 1927\n",
      "End Train for channel: CADC0872, segment: 1927\n",
      "Training for channel: CADC0872, segment: 1928\n",
      "End Train for channel: CADC0872, segment: 1928\n",
      "Training for channel: CADC0872, segment: 1930\n",
      "End Train for channel: CADC0872, segment: 1930\n",
      "Training for channel: CADC0872, segment: 1931\n",
      "End Train for channel: CADC0872, segment: 1931\n",
      "Training for channel: CADC0872, segment: 1932\n",
      "End Train for channel: CADC0872, segment: 1932\n",
      "Training for channel: CADC0872, segment: 1933\n",
      "End Train for channel: CADC0872, segment: 1933\n",
      "Training for channel: CADC0872, segment: 1934\n",
      "End Train for channel: CADC0872, segment: 1934\n",
      "Training for channel: CADC0872, segment: 1935\n",
      "End Train for channel: CADC0872, segment: 1935\n",
      "Training for channel: CADC0872, segment: 1936\n",
      "End Train for channel: CADC0872, segment: 1936\n",
      "Training for channel: CADC0872, segment: 1937\n",
      "End Train for channel: CADC0872, segment: 1937\n",
      "Training for channel: CADC0872, segment: 1939\n",
      "End Train for channel: CADC0872, segment: 1939\n",
      "Training for channel: CADC0872, segment: 1940\n",
      "End Train for channel: CADC0872, segment: 1940\n",
      "Training for channel: CADC0872, segment: 1941\n",
      "End Train for channel: CADC0872, segment: 1941\n",
      "Training for channel: CADC0872, segment: 1942\n",
      "End Train for channel: CADC0872, segment: 1942\n",
      "Training for channel: CADC0872, segment: 1943\n",
      "End Train for channel: CADC0872, segment: 1943\n",
      "Training for channel: CADC0872, segment: 1944\n",
      "End Train for channel: CADC0872, segment: 1944\n",
      "Training for channel: CADC0872, segment: 1945\n",
      "End Train for channel: CADC0872, segment: 1945\n",
      "Training for channel: CADC0872, segment: 1946\n",
      "End Train for channel: CADC0872, segment: 1946\n",
      "Training for channel: CADC0872, segment: 1947\n",
      "End Train for channel: CADC0872, segment: 1947\n",
      "Training for channel: CADC0872, segment: 1948\n",
      "End Train for channel: CADC0872, segment: 1948\n",
      "Training for channel: CADC0872, segment: 1950\n",
      "End Train for channel: CADC0872, segment: 1950\n",
      "Training for channel: CADC0872, segment: 1951\n",
      "End Train for channel: CADC0872, segment: 1951\n",
      "Training for channel: CADC0872, segment: 1952\n",
      "End Train for channel: CADC0872, segment: 1952\n",
      "Training for channel: CADC0872, segment: 1958\n",
      "End Train for channel: CADC0872, segment: 1958\n",
      "Training for channel: CADC0872, segment: 1959\n",
      "End Train for channel: CADC0872, segment: 1959\n",
      "Training for channel: CADC0872, segment: 1961\n",
      "End Train for channel: CADC0872, segment: 1961\n",
      "Training for channel: CADC0872, segment: 1963\n",
      "End Train for channel: CADC0872, segment: 1963\n",
      "Training for channel: CADC0872, segment: 1965\n",
      "End Train for channel: CADC0872, segment: 1965\n",
      "Training for channel: CADC0872, segment: 1966\n",
      "End Train for channel: CADC0872, segment: 1966\n",
      "Training for channel: CADC0872, segment: 1969\n",
      "End Train for channel: CADC0872, segment: 1969\n",
      "Training for channel: CADC0872, segment: 1970\n",
      "End Train for channel: CADC0872, segment: 1970\n",
      "Training for channel: CADC0872, segment: 1971\n",
      "End Train for channel: CADC0872, segment: 1971\n",
      "Training for channel: CADC0872, segment: 1972\n",
      "End Train for channel: CADC0872, segment: 1972\n",
      "Training for channel: CADC0872, segment: 1974\n",
      "End Train for channel: CADC0872, segment: 1974\n",
      "Training for channel: CADC0872, segment: 1976\n",
      "End Train for channel: CADC0872, segment: 1976\n",
      "Training for channel: CADC0872, segment: 1977\n",
      "End Train for channel: CADC0872, segment: 1977\n",
      "Training for channel: CADC0872, segment: 1978\n",
      "End Train for channel: CADC0872, segment: 1978\n",
      "Training for channel: CADC0872, segment: 1979\n",
      "End Train for channel: CADC0872, segment: 1979\n",
      "Training for channel: CADC0872, segment: 1980\n",
      "End Train for channel: CADC0872, segment: 1980\n",
      "Training for channel: CADC0872, segment: 1981\n",
      "End Train for channel: CADC0872, segment: 1981\n",
      "Training for channel: CADC0872, segment: 1982\n",
      "End Train for channel: CADC0872, segment: 1982\n",
      "Training for channel: CADC0872, segment: 1983\n",
      "End Train for channel: CADC0872, segment: 1983\n",
      "Training for channel: CADC0872, segment: 1984\n",
      "End Train for channel: CADC0872, segment: 1984\n",
      "Training for channel: CADC0872, segment: 1985\n",
      "End Train for channel: CADC0872, segment: 1985\n",
      "Training for channel: CADC0872, segment: 1987\n",
      "End Train for channel: CADC0872, segment: 1987\n",
      "Training for channel: CADC0872, segment: 1989\n",
      "End Train for channel: CADC0872, segment: 1989\n",
      "Training for channel: CADC0872, segment: 1991\n",
      "End Train for channel: CADC0872, segment: 1991\n",
      "Training for channel: CADC0872, segment: 1992\n",
      "End Train for channel: CADC0872, segment: 1992\n",
      "Training for channel: CADC0872, segment: 1993\n",
      "End Train for channel: CADC0872, segment: 1993\n",
      "Training for channel: CADC0872, segment: 1994\n",
      "End Train for channel: CADC0872, segment: 1994\n",
      "Training for channel: CADC0872, segment: 1995\n",
      "End Train for channel: CADC0872, segment: 1995\n",
      "Training for channel: CADC0872, segment: 1997\n",
      "End Train for channel: CADC0872, segment: 1997\n",
      "Training for channel: CADC0872, segment: 1998\n",
      "End Train for channel: CADC0872, segment: 1998\n",
      "Training for channel: CADC0872, segment: 2000\n",
      "End Train for channel: CADC0872, segment: 2000\n",
      "Training for channel: CADC0872, segment: 2001\n",
      "End Train for channel: CADC0872, segment: 2001\n",
      "Training for channel: CADC0872, segment: 2002\n",
      "End Train for channel: CADC0872, segment: 2002\n",
      "Training for channel: CADC0872, segment: 2003\n",
      "End Train for channel: CADC0872, segment: 2003\n",
      "Training for channel: CADC0872, segment: 2004\n",
      "End Train for channel: CADC0872, segment: 2004\n",
      "Training for channel: CADC0872, segment: 2005\n",
      "End Train for channel: CADC0872, segment: 2005\n",
      "Training for channel: CADC0872, segment: 2006\n",
      "End Train for channel: CADC0872, segment: 2006\n",
      "Training for channel: CADC0872, segment: 2007\n",
      "End Train for channel: CADC0872, segment: 2007\n",
      "Training for channel: CADC0872, segment: 2008\n",
      "End Train for channel: CADC0872, segment: 2008\n",
      "Training for channel: CADC0872, segment: 2009\n",
      "End Train for channel: CADC0872, segment: 2009\n",
      "Training for channel: CADC0872, segment: 2010\n",
      "End Train for channel: CADC0872, segment: 2010\n",
      "Training for channel: CADC0872, segment: 2011\n",
      "End Train for channel: CADC0872, segment: 2011\n",
      "Training for channel: CADC0872, segment: 2012\n",
      "End Train for channel: CADC0872, segment: 2012\n",
      "Training for channel: CADC0872, segment: 2013\n",
      "End Train for channel: CADC0872, segment: 2013\n",
      "Training for channel: CADC0872, segment: 2014\n",
      "End Train for channel: CADC0872, segment: 2014\n",
      "Training for channel: CADC0872, segment: 2015\n",
      "End Train for channel: CADC0872, segment: 2015\n",
      "Training for channel: CADC0872, segment: 2016\n",
      "End Train for channel: CADC0872, segment: 2016\n",
      "Training for channel: CADC0872, segment: 2019\n",
      "End Train for channel: CADC0872, segment: 2019\n",
      "Training for channel: CADC0872, segment: 2020\n",
      "End Train for channel: CADC0872, segment: 2020\n",
      "Training for channel: CADC0872, segment: 2021\n",
      "End Train for channel: CADC0872, segment: 2021\n",
      "Training for channel: CADC0872, segment: 2022\n",
      "End Train for channel: CADC0872, segment: 2022\n",
      "Training for channel: CADC0872, segment: 2024\n",
      "End Train for channel: CADC0872, segment: 2024\n",
      "Training for channel: CADC0872, segment: 2025\n",
      "End Train for channel: CADC0872, segment: 2025\n",
      "Training for channel: CADC0872, segment: 2026\n",
      "End Train for channel: CADC0872, segment: 2026\n",
      "Training for channel: CADC0872, segment: 2027\n",
      "End Train for channel: CADC0872, segment: 2027\n",
      "Training for channel: CADC0872, segment: 2028\n",
      "End Train for channel: CADC0872, segment: 2028\n",
      "Training for channel: CADC0872, segment: 2029\n",
      "End Train for channel: CADC0872, segment: 2029\n",
      "Training for channel: CADC0872, segment: 2030\n",
      "End Train for channel: CADC0872, segment: 2030\n",
      "Training for channel: CADC0872, segment: 2031\n",
      "End Train for channel: CADC0872, segment: 2031\n",
      "Training for channel: CADC0872, segment: 2032\n",
      "End Train for channel: CADC0872, segment: 2032\n",
      "Training for channel: CADC0872, segment: 2033\n",
      "End Train for channel: CADC0872, segment: 2033\n",
      "Training for channel: CADC0872, segment: 2034\n",
      "End Train for channel: CADC0872, segment: 2034\n",
      "Training for channel: CADC0872, segment: 2035\n",
      "End Train for channel: CADC0872, segment: 2035\n",
      "Training for channel: CADC0872, segment: 2037\n",
      "End Train for channel: CADC0872, segment: 2037\n",
      "Training for channel: CADC0872, segment: 2038\n",
      "End Train for channel: CADC0872, segment: 2038\n",
      "Training for channel: CADC0872, segment: 2039\n",
      "End Train for channel: CADC0872, segment: 2039\n",
      "Training for channel: CADC0872, segment: 2043\n",
      "End Train for channel: CADC0872, segment: 2043\n",
      "Training for channel: CADC0872, segment: 2044\n",
      "End Train for channel: CADC0872, segment: 2044\n",
      "Training for channel: CADC0872, segment: 2045\n",
      "End Train for channel: CADC0872, segment: 2045\n",
      "Training for channel: CADC0872, segment: 2046\n",
      "End Train for channel: CADC0872, segment: 2046\n",
      "Training for channel: CADC0872, segment: 2047\n",
      "End Train for channel: CADC0872, segment: 2047\n",
      "Training for channel: CADC0872, segment: 2048\n",
      "End Train for channel: CADC0872, segment: 2048\n",
      "Training for channel: CADC0872, segment: 2049\n",
      "End Train for channel: CADC0872, segment: 2049\n",
      "Training for channel: CADC0872, segment: 2050\n",
      "End Train for channel: CADC0872, segment: 2050\n",
      "Training for channel: CADC0872, segment: 2051\n",
      "End Train for channel: CADC0872, segment: 2051\n",
      "Training for channel: CADC0872, segment: 2052\n",
      "End Train for channel: CADC0872, segment: 2052\n",
      "Training for channel: CADC0872, segment: 2053\n",
      "End Train for channel: CADC0872, segment: 2053\n",
      "Training for channel: CADC0872, segment: 2054\n",
      "End Train for channel: CADC0872, segment: 2054\n",
      "Training for channel: CADC0872, segment: 2055\n",
      "End Train for channel: CADC0872, segment: 2055\n",
      "Training for channel: CADC0872, segment: 2056\n",
      "End Train for channel: CADC0872, segment: 2056\n",
      "Training for channel: CADC0872, segment: 2057\n",
      "End Train for channel: CADC0872, segment: 2057\n",
      "Training for channel: CADC0872, segment: 2059\n",
      "End Train for channel: CADC0872, segment: 2059\n",
      "Training for channel: CADC0872, segment: 2060\n",
      "End Train for channel: CADC0872, segment: 2060\n",
      "Training for channel: CADC0872, segment: 2061\n",
      "End Train for channel: CADC0872, segment: 2061\n",
      "Training for channel: CADC0872, segment: 2062\n",
      "End Train for channel: CADC0872, segment: 2062\n",
      "Training for channel: CADC0872, segment: 2063\n",
      "End Train for channel: CADC0872, segment: 2063\n",
      "Training for channel: CADC0872, segment: 2064\n",
      "End Train for channel: CADC0872, segment: 2064\n",
      "Training for channel: CADC0872, segment: 2067\n",
      "End Train for channel: CADC0872, segment: 2067\n",
      "Training for channel: CADC0872, segment: 2069\n",
      "End Train for channel: CADC0872, segment: 2069\n",
      "Training for channel: CADC0872, segment: 2070\n",
      "End Train for channel: CADC0872, segment: 2070\n",
      "Training for channel: CADC0872, segment: 2071\n",
      "End Train for channel: CADC0872, segment: 2071\n",
      "Training for channel: CADC0872, segment: 2072\n",
      "End Train for channel: CADC0872, segment: 2072\n",
      "Training for channel: CADC0872, segment: 2073\n",
      "End Train for channel: CADC0872, segment: 2073\n",
      "Training for channel: CADC0872, segment: 2074\n",
      "End Train for channel: CADC0872, segment: 2074\n",
      "Training for channel: CADC0872, segment: 2075\n",
      "End Train for channel: CADC0872, segment: 2075\n",
      "Training for channel: CADC0872, segment: 2077\n",
      "End Train for channel: CADC0872, segment: 2077\n",
      "Training for channel: CADC0872, segment: 2078\n",
      "End Train for channel: CADC0872, segment: 2078\n",
      "Training for channel: CADC0872, segment: 2080\n",
      "End Train for channel: CADC0872, segment: 2080\n",
      "Training for channel: CADC0872, segment: 2082\n",
      "End Train for channel: CADC0872, segment: 2082\n",
      "Training for channel: CADC0872, segment: 2084\n",
      "End Train for channel: CADC0872, segment: 2084\n",
      "Training for channel: CADC0872, segment: 2086\n",
      "End Train for channel: CADC0872, segment: 2086\n",
      "Training for channel: CADC0872, segment: 2088\n",
      "End Train for channel: CADC0872, segment: 2088\n",
      "Training for channel: CADC0872, segment: 2091\n",
      "End Train for channel: CADC0872, segment: 2091\n",
      "Training for channel: CADC0872, segment: 2092\n",
      "End Train for channel: CADC0872, segment: 2092\n",
      "Training for channel: CADC0872, segment: 2093\n",
      "End Train for channel: CADC0872, segment: 2093\n",
      "Training for channel: CADC0872, segment: 2095\n",
      "End Train for channel: CADC0872, segment: 2095\n",
      "Training for channel: CADC0872, segment: 2096\n",
      "End Train for channel: CADC0872, segment: 2096\n",
      "Training for channel: CADC0872, segment: 2097\n",
      "End Train for channel: CADC0872, segment: 2097\n",
      "Training for channel: CADC0872, segment: 2098\n",
      "End Train for channel: CADC0872, segment: 2098\n",
      "Training for channel: CADC0872, segment: 2099\n",
      "End Train for channel: CADC0872, segment: 2099\n",
      "Training for channel: CADC0872, segment: 2100\n",
      "End Train for channel: CADC0872, segment: 2100\n",
      "Training for channel: CADC0872, segment: 2101\n",
      "End Train for channel: CADC0872, segment: 2101\n",
      "Training for channel: CADC0872, segment: 2102\n",
      "End Train for channel: CADC0872, segment: 2102\n",
      "Training for channel: CADC0872, segment: 2105\n",
      "End Train for channel: CADC0872, segment: 2105\n",
      "Training for channel: CADC0872, segment: 2106\n",
      "End Train for channel: CADC0872, segment: 2106\n",
      "Training for channel: CADC0872, segment: 2107\n",
      "End Train for channel: CADC0872, segment: 2107\n",
      "Training for channel: CADC0872, segment: 2110\n",
      "End Train for channel: CADC0872, segment: 2110\n",
      "Training for channel: CADC0872, segment: 2112\n",
      "End Train for channel: CADC0872, segment: 2112\n",
      "Training for channel: CADC0872, segment: 2113\n",
      "End Train for channel: CADC0872, segment: 2113\n",
      "Training for channel: CADC0872, segment: 2115\n",
      "End Train for channel: CADC0872, segment: 2115\n",
      "Training for channel: CADC0872, segment: 2117\n",
      "End Train for channel: CADC0872, segment: 2117\n",
      "Training for channel: CADC0872, segment: 2118\n",
      "End Train for channel: CADC0872, segment: 2118\n",
      "Training for channel: CADC0872, segment: 2120\n",
      "End Train for channel: CADC0872, segment: 2120\n",
      "Training for channel: CADC0872, segment: 2121\n",
      "End Train for channel: CADC0872, segment: 2121\n",
      "Training for channel: CADC0872, segment: 2122\n",
      "End Train for channel: CADC0872, segment: 2122\n",
      "Training for channel: CADC0872, segment: 2123\n",
      "End Train for channel: CADC0872, segment: 2123\n",
      "Training for channel: CADC0892, segment: 219\n",
      "End Train for channel: CADC0892, segment: 219\n",
      "Training for channel: CADC0892, segment: 220\n",
      "End Train for channel: CADC0892, segment: 220\n",
      "Training for channel: CADC0892, segment: 222\n",
      "End Train for channel: CADC0892, segment: 222\n",
      "Training for channel: CADC0892, segment: 223\n",
      "End Train for channel: CADC0892, segment: 223\n",
      "Training for channel: CADC0892, segment: 225\n",
      "End Train for channel: CADC0892, segment: 225\n",
      "Training for channel: CADC0892, segment: 227\n",
      "End Train for channel: CADC0892, segment: 227\n",
      "Training for channel: CADC0892, segment: 230\n",
      "End Train for channel: CADC0892, segment: 230\n",
      "Training for channel: CADC0892, segment: 231\n",
      "End Train for channel: CADC0892, segment: 231\n",
      "Training for channel: CADC0892, segment: 232\n",
      "End Train for channel: CADC0892, segment: 232\n",
      "Training for channel: CADC0892, segment: 233\n",
      "End Train for channel: CADC0892, segment: 233\n",
      "Training for channel: CADC0892, segment: 234\n",
      "End Train for channel: CADC0892, segment: 234\n",
      "Training for channel: CADC0892, segment: 236\n",
      "End Train for channel: CADC0892, segment: 236\n",
      "Training for channel: CADC0892, segment: 237\n",
      "End Train for channel: CADC0892, segment: 237\n",
      "Training for channel: CADC0892, segment: 821\n",
      "End Train for channel: CADC0892, segment: 821\n",
      "Training for channel: CADC0892, segment: 823\n",
      "End Train for channel: CADC0892, segment: 823\n",
      "Training for channel: CADC0892, segment: 824\n",
      "End Train for channel: CADC0892, segment: 824\n",
      "Training for channel: CADC0892, segment: 825\n",
      "End Train for channel: CADC0892, segment: 825\n",
      "Training for channel: CADC0892, segment: 826\n",
      "End Train for channel: CADC0892, segment: 826\n",
      "Training for channel: CADC0892, segment: 829\n",
      "End Train for channel: CADC0892, segment: 829\n",
      "Training for channel: CADC0892, segment: 830\n",
      "End Train for channel: CADC0892, segment: 830\n",
      "Training for channel: CADC0892, segment: 832\n",
      "End Train for channel: CADC0892, segment: 832\n",
      "Training for channel: CADC0892, segment: 833\n",
      "End Train for channel: CADC0892, segment: 833\n",
      "Training for channel: CADC0892, segment: 834\n",
      "End Train for channel: CADC0892, segment: 834\n",
      "Training for channel: CADC0892, segment: 836\n",
      "End Train for channel: CADC0892, segment: 836\n",
      "Training for channel: CADC0892, segment: 837\n",
      "End Train for channel: CADC0892, segment: 837\n",
      "Training for channel: CADC0892, segment: 838\n",
      "End Train for channel: CADC0892, segment: 838\n",
      "Training for channel: CADC0892, segment: 839\n",
      "End Train for channel: CADC0892, segment: 839\n",
      "Training for channel: CADC0892, segment: 840\n",
      "End Train for channel: CADC0892, segment: 840\n",
      "Training for channel: CADC0892, segment: 842\n",
      "End Train for channel: CADC0892, segment: 842\n",
      "Training for channel: CADC0892, segment: 843\n",
      "End Train for channel: CADC0892, segment: 843\n",
      "Training for channel: CADC0892, segment: 844\n",
      "End Train for channel: CADC0892, segment: 844\n",
      "Training for channel: CADC0892, segment: 845\n",
      "End Train for channel: CADC0892, segment: 845\n",
      "Training for channel: CADC0892, segment: 846\n",
      "End Train for channel: CADC0892, segment: 846\n",
      "Training for channel: CADC0892, segment: 847\n",
      "End Train for channel: CADC0892, segment: 847\n",
      "Training for channel: CADC0892, segment: 848\n",
      "End Train for channel: CADC0892, segment: 848\n",
      "Training for channel: CADC0892, segment: 849\n",
      "End Train for channel: CADC0892, segment: 849\n",
      "Training for channel: CADC0892, segment: 850\n",
      "End Train for channel: CADC0892, segment: 850\n",
      "Training for channel: CADC0892, segment: 851\n",
      "End Train for channel: CADC0892, segment: 851\n",
      "Training for channel: CADC0892, segment: 852\n",
      "End Train for channel: CADC0892, segment: 852\n",
      "Training for channel: CADC0892, segment: 854\n",
      "End Train for channel: CADC0892, segment: 854\n",
      "Training for channel: CADC0892, segment: 855\n",
      "End Train for channel: CADC0892, segment: 855\n",
      "Training for channel: CADC0892, segment: 857\n",
      "End Train for channel: CADC0892, segment: 857\n",
      "Training for channel: CADC0892, segment: 858\n",
      "End Train for channel: CADC0892, segment: 858\n",
      "Training for channel: CADC0892, segment: 859\n",
      "End Train for channel: CADC0892, segment: 859\n",
      "Training for channel: CADC0892, segment: 862\n",
      "End Train for channel: CADC0892, segment: 862\n",
      "Training for channel: CADC0892, segment: 864\n",
      "End Train for channel: CADC0892, segment: 864\n",
      "Training for channel: CADC0892, segment: 866\n",
      "End Train for channel: CADC0892, segment: 866\n",
      "Training for channel: CADC0892, segment: 867\n",
      "End Train for channel: CADC0892, segment: 867\n",
      "Training for channel: CADC0892, segment: 869\n",
      "End Train for channel: CADC0892, segment: 869\n",
      "Training for channel: CADC0892, segment: 872\n",
      "End Train for channel: CADC0892, segment: 872\n",
      "Training for channel: CADC0892, segment: 873\n",
      "End Train for channel: CADC0892, segment: 873\n",
      "Training for channel: CADC0892, segment: 874\n",
      "End Train for channel: CADC0892, segment: 874\n",
      "Training for channel: CADC0892, segment: 875\n",
      "End Train for channel: CADC0892, segment: 875\n",
      "Training for channel: CADC0892, segment: 876\n",
      "End Train for channel: CADC0892, segment: 876\n",
      "Training for channel: CADC0892, segment: 877\n",
      "End Train for channel: CADC0892, segment: 877\n",
      "Training for channel: CADC0892, segment: 878\n",
      "End Train for channel: CADC0892, segment: 878\n",
      "Training for channel: CADC0892, segment: 879\n",
      "End Train for channel: CADC0892, segment: 879\n",
      "Training for channel: CADC0892, segment: 880\n",
      "End Train for channel: CADC0892, segment: 880\n",
      "Training for channel: CADC0892, segment: 881\n",
      "End Train for channel: CADC0892, segment: 881\n",
      "Training for channel: CADC0892, segment: 882\n",
      "End Train for channel: CADC0892, segment: 882\n",
      "Training for channel: CADC0892, segment: 884\n",
      "End Train for channel: CADC0892, segment: 884\n",
      "Training for channel: CADC0892, segment: 885\n",
      "End Train for channel: CADC0892, segment: 885\n",
      "Training for channel: CADC0892, segment: 886\n",
      "End Train for channel: CADC0892, segment: 886\n",
      "Training for channel: CADC0892, segment: 887\n",
      "End Train for channel: CADC0892, segment: 887\n",
      "Training for channel: CADC0892, segment: 888\n",
      "End Train for channel: CADC0892, segment: 888\n",
      "Training for channel: CADC0892, segment: 889\n",
      "End Train for channel: CADC0892, segment: 889\n",
      "Training for channel: CADC0892, segment: 890\n",
      "End Train for channel: CADC0892, segment: 890\n",
      "Training for channel: CADC0892, segment: 891\n",
      "End Train for channel: CADC0892, segment: 891\n",
      "Training for channel: CADC0892, segment: 892\n",
      "End Train for channel: CADC0892, segment: 892\n",
      "Training for channel: CADC0892, segment: 893\n",
      "End Train for channel: CADC0892, segment: 893\n",
      "Training for channel: CADC0892, segment: 894\n",
      "End Train for channel: CADC0892, segment: 894\n",
      "Training for channel: CADC0892, segment: 896\n",
      "End Train for channel: CADC0892, segment: 896\n",
      "Training for channel: CADC0892, segment: 897\n",
      "End Train for channel: CADC0892, segment: 897\n",
      "Training for channel: CADC0892, segment: 898\n",
      "End Train for channel: CADC0892, segment: 898\n",
      "Training for channel: CADC0892, segment: 899\n",
      "End Train for channel: CADC0892, segment: 899\n",
      "Training for channel: CADC0892, segment: 900\n",
      "End Train for channel: CADC0892, segment: 900\n",
      "Training for channel: CADC0892, segment: 901\n",
      "End Train for channel: CADC0892, segment: 901\n",
      "Training for channel: CADC0892, segment: 902\n",
      "End Train for channel: CADC0892, segment: 902\n",
      "Training for channel: CADC0892, segment: 904\n",
      "End Train for channel: CADC0892, segment: 904\n",
      "Training for channel: CADC0892, segment: 906\n",
      "End Train for channel: CADC0892, segment: 906\n",
      "Training for channel: CADC0892, segment: 907\n",
      "End Train for channel: CADC0892, segment: 907\n",
      "Training for channel: CADC0892, segment: 908\n",
      "End Train for channel: CADC0892, segment: 908\n",
      "Training for channel: CADC0892, segment: 909\n",
      "End Train for channel: CADC0892, segment: 909\n",
      "Training for channel: CADC0892, segment: 910\n",
      "End Train for channel: CADC0892, segment: 910\n",
      "Training for channel: CADC0892, segment: 911\n",
      "End Train for channel: CADC0892, segment: 911\n",
      "Training for channel: CADC0892, segment: 913\n",
      "End Train for channel: CADC0892, segment: 913\n",
      "Training for channel: CADC0892, segment: 914\n",
      "End Train for channel: CADC0892, segment: 914\n",
      "Training for channel: CADC0892, segment: 915\n",
      "End Train for channel: CADC0892, segment: 915\n",
      "Training for channel: CADC0892, segment: 916\n",
      "End Train for channel: CADC0892, segment: 916\n",
      "Training for channel: CADC0892, segment: 917\n",
      "End Train for channel: CADC0892, segment: 917\n",
      "Training for channel: CADC0892, segment: 918\n",
      "End Train for channel: CADC0892, segment: 918\n",
      "Training for channel: CADC0892, segment: 919\n",
      "End Train for channel: CADC0892, segment: 919\n",
      "Training for channel: CADC0892, segment: 920\n",
      "End Train for channel: CADC0892, segment: 920\n",
      "Training for channel: CADC0892, segment: 921\n",
      "End Train for channel: CADC0892, segment: 921\n",
      "Training for channel: CADC0892, segment: 922\n",
      "End Train for channel: CADC0892, segment: 922\n",
      "Training for channel: CADC0892, segment: 924\n",
      "End Train for channel: CADC0892, segment: 924\n",
      "Training for channel: CADC0892, segment: 926\n",
      "End Train for channel: CADC0892, segment: 926\n",
      "Training for channel: CADC0892, segment: 928\n",
      "End Train for channel: CADC0892, segment: 928\n",
      "Training for channel: CADC0892, segment: 930\n",
      "End Train for channel: CADC0892, segment: 930\n",
      "Training for channel: CADC0892, segment: 931\n",
      "End Train for channel: CADC0892, segment: 931\n",
      "Training for channel: CADC0892, segment: 932\n",
      "End Train for channel: CADC0892, segment: 932\n",
      "Training for channel: CADC0892, segment: 933\n",
      "End Train for channel: CADC0892, segment: 933\n",
      "Training for channel: CADC0892, segment: 934\n",
      "End Train for channel: CADC0892, segment: 934\n",
      "Training for channel: CADC0892, segment: 935\n",
      "End Train for channel: CADC0892, segment: 935\n",
      "Training for channel: CADC0892, segment: 936\n",
      "End Train for channel: CADC0892, segment: 936\n",
      "Training for channel: CADC0892, segment: 938\n",
      "End Train for channel: CADC0892, segment: 938\n",
      "Training for channel: CADC0892, segment: 939\n",
      "End Train for channel: CADC0892, segment: 939\n",
      "Training for channel: CADC0892, segment: 940\n",
      "End Train for channel: CADC0892, segment: 940\n",
      "Training for channel: CADC0892, segment: 941\n",
      "End Train for channel: CADC0892, segment: 941\n",
      "Training for channel: CADC0892, segment: 942\n",
      "End Train for channel: CADC0892, segment: 942\n",
      "Training for channel: CADC0892, segment: 943\n",
      "End Train for channel: CADC0892, segment: 943\n",
      "Training for channel: CADC0892, segment: 945\n",
      "End Train for channel: CADC0892, segment: 945\n",
      "Training for channel: CADC0892, segment: 946\n",
      "End Train for channel: CADC0892, segment: 946\n",
      "Training for channel: CADC0892, segment: 947\n",
      "End Train for channel: CADC0892, segment: 947\n",
      "Training for channel: CADC0892, segment: 948\n",
      "End Train for channel: CADC0892, segment: 948\n",
      "Training for channel: CADC0892, segment: 950\n",
      "End Train for channel: CADC0892, segment: 950\n",
      "Training for channel: CADC0892, segment: 951\n",
      "End Train for channel: CADC0892, segment: 951\n",
      "Training for channel: CADC0892, segment: 955\n",
      "End Train for channel: CADC0892, segment: 955\n",
      "Training for channel: CADC0892, segment: 958\n",
      "End Train for channel: CADC0892, segment: 958\n",
      "Training for channel: CADC0892, segment: 959\n",
      "End Train for channel: CADC0892, segment: 959\n",
      "Training for channel: CADC0892, segment: 960\n",
      "End Train for channel: CADC0892, segment: 960\n",
      "Training for channel: CADC0892, segment: 962\n",
      "End Train for channel: CADC0892, segment: 962\n",
      "Training for channel: CADC0892, segment: 963\n",
      "End Train for channel: CADC0892, segment: 963\n",
      "Training for channel: CADC0892, segment: 964\n",
      "End Train for channel: CADC0892, segment: 964\n",
      "Training for channel: CADC0892, segment: 966\n",
      "End Train for channel: CADC0892, segment: 966\n",
      "Training for channel: CADC0892, segment: 967\n",
      "End Train for channel: CADC0892, segment: 967\n",
      "Training for channel: CADC0892, segment: 968\n",
      "End Train for channel: CADC0892, segment: 968\n",
      "Training for channel: CADC0892, segment: 969\n",
      "End Train for channel: CADC0892, segment: 969\n",
      "Training for channel: CADC0892, segment: 972\n",
      "End Train for channel: CADC0892, segment: 972\n",
      "Training for channel: CADC0892, segment: 973\n",
      "End Train for channel: CADC0892, segment: 973\n",
      "Training for channel: CADC0892, segment: 975\n",
      "End Train for channel: CADC0892, segment: 975\n",
      "Training for channel: CADC0892, segment: 976\n",
      "End Train for channel: CADC0892, segment: 976\n",
      "Training for channel: CADC0892, segment: 978\n",
      "End Train for channel: CADC0892, segment: 978\n",
      "Training for channel: CADC0892, segment: 981\n",
      "End Train for channel: CADC0892, segment: 981\n",
      "Training for channel: CADC0892, segment: 982\n",
      "End Train for channel: CADC0892, segment: 982\n",
      "Training for channel: CADC0892, segment: 983\n",
      "End Train for channel: CADC0892, segment: 983\n",
      "Training for channel: CADC0892, segment: 984\n",
      "End Train for channel: CADC0892, segment: 984\n",
      "Training for channel: CADC0892, segment: 985\n",
      "End Train for channel: CADC0892, segment: 985\n",
      "Training for channel: CADC0892, segment: 986\n",
      "End Train for channel: CADC0892, segment: 986\n",
      "Training for channel: CADC0892, segment: 987\n",
      "End Train for channel: CADC0892, segment: 987\n",
      "Training for channel: CADC0892, segment: 988\n",
      "End Train for channel: CADC0892, segment: 988\n",
      "Training for channel: CADC0892, segment: 990\n",
      "End Train for channel: CADC0892, segment: 990\n",
      "Training for channel: CADC0892, segment: 991\n",
      "End Train for channel: CADC0892, segment: 991\n",
      "Training for channel: CADC0892, segment: 993\n",
      "End Train for channel: CADC0892, segment: 993\n",
      "Training for channel: CADC0892, segment: 994\n",
      "End Train for channel: CADC0892, segment: 994\n",
      "Training for channel: CADC0892, segment: 995\n",
      "End Train for channel: CADC0892, segment: 995\n",
      "Training for channel: CADC0892, segment: 996\n",
      "End Train for channel: CADC0892, segment: 996\n",
      "Training for channel: CADC0892, segment: 997\n",
      "End Train for channel: CADC0892, segment: 997\n",
      "Training for channel: CADC0892, segment: 998\n",
      "End Train for channel: CADC0892, segment: 998\n",
      "Training for channel: CADC0892, segment: 999\n",
      "End Train for channel: CADC0892, segment: 999\n",
      "Training for channel: CADC0892, segment: 1000\n",
      "End Train for channel: CADC0892, segment: 1000\n",
      "Training for channel: CADC0892, segment: 1002\n",
      "End Train for channel: CADC0892, segment: 1002\n",
      "Training for channel: CADC0892, segment: 1007\n",
      "End Train for channel: CADC0892, segment: 1007\n",
      "Training for channel: CADC0892, segment: 1008\n",
      "End Train for channel: CADC0892, segment: 1008\n",
      "Training for channel: CADC0892, segment: 1009\n",
      "End Train for channel: CADC0892, segment: 1009\n",
      "Training for channel: CADC0892, segment: 1010\n",
      "End Train for channel: CADC0892, segment: 1010\n",
      "Training for channel: CADC0892, segment: 1011\n",
      "End Train for channel: CADC0892, segment: 1011\n",
      "Training for channel: CADC0892, segment: 1012\n",
      "End Train for channel: CADC0892, segment: 1012\n",
      "Training for channel: CADC0874, segment: 238\n",
      "End Train for channel: CADC0874, segment: 238\n",
      "Training for channel: CADC0874, segment: 240\n",
      "End Train for channel: CADC0874, segment: 240\n",
      "Training for channel: CADC0874, segment: 241\n",
      "End Train for channel: CADC0874, segment: 241\n",
      "Training for channel: CADC0874, segment: 242\n",
      "End Train for channel: CADC0874, segment: 242\n",
      "Training for channel: CADC0874, segment: 244\n",
      "End Train for channel: CADC0874, segment: 244\n",
      "Training for channel: CADC0874, segment: 245\n",
      "End Train for channel: CADC0874, segment: 245\n",
      "Training for channel: CADC0874, segment: 246\n",
      "End Train for channel: CADC0874, segment: 246\n",
      "Training for channel: CADC0874, segment: 247\n",
      "End Train for channel: CADC0874, segment: 247\n",
      "Training for channel: CADC0874, segment: 248\n",
      "End Train for channel: CADC0874, segment: 248\n",
      "Training for channel: CADC0874, segment: 249\n",
      "End Train for channel: CADC0874, segment: 249\n",
      "Training for channel: CADC0874, segment: 250\n",
      "End Train for channel: CADC0874, segment: 250\n",
      "Training for channel: CADC0874, segment: 251\n",
      "End Train for channel: CADC0874, segment: 251\n",
      "Training for channel: CADC0874, segment: 253\n",
      "End Train for channel: CADC0874, segment: 253\n",
      "Training for channel: CADC0874, segment: 254\n",
      "End Train for channel: CADC0874, segment: 254\n",
      "Training for channel: CADC0874, segment: 255\n",
      "End Train for channel: CADC0874, segment: 255\n",
      "Training for channel: CADC0874, segment: 257\n",
      "End Train for channel: CADC0874, segment: 257\n",
      "Training for channel: CADC0874, segment: 258\n",
      "End Train for channel: CADC0874, segment: 258\n",
      "Training for channel: CADC0874, segment: 259\n",
      "End Train for channel: CADC0874, segment: 259\n",
      "Training for channel: CADC0874, segment: 262\n",
      "End Train for channel: CADC0874, segment: 262\n",
      "Training for channel: CADC0874, segment: 263\n",
      "End Train for channel: CADC0874, segment: 263\n",
      "Training for channel: CADC0874, segment: 264\n",
      "End Train for channel: CADC0874, segment: 264\n",
      "Training for channel: CADC0874, segment: 267\n",
      "End Train for channel: CADC0874, segment: 267\n",
      "Training for channel: CADC0874, segment: 268\n",
      "End Train for channel: CADC0874, segment: 268\n",
      "Training for channel: CADC0874, segment: 269\n",
      "End Train for channel: CADC0874, segment: 269\n",
      "Training for channel: CADC0874, segment: 271\n",
      "End Train for channel: CADC0874, segment: 271\n",
      "Training for channel: CADC0874, segment: 272\n",
      "End Train for channel: CADC0874, segment: 272\n",
      "Training for channel: CADC0874, segment: 274\n",
      "End Train for channel: CADC0874, segment: 274\n",
      "Training for channel: CADC0874, segment: 275\n",
      "End Train for channel: CADC0874, segment: 275\n",
      "Training for channel: CADC0874, segment: 280\n",
      "End Train for channel: CADC0874, segment: 280\n",
      "Training for channel: CADC0874, segment: 281\n",
      "End Train for channel: CADC0874, segment: 281\n",
      "Training for channel: CADC0874, segment: 282\n",
      "End Train for channel: CADC0874, segment: 282\n",
      "Training for channel: CADC0874, segment: 283\n",
      "End Train for channel: CADC0874, segment: 283\n",
      "Training for channel: CADC0874, segment: 284\n",
      "End Train for channel: CADC0874, segment: 284\n",
      "Training for channel: CADC0874, segment: 285\n",
      "End Train for channel: CADC0874, segment: 285\n",
      "Training for channel: CADC0874, segment: 286\n",
      "End Train for channel: CADC0874, segment: 286\n",
      "Training for channel: CADC0874, segment: 287\n",
      "End Train for channel: CADC0874, segment: 287\n",
      "Training for channel: CADC0874, segment: 288\n",
      "End Train for channel: CADC0874, segment: 288\n",
      "Training for channel: CADC0874, segment: 290\n",
      "End Train for channel: CADC0874, segment: 290\n",
      "Training for channel: CADC0874, segment: 291\n",
      "End Train for channel: CADC0874, segment: 291\n",
      "Training for channel: CADC0874, segment: 293\n",
      "End Train for channel: CADC0874, segment: 293\n",
      "Training for channel: CADC0874, segment: 294\n",
      "End Train for channel: CADC0874, segment: 294\n",
      "Training for channel: CADC0874, segment: 295\n",
      "End Train for channel: CADC0874, segment: 295\n",
      "Training for channel: CADC0874, segment: 296\n",
      "End Train for channel: CADC0874, segment: 296\n",
      "Training for channel: CADC0874, segment: 297\n",
      "End Train for channel: CADC0874, segment: 297\n",
      "Training for channel: CADC0874, segment: 298\n",
      "End Train for channel: CADC0874, segment: 298\n",
      "Training for channel: CADC0874, segment: 299\n",
      "End Train for channel: CADC0874, segment: 299\n",
      "Training for channel: CADC0874, segment: 300\n",
      "End Train for channel: CADC0874, segment: 300\n",
      "Training for channel: CADC0874, segment: 302\n",
      "End Train for channel: CADC0874, segment: 302\n",
      "Training for channel: CADC0874, segment: 303\n",
      "End Train for channel: CADC0874, segment: 303\n",
      "Training for channel: CADC0874, segment: 305\n",
      "End Train for channel: CADC0874, segment: 305\n",
      "Training for channel: CADC0874, segment: 307\n",
      "End Train for channel: CADC0874, segment: 307\n",
      "Training for channel: CADC0874, segment: 311\n",
      "End Train for channel: CADC0874, segment: 311\n",
      "Training for channel: CADC0874, segment: 312\n",
      "End Train for channel: CADC0874, segment: 312\n",
      "Training for channel: CADC0874, segment: 313\n",
      "End Train for channel: CADC0874, segment: 313\n",
      "Training for channel: CADC0874, segment: 316\n",
      "End Train for channel: CADC0874, segment: 316\n",
      "Training for channel: CADC0874, segment: 317\n",
      "End Train for channel: CADC0874, segment: 317\n",
      "Training for channel: CADC0874, segment: 319\n",
      "End Train for channel: CADC0874, segment: 319\n",
      "Training for channel: CADC0874, segment: 321\n",
      "End Train for channel: CADC0874, segment: 321\n",
      "Training for channel: CADC0874, segment: 322\n",
      "End Train for channel: CADC0874, segment: 322\n",
      "Training for channel: CADC0874, segment: 323\n",
      "End Train for channel: CADC0874, segment: 323\n",
      "Training for channel: CADC0874, segment: 324\n",
      "End Train for channel: CADC0874, segment: 324\n",
      "Training for channel: CADC0874, segment: 325\n",
      "End Train for channel: CADC0874, segment: 325\n",
      "Training for channel: CADC0874, segment: 329\n",
      "End Train for channel: CADC0874, segment: 329\n",
      "Training for channel: CADC0874, segment: 330\n",
      "End Train for channel: CADC0874, segment: 330\n",
      "Training for channel: CADC0874, segment: 331\n",
      "End Train for channel: CADC0874, segment: 331\n",
      "Training for channel: CADC0874, segment: 332\n",
      "End Train for channel: CADC0874, segment: 332\n",
      "Training for channel: CADC0874, segment: 713\n",
      "End Train for channel: CADC0874, segment: 713\n",
      "Training for channel: CADC0874, segment: 714\n",
      "End Train for channel: CADC0874, segment: 714\n",
      "Training for channel: CADC0874, segment: 716\n",
      "End Train for channel: CADC0874, segment: 716\n",
      "Training for channel: CADC0874, segment: 718\n",
      "End Train for channel: CADC0874, segment: 718\n",
      "Training for channel: CADC0874, segment: 719\n",
      "End Train for channel: CADC0874, segment: 719\n",
      "Training for channel: CADC0874, segment: 720\n",
      "End Train for channel: CADC0874, segment: 720\n",
      "Training for channel: CADC0874, segment: 721\n",
      "End Train for channel: CADC0874, segment: 721\n",
      "Training for channel: CADC0874, segment: 723\n",
      "End Train for channel: CADC0874, segment: 723\n",
      "Training for channel: CADC0874, segment: 724\n",
      "End Train for channel: CADC0874, segment: 724\n",
      "Training for channel: CADC0874, segment: 725\n",
      "End Train for channel: CADC0874, segment: 725\n",
      "Training for channel: CADC0874, segment: 727\n",
      "End Train for channel: CADC0874, segment: 727\n",
      "Training for channel: CADC0874, segment: 728\n",
      "End Train for channel: CADC0874, segment: 728\n",
      "Training for channel: CADC0874, segment: 729\n",
      "End Train for channel: CADC0874, segment: 729\n",
      "Training for channel: CADC0874, segment: 730\n",
      "End Train for channel: CADC0874, segment: 730\n",
      "Training for channel: CADC0874, segment: 731\n",
      "End Train for channel: CADC0874, segment: 731\n",
      "Training for channel: CADC0874, segment: 732\n",
      "End Train for channel: CADC0874, segment: 732\n",
      "Training for channel: CADC0874, segment: 736\n",
      "End Train for channel: CADC0874, segment: 736\n",
      "Training for channel: CADC0874, segment: 737\n",
      "End Train for channel: CADC0874, segment: 737\n",
      "Training for channel: CADC0874, segment: 739\n",
      "End Train for channel: CADC0874, segment: 739\n",
      "Training for channel: CADC0874, segment: 740\n",
      "End Train for channel: CADC0874, segment: 740\n",
      "Training for channel: CADC0874, segment: 741\n",
      "End Train for channel: CADC0874, segment: 741\n",
      "Training for channel: CADC0874, segment: 742\n",
      "End Train for channel: CADC0874, segment: 742\n",
      "Training for channel: CADC0874, segment: 743\n",
      "End Train for channel: CADC0874, segment: 743\n",
      "Training for channel: CADC0874, segment: 744\n",
      "End Train for channel: CADC0874, segment: 744\n",
      "Training for channel: CADC0874, segment: 745\n",
      "End Train for channel: CADC0874, segment: 745\n",
      "Training for channel: CADC0874, segment: 747\n",
      "End Train for channel: CADC0874, segment: 747\n",
      "Training for channel: CADC0874, segment: 748\n",
      "End Train for channel: CADC0874, segment: 748\n",
      "Training for channel: CADC0874, segment: 750\n",
      "End Train for channel: CADC0874, segment: 750\n",
      "Training for channel: CADC0874, segment: 751\n",
      "End Train for channel: CADC0874, segment: 751\n",
      "Training for channel: CADC0874, segment: 752\n",
      "End Train for channel: CADC0874, segment: 752\n",
      "Training for channel: CADC0874, segment: 754\n",
      "End Train for channel: CADC0874, segment: 754\n",
      "Training for channel: CADC0874, segment: 755\n",
      "End Train for channel: CADC0874, segment: 755\n",
      "Training for channel: CADC0874, segment: 757\n",
      "End Train for channel: CADC0874, segment: 757\n",
      "Training for channel: CADC0874, segment: 758\n",
      "End Train for channel: CADC0874, segment: 758\n",
      "Training for channel: CADC0874, segment: 759\n",
      "End Train for channel: CADC0874, segment: 759\n",
      "Training for channel: CADC0874, segment: 760\n",
      "End Train for channel: CADC0874, segment: 760\n",
      "Training for channel: CADC0874, segment: 762\n",
      "End Train for channel: CADC0874, segment: 762\n",
      "Training for channel: CADC0874, segment: 763\n",
      "End Train for channel: CADC0874, segment: 763\n",
      "Training for channel: CADC0874, segment: 765\n",
      "End Train for channel: CADC0874, segment: 765\n",
      "Training for channel: CADC0874, segment: 766\n",
      "End Train for channel: CADC0874, segment: 766\n",
      "Training for channel: CADC0874, segment: 768\n",
      "End Train for channel: CADC0874, segment: 768\n",
      "Training for channel: CADC0874, segment: 769\n",
      "End Train for channel: CADC0874, segment: 769\n",
      "Training for channel: CADC0874, segment: 770\n",
      "End Train for channel: CADC0874, segment: 770\n",
      "Training for channel: CADC0874, segment: 771\n",
      "End Train for channel: CADC0874, segment: 771\n",
      "Training for channel: CADC0874, segment: 772\n",
      "End Train for channel: CADC0874, segment: 772\n",
      "Training for channel: CADC0874, segment: 773\n",
      "End Train for channel: CADC0874, segment: 773\n",
      "Training for channel: CADC0874, segment: 774\n",
      "End Train for channel: CADC0874, segment: 774\n",
      "Training for channel: CADC0874, segment: 775\n",
      "End Train for channel: CADC0874, segment: 775\n",
      "Training for channel: CADC0874, segment: 776\n",
      "End Train for channel: CADC0874, segment: 776\n",
      "Training for channel: CADC0874, segment: 777\n",
      "End Train for channel: CADC0874, segment: 777\n",
      "Training for channel: CADC0874, segment: 778\n",
      "End Train for channel: CADC0874, segment: 778\n",
      "Training for channel: CADC0874, segment: 780\n",
      "End Train for channel: CADC0874, segment: 780\n",
      "Training for channel: CADC0874, segment: 781\n",
      "End Train for channel: CADC0874, segment: 781\n",
      "Training for channel: CADC0874, segment: 782\n",
      "End Train for channel: CADC0874, segment: 782\n",
      "Training for channel: CADC0874, segment: 783\n",
      "End Train for channel: CADC0874, segment: 783\n",
      "Training for channel: CADC0874, segment: 784\n",
      "End Train for channel: CADC0874, segment: 784\n",
      "Training for channel: CADC0874, segment: 785\n",
      "End Train for channel: CADC0874, segment: 785\n",
      "Training for channel: CADC0874, segment: 786\n",
      "End Train for channel: CADC0874, segment: 786\n",
      "Training for channel: CADC0874, segment: 787\n",
      "End Train for channel: CADC0874, segment: 787\n",
      "Training for channel: CADC0874, segment: 788\n",
      "End Train for channel: CADC0874, segment: 788\n",
      "Training for channel: CADC0874, segment: 789\n",
      "End Train for channel: CADC0874, segment: 789\n",
      "Training for channel: CADC0874, segment: 790\n",
      "End Train for channel: CADC0874, segment: 790\n",
      "Training for channel: CADC0874, segment: 791\n",
      "End Train for channel: CADC0874, segment: 791\n",
      "Training for channel: CADC0874, segment: 793\n",
      "End Train for channel: CADC0874, segment: 793\n",
      "Training for channel: CADC0874, segment: 794\n",
      "End Train for channel: CADC0874, segment: 794\n",
      "Training for channel: CADC0874, segment: 795\n",
      "End Train for channel: CADC0874, segment: 795\n",
      "Training for channel: CADC0874, segment: 796\n",
      "End Train for channel: CADC0874, segment: 796\n",
      "Training for channel: CADC0874, segment: 797\n",
      "End Train for channel: CADC0874, segment: 797\n",
      "Training for channel: CADC0874, segment: 799\n",
      "End Train for channel: CADC0874, segment: 799\n",
      "Training for channel: CADC0874, segment: 801\n",
      "End Train for channel: CADC0874, segment: 801\n",
      "Training for channel: CADC0874, segment: 802\n",
      "End Train for channel: CADC0874, segment: 802\n",
      "Training for channel: CADC0874, segment: 804\n",
      "End Train for channel: CADC0874, segment: 804\n",
      "Training for channel: CADC0874, segment: 806\n",
      "End Train for channel: CADC0874, segment: 806\n",
      "Training for channel: CADC0874, segment: 807\n",
      "End Train for channel: CADC0874, segment: 807\n",
      "Training for channel: CADC0874, segment: 808\n",
      "End Train for channel: CADC0874, segment: 808\n",
      "Training for channel: CADC0874, segment: 809\n",
      "End Train for channel: CADC0874, segment: 809\n",
      "Training for channel: CADC0884, segment: 333\n",
      "End Train for channel: CADC0884, segment: 333\n",
      "Training for channel: CADC0884, segment: 334\n",
      "End Train for channel: CADC0884, segment: 334\n",
      "Training for channel: CADC0884, segment: 335\n",
      "End Train for channel: CADC0884, segment: 335\n",
      "Training for channel: CADC0884, segment: 337\n",
      "End Train for channel: CADC0884, segment: 337\n",
      "Training for channel: CADC0884, segment: 338\n",
      "End Train for channel: CADC0884, segment: 338\n",
      "Training for channel: CADC0884, segment: 339\n",
      "End Train for channel: CADC0884, segment: 339\n",
      "Training for channel: CADC0884, segment: 340\n",
      "End Train for channel: CADC0884, segment: 340\n",
      "Training for channel: CADC0884, segment: 341\n",
      "End Train for channel: CADC0884, segment: 341\n",
      "Training for channel: CADC0884, segment: 342\n",
      "End Train for channel: CADC0884, segment: 342\n",
      "Training for channel: CADC0884, segment: 344\n",
      "End Train for channel: CADC0884, segment: 344\n",
      "Training for channel: CADC0884, segment: 345\n",
      "End Train for channel: CADC0884, segment: 345\n",
      "Training for channel: CADC0884, segment: 346\n",
      "End Train for channel: CADC0884, segment: 346\n",
      "Training for channel: CADC0884, segment: 347\n",
      "End Train for channel: CADC0884, segment: 347\n",
      "Training for channel: CADC0884, segment: 348\n",
      "End Train for channel: CADC0884, segment: 348\n",
      "Training for channel: CADC0884, segment: 349\n",
      "End Train for channel: CADC0884, segment: 349\n",
      "Training for channel: CADC0884, segment: 350\n",
      "End Train for channel: CADC0884, segment: 350\n",
      "Training for channel: CADC0884, segment: 352\n",
      "End Train for channel: CADC0884, segment: 352\n",
      "Training for channel: CADC0884, segment: 353\n",
      "End Train for channel: CADC0884, segment: 353\n",
      "Training for channel: CADC0884, segment: 354\n",
      "End Train for channel: CADC0884, segment: 354\n",
      "Training for channel: CADC0884, segment: 355\n",
      "End Train for channel: CADC0884, segment: 355\n",
      "Training for channel: CADC0884, segment: 358\n",
      "End Train for channel: CADC0884, segment: 358\n",
      "Training for channel: CADC0884, segment: 359\n",
      "End Train for channel: CADC0884, segment: 359\n",
      "Training for channel: CADC0884, segment: 360\n",
      "End Train for channel: CADC0884, segment: 360\n",
      "Training for channel: CADC0884, segment: 361\n",
      "End Train for channel: CADC0884, segment: 361\n",
      "Training for channel: CADC0884, segment: 362\n",
      "End Train for channel: CADC0884, segment: 362\n",
      "Training for channel: CADC0884, segment: 363\n",
      "End Train for channel: CADC0884, segment: 363\n",
      "Training for channel: CADC0884, segment: 364\n",
      "End Train for channel: CADC0884, segment: 364\n",
      "Training for channel: CADC0884, segment: 365\n",
      "End Train for channel: CADC0884, segment: 365\n",
      "Training for channel: CADC0884, segment: 366\n",
      "End Train for channel: CADC0884, segment: 366\n",
      "Training for channel: CADC0884, segment: 367\n",
      "End Train for channel: CADC0884, segment: 367\n",
      "Training for channel: CADC0884, segment: 368\n",
      "End Train for channel: CADC0884, segment: 368\n",
      "Training for channel: CADC0884, segment: 369\n",
      "End Train for channel: CADC0884, segment: 369\n",
      "Training for channel: CADC0884, segment: 370\n",
      "End Train for channel: CADC0884, segment: 370\n",
      "Training for channel: CADC0884, segment: 371\n",
      "End Train for channel: CADC0884, segment: 371\n",
      "Training for channel: CADC0884, segment: 373\n",
      "End Train for channel: CADC0884, segment: 373\n",
      "Training for channel: CADC0884, segment: 374\n",
      "End Train for channel: CADC0884, segment: 374\n",
      "Training for channel: CADC0884, segment: 375\n",
      "End Train for channel: CADC0884, segment: 375\n",
      "Training for channel: CADC0884, segment: 376\n",
      "End Train for channel: CADC0884, segment: 376\n",
      "Training for channel: CADC0884, segment: 377\n",
      "End Train for channel: CADC0884, segment: 377\n",
      "Training for channel: CADC0884, segment: 378\n",
      "End Train for channel: CADC0884, segment: 378\n",
      "Training for channel: CADC0884, segment: 379\n",
      "End Train for channel: CADC0884, segment: 379\n",
      "Training for channel: CADC0884, segment: 380\n",
      "End Train for channel: CADC0884, segment: 380\n",
      "Training for channel: CADC0884, segment: 383\n",
      "End Train for channel: CADC0884, segment: 383\n",
      "Training for channel: CADC0884, segment: 385\n",
      "End Train for channel: CADC0884, segment: 385\n",
      "Training for channel: CADC0884, segment: 386\n",
      "End Train for channel: CADC0884, segment: 386\n",
      "Training for channel: CADC0884, segment: 387\n",
      "End Train for channel: CADC0884, segment: 387\n",
      "Training for channel: CADC0884, segment: 389\n",
      "End Train for channel: CADC0884, segment: 389\n",
      "Training for channel: CADC0884, segment: 390\n",
      "End Train for channel: CADC0884, segment: 390\n",
      "Training for channel: CADC0884, segment: 391\n",
      "End Train for channel: CADC0884, segment: 391\n",
      "Training for channel: CADC0884, segment: 392\n",
      "End Train for channel: CADC0884, segment: 392\n",
      "Training for channel: CADC0884, segment: 393\n",
      "End Train for channel: CADC0884, segment: 393\n",
      "Training for channel: CADC0884, segment: 394\n",
      "End Train for channel: CADC0884, segment: 394\n",
      "Training for channel: CADC0884, segment: 396\n",
      "End Train for channel: CADC0884, segment: 396\n",
      "Training for channel: CADC0884, segment: 398\n",
      "End Train for channel: CADC0884, segment: 398\n",
      "Training for channel: CADC0884, segment: 399\n",
      "End Train for channel: CADC0884, segment: 399\n",
      "Training for channel: CADC0884, segment: 400\n",
      "End Train for channel: CADC0884, segment: 400\n",
      "Training for channel: CADC0884, segment: 401\n",
      "End Train for channel: CADC0884, segment: 401\n",
      "Training for channel: CADC0884, segment: 402\n",
      "End Train for channel: CADC0884, segment: 402\n",
      "Training for channel: CADC0884, segment: 404\n",
      "End Train for channel: CADC0884, segment: 404\n",
      "Training for channel: CADC0884, segment: 405\n",
      "End Train for channel: CADC0884, segment: 405\n",
      "Training for channel: CADC0884, segment: 407\n",
      "End Train for channel: CADC0884, segment: 407\n",
      "Training for channel: CADC0884, segment: 408\n",
      "End Train for channel: CADC0884, segment: 408\n",
      "Training for channel: CADC0884, segment: 409\n",
      "End Train for channel: CADC0884, segment: 409\n",
      "Training for channel: CADC0884, segment: 411\n",
      "End Train for channel: CADC0884, segment: 411\n",
      "Training for channel: CADC0884, segment: 412\n",
      "End Train for channel: CADC0884, segment: 412\n",
      "Training for channel: CADC0884, segment: 413\n",
      "End Train for channel: CADC0884, segment: 413\n",
      "Training for channel: CADC0884, segment: 414\n",
      "End Train for channel: CADC0884, segment: 414\n",
      "Training for channel: CADC0884, segment: 416\n",
      "End Train for channel: CADC0884, segment: 416\n",
      "Training for channel: CADC0884, segment: 418\n",
      "End Train for channel: CADC0884, segment: 418\n",
      "Training for channel: CADC0884, segment: 419\n",
      "End Train for channel: CADC0884, segment: 419\n",
      "Training for channel: CADC0884, segment: 422\n",
      "End Train for channel: CADC0884, segment: 422\n",
      "Training for channel: CADC0884, segment: 423\n",
      "End Train for channel: CADC0884, segment: 423\n",
      "Training for channel: CADC0884, segment: 424\n",
      "End Train for channel: CADC0884, segment: 424\n",
      "Training for channel: CADC0884, segment: 425\n",
      "End Train for channel: CADC0884, segment: 425\n",
      "Training for channel: CADC0884, segment: 426\n",
      "End Train for channel: CADC0884, segment: 426\n",
      "Training for channel: CADC0884, segment: 428\n",
      "End Train for channel: CADC0884, segment: 428\n",
      "Training for channel: CADC0884, segment: 430\n",
      "End Train for channel: CADC0884, segment: 430\n",
      "Training for channel: CADC0884, segment: 431\n",
      "End Train for channel: CADC0884, segment: 431\n",
      "Training for channel: CADC0884, segment: 432\n",
      "End Train for channel: CADC0884, segment: 432\n",
      "Training for channel: CADC0884, segment: 434\n",
      "End Train for channel: CADC0884, segment: 434\n",
      "Training for channel: CADC0884, segment: 435\n",
      "End Train for channel: CADC0884, segment: 435\n",
      "Training for channel: CADC0884, segment: 436\n",
      "End Train for channel: CADC0884, segment: 436\n",
      "Training for channel: CADC0884, segment: 438\n",
      "End Train for channel: CADC0884, segment: 438\n",
      "Training for channel: CADC0884, segment: 439\n",
      "End Train for channel: CADC0884, segment: 439\n",
      "Training for channel: CADC0884, segment: 441\n",
      "End Train for channel: CADC0884, segment: 441\n",
      "Training for channel: CADC0884, segment: 442\n",
      "End Train for channel: CADC0884, segment: 442\n",
      "Training for channel: CADC0884, segment: 663\n",
      "End Train for channel: CADC0884, segment: 663\n",
      "Training for channel: CADC0884, segment: 664\n",
      "End Train for channel: CADC0884, segment: 664\n",
      "Training for channel: CADC0884, segment: 665\n",
      "End Train for channel: CADC0884, segment: 665\n",
      "Training for channel: CADC0884, segment: 666\n",
      "End Train for channel: CADC0884, segment: 666\n",
      "Training for channel: CADC0884, segment: 667\n",
      "End Train for channel: CADC0884, segment: 667\n",
      "Training for channel: CADC0884, segment: 668\n",
      "End Train for channel: CADC0884, segment: 668\n",
      "Training for channel: CADC0884, segment: 669\n",
      "End Train for channel: CADC0884, segment: 669\n",
      "Training for channel: CADC0884, segment: 672\n",
      "End Train for channel: CADC0884, segment: 672\n",
      "Training for channel: CADC0884, segment: 673\n",
      "End Train for channel: CADC0884, segment: 673\n",
      "Training for channel: CADC0884, segment: 674\n",
      "End Train for channel: CADC0884, segment: 674\n",
      "Training for channel: CADC0884, segment: 675\n",
      "End Train for channel: CADC0884, segment: 675\n",
      "Training for channel: CADC0884, segment: 676\n",
      "End Train for channel: CADC0884, segment: 676\n",
      "Training for channel: CADC0884, segment: 677\n",
      "End Train for channel: CADC0884, segment: 677\n",
      "Training for channel: CADC0884, segment: 681\n",
      "End Train for channel: CADC0884, segment: 681\n",
      "Training for channel: CADC0884, segment: 684\n",
      "End Train for channel: CADC0884, segment: 684\n",
      "Training for channel: CADC0884, segment: 685\n",
      "End Train for channel: CADC0884, segment: 685\n",
      "Training for channel: CADC0884, segment: 686\n",
      "End Train for channel: CADC0884, segment: 686\n",
      "Training for channel: CADC0884, segment: 687\n",
      "End Train for channel: CADC0884, segment: 687\n",
      "Training for channel: CADC0884, segment: 688\n",
      "End Train for channel: CADC0884, segment: 688\n",
      "Training for channel: CADC0884, segment: 689\n",
      "End Train for channel: CADC0884, segment: 689\n",
      "Training for channel: CADC0884, segment: 690\n",
      "End Train for channel: CADC0884, segment: 690\n",
      "Training for channel: CADC0884, segment: 691\n",
      "End Train for channel: CADC0884, segment: 691\n",
      "Training for channel: CADC0884, segment: 692\n",
      "End Train for channel: CADC0884, segment: 692\n",
      "Training for channel: CADC0884, segment: 693\n",
      "End Train for channel: CADC0884, segment: 693\n",
      "Training for channel: CADC0884, segment: 694\n",
      "End Train for channel: CADC0884, segment: 694\n",
      "Training for channel: CADC0884, segment: 695\n",
      "End Train for channel: CADC0884, segment: 695\n",
      "Training for channel: CADC0884, segment: 696\n",
      "End Train for channel: CADC0884, segment: 696\n",
      "Training for channel: CADC0884, segment: 697\n",
      "End Train for channel: CADC0884, segment: 697\n",
      "Training for channel: CADC0884, segment: 698\n",
      "End Train for channel: CADC0884, segment: 698\n",
      "Training for channel: CADC0884, segment: 699\n",
      "End Train for channel: CADC0884, segment: 699\n",
      "Training for channel: CADC0884, segment: 700\n",
      "End Train for channel: CADC0884, segment: 700\n",
      "Training for channel: CADC0884, segment: 702\n",
      "End Train for channel: CADC0884, segment: 702\n",
      "Training for channel: CADC0884, segment: 703\n",
      "End Train for channel: CADC0884, segment: 703\n",
      "Training for channel: CADC0884, segment: 704\n",
      "End Train for channel: CADC0884, segment: 704\n",
      "Training for channel: CADC0884, segment: 705\n",
      "End Train for channel: CADC0884, segment: 705\n",
      "Training for channel: CADC0884, segment: 709\n",
      "End Train for channel: CADC0884, segment: 709\n",
      "Training for channel: CADC0873, segment: 443\n",
      "End Train for channel: CADC0873, segment: 443\n",
      "Training for channel: CADC0873, segment: 445\n",
      "End Train for channel: CADC0873, segment: 445\n",
      "Training for channel: CADC0873, segment: 446\n",
      "End Train for channel: CADC0873, segment: 446\n",
      "Training for channel: CADC0873, segment: 447\n",
      "End Train for channel: CADC0873, segment: 447\n",
      "Training for channel: CADC0873, segment: 448\n",
      "End Train for channel: CADC0873, segment: 448\n",
      "Training for channel: CADC0873, segment: 451\n",
      "End Train for channel: CADC0873, segment: 451\n",
      "Training for channel: CADC0873, segment: 453\n",
      "End Train for channel: CADC0873, segment: 453\n",
      "Training for channel: CADC0873, segment: 454\n",
      "End Train for channel: CADC0873, segment: 454\n",
      "Training for channel: CADC0873, segment: 455\n",
      "End Train for channel: CADC0873, segment: 455\n",
      "Training for channel: CADC0873, segment: 456\n",
      "End Train for channel: CADC0873, segment: 456\n",
      "Training for channel: CADC0873, segment: 457\n",
      "End Train for channel: CADC0873, segment: 457\n",
      "Training for channel: CADC0873, segment: 459\n",
      "End Train for channel: CADC0873, segment: 459\n",
      "Training for channel: CADC0873, segment: 460\n",
      "End Train for channel: CADC0873, segment: 460\n",
      "Training for channel: CADC0873, segment: 461\n",
      "End Train for channel: CADC0873, segment: 461\n",
      "Training for channel: CADC0873, segment: 462\n",
      "End Train for channel: CADC0873, segment: 462\n",
      "Training for channel: CADC0873, segment: 463\n",
      "End Train for channel: CADC0873, segment: 463\n",
      "Training for channel: CADC0873, segment: 464\n",
      "End Train for channel: CADC0873, segment: 464\n",
      "Training for channel: CADC0873, segment: 465\n",
      "End Train for channel: CADC0873, segment: 465\n",
      "Training for channel: CADC0873, segment: 467\n",
      "End Train for channel: CADC0873, segment: 467\n",
      "Training for channel: CADC0873, segment: 468\n",
      "End Train for channel: CADC0873, segment: 468\n",
      "Training for channel: CADC0873, segment: 469\n",
      "End Train for channel: CADC0873, segment: 469\n",
      "Training for channel: CADC0873, segment: 470\n",
      "End Train for channel: CADC0873, segment: 470\n",
      "Training for channel: CADC0873, segment: 471\n",
      "End Train for channel: CADC0873, segment: 471\n",
      "Training for channel: CADC0873, segment: 472\n",
      "End Train for channel: CADC0873, segment: 472\n",
      "Training for channel: CADC0873, segment: 473\n",
      "End Train for channel: CADC0873, segment: 473\n",
      "Training for channel: CADC0873, segment: 474\n",
      "End Train for channel: CADC0873, segment: 474\n",
      "Training for channel: CADC0873, segment: 475\n",
      "End Train for channel: CADC0873, segment: 475\n",
      "Training for channel: CADC0873, segment: 477\n",
      "End Train for channel: CADC0873, segment: 477\n",
      "Training for channel: CADC0873, segment: 479\n",
      "End Train for channel: CADC0873, segment: 479\n",
      "Training for channel: CADC0873, segment: 480\n",
      "End Train for channel: CADC0873, segment: 480\n",
      "Training for channel: CADC0873, segment: 481\n",
      "End Train for channel: CADC0873, segment: 481\n",
      "Training for channel: CADC0873, segment: 482\n",
      "End Train for channel: CADC0873, segment: 482\n",
      "Training for channel: CADC0873, segment: 483\n",
      "End Train for channel: CADC0873, segment: 483\n",
      "Training for channel: CADC0873, segment: 484\n",
      "End Train for channel: CADC0873, segment: 484\n",
      "Training for channel: CADC0873, segment: 485\n",
      "End Train for channel: CADC0873, segment: 485\n",
      "Training for channel: CADC0873, segment: 486\n",
      "End Train for channel: CADC0873, segment: 486\n",
      "Training for channel: CADC0873, segment: 487\n",
      "End Train for channel: CADC0873, segment: 487\n",
      "Training for channel: CADC0873, segment: 488\n",
      "End Train for channel: CADC0873, segment: 488\n",
      "Training for channel: CADC0873, segment: 489\n",
      "End Train for channel: CADC0873, segment: 489\n",
      "Training for channel: CADC0873, segment: 490\n",
      "End Train for channel: CADC0873, segment: 490\n",
      "Training for channel: CADC0873, segment: 491\n",
      "End Train for channel: CADC0873, segment: 491\n",
      "Training for channel: CADC0873, segment: 492\n",
      "End Train for channel: CADC0873, segment: 492\n",
      "Training for channel: CADC0873, segment: 494\n",
      "End Train for channel: CADC0873, segment: 494\n",
      "Training for channel: CADC0873, segment: 495\n",
      "End Train for channel: CADC0873, segment: 495\n",
      "Training for channel: CADC0873, segment: 496\n",
      "End Train for channel: CADC0873, segment: 496\n",
      "Training for channel: CADC0873, segment: 497\n",
      "End Train for channel: CADC0873, segment: 497\n",
      "Training for channel: CADC0873, segment: 499\n",
      "End Train for channel: CADC0873, segment: 499\n",
      "Training for channel: CADC0873, segment: 501\n",
      "End Train for channel: CADC0873, segment: 501\n",
      "Training for channel: CADC0873, segment: 502\n",
      "End Train for channel: CADC0873, segment: 502\n",
      "Training for channel: CADC0873, segment: 503\n",
      "End Train for channel: CADC0873, segment: 503\n",
      "Training for channel: CADC0873, segment: 505\n",
      "End Train for channel: CADC0873, segment: 505\n",
      "Training for channel: CADC0873, segment: 506\n",
      "End Train for channel: CADC0873, segment: 506\n",
      "Training for channel: CADC0873, segment: 507\n",
      "End Train for channel: CADC0873, segment: 507\n",
      "Training for channel: CADC0873, segment: 508\n",
      "End Train for channel: CADC0873, segment: 508\n",
      "Training for channel: CADC0873, segment: 509\n",
      "End Train for channel: CADC0873, segment: 509\n",
      "Training for channel: CADC0873, segment: 510\n",
      "End Train for channel: CADC0873, segment: 510\n",
      "Training for channel: CADC0873, segment: 511\n",
      "End Train for channel: CADC0873, segment: 511\n",
      "Training for channel: CADC0873, segment: 512\n",
      "End Train for channel: CADC0873, segment: 512\n",
      "Training for channel: CADC0873, segment: 513\n",
      "End Train for channel: CADC0873, segment: 513\n",
      "Training for channel: CADC0873, segment: 514\n",
      "End Train for channel: CADC0873, segment: 514\n",
      "Training for channel: CADC0873, segment: 515\n",
      "End Train for channel: CADC0873, segment: 515\n",
      "Training for channel: CADC0873, segment: 516\n",
      "End Train for channel: CADC0873, segment: 516\n",
      "Training for channel: CADC0873, segment: 517\n",
      "End Train for channel: CADC0873, segment: 517\n",
      "Training for channel: CADC0873, segment: 518\n",
      "End Train for channel: CADC0873, segment: 518\n",
      "Training for channel: CADC0873, segment: 519\n",
      "End Train for channel: CADC0873, segment: 519\n",
      "Training for channel: CADC0873, segment: 521\n",
      "End Train for channel: CADC0873, segment: 521\n",
      "Training for channel: CADC0873, segment: 523\n",
      "End Train for channel: CADC0873, segment: 523\n",
      "Training for channel: CADC0873, segment: 525\n",
      "End Train for channel: CADC0873, segment: 525\n",
      "Training for channel: CADC0873, segment: 526\n",
      "End Train for channel: CADC0873, segment: 526\n",
      "Training for channel: CADC0873, segment: 527\n",
      "End Train for channel: CADC0873, segment: 527\n",
      "Training for channel: CADC0873, segment: 528\n",
      "End Train for channel: CADC0873, segment: 528\n",
      "Training for channel: CADC0873, segment: 530\n",
      "End Train for channel: CADC0873, segment: 530\n",
      "Training for channel: CADC0873, segment: 531\n",
      "End Train for channel: CADC0873, segment: 531\n",
      "Training for channel: CADC0873, segment: 532\n",
      "End Train for channel: CADC0873, segment: 532\n",
      "Training for channel: CADC0873, segment: 534\n",
      "End Train for channel: CADC0873, segment: 534\n",
      "Training for channel: CADC0873, segment: 536\n",
      "End Train for channel: CADC0873, segment: 536\n",
      "Training for channel: CADC0873, segment: 538\n",
      "End Train for channel: CADC0873, segment: 538\n",
      "Training for channel: CADC0873, segment: 539\n",
      "End Train for channel: CADC0873, segment: 539\n",
      "Training for channel: CADC0873, segment: 540\n",
      "End Train for channel: CADC0873, segment: 540\n",
      "Training for channel: CADC0873, segment: 541\n",
      "End Train for channel: CADC0873, segment: 541\n",
      "Training for channel: CADC0873, segment: 542\n",
      "End Train for channel: CADC0873, segment: 542\n",
      "Training for channel: CADC0873, segment: 544\n",
      "End Train for channel: CADC0873, segment: 544\n",
      "Training for channel: CADC0873, segment: 545\n",
      "End Train for channel: CADC0873, segment: 545\n",
      "Training for channel: CADC0873, segment: 548\n",
      "End Train for channel: CADC0873, segment: 548\n",
      "Training for channel: CADC0873, segment: 549\n",
      "End Train for channel: CADC0873, segment: 549\n",
      "Training for channel: CADC0873, segment: 551\n",
      "End Train for channel: CADC0873, segment: 551\n",
      "Training for channel: CADC0873, segment: 552\n",
      "End Train for channel: CADC0873, segment: 552\n",
      "Training for channel: CADC0873, segment: 555\n",
      "End Train for channel: CADC0873, segment: 555\n",
      "Training for channel: CADC0873, segment: 557\n",
      "End Train for channel: CADC0873, segment: 557\n",
      "Training for channel: CADC0873, segment: 559\n",
      "End Train for channel: CADC0873, segment: 559\n",
      "Training for channel: CADC0873, segment: 560\n",
      "End Train for channel: CADC0873, segment: 560\n",
      "Training for channel: CADC0873, segment: 561\n",
      "End Train for channel: CADC0873, segment: 561\n",
      "Training for channel: CADC0873, segment: 562\n",
      "End Train for channel: CADC0873, segment: 562\n",
      "Training for channel: CADC0873, segment: 563\n",
      "End Train for channel: CADC0873, segment: 563\n",
      "Training for channel: CADC0873, segment: 567\n",
      "End Train for channel: CADC0873, segment: 567\n",
      "Training for channel: CADC0873, segment: 568\n",
      "End Train for channel: CADC0873, segment: 568\n",
      "Training for channel: CADC0873, segment: 570\n",
      "End Train for channel: CADC0873, segment: 570\n",
      "Training for channel: CADC0873, segment: 571\n",
      "End Train for channel: CADC0873, segment: 571\n",
      "Training for channel: CADC0873, segment: 572\n",
      "End Train for channel: CADC0873, segment: 572\n",
      "Training for channel: CADC0873, segment: 573\n",
      "End Train for channel: CADC0873, segment: 573\n",
      "Training for channel: CADC0873, segment: 574\n",
      "End Train for channel: CADC0873, segment: 574\n",
      "Training for channel: CADC0873, segment: 575\n",
      "End Train for channel: CADC0873, segment: 575\n",
      "Training for channel: CADC0873, segment: 577\n",
      "End Train for channel: CADC0873, segment: 577\n",
      "Training for channel: CADC0873, segment: 578\n",
      "End Train for channel: CADC0873, segment: 578\n",
      "Training for channel: CADC0873, segment: 579\n",
      "End Train for channel: CADC0873, segment: 579\n",
      "Training for channel: CADC0873, segment: 580\n",
      "End Train for channel: CADC0873, segment: 580\n",
      "Training for channel: CADC0873, segment: 581\n",
      "End Train for channel: CADC0873, segment: 581\n",
      "Training for channel: CADC0873, segment: 583\n",
      "End Train for channel: CADC0873, segment: 583\n",
      "Training for channel: CADC0873, segment: 584\n",
      "End Train for channel: CADC0873, segment: 584\n",
      "Training for channel: CADC0873, segment: 586\n",
      "End Train for channel: CADC0873, segment: 586\n",
      "Training for channel: CADC0873, segment: 587\n",
      "End Train for channel: CADC0873, segment: 587\n",
      "Training for channel: CADC0873, segment: 588\n",
      "End Train for channel: CADC0873, segment: 588\n",
      "Training for channel: CADC0873, segment: 589\n",
      "End Train for channel: CADC0873, segment: 589\n",
      "Training for channel: CADC0873, segment: 592\n",
      "End Train for channel: CADC0873, segment: 592\n",
      "Training for channel: CADC0873, segment: 593\n",
      "End Train for channel: CADC0873, segment: 593\n",
      "Training for channel: CADC0873, segment: 595\n",
      "End Train for channel: CADC0873, segment: 595\n",
      "Training for channel: CADC0873, segment: 596\n",
      "End Train for channel: CADC0873, segment: 596\n",
      "Training for channel: CADC0873, segment: 597\n",
      "End Train for channel: CADC0873, segment: 597\n",
      "Training for channel: CADC0873, segment: 598\n",
      "End Train for channel: CADC0873, segment: 598\n",
      "Training for channel: CADC0873, segment: 599\n",
      "End Train for channel: CADC0873, segment: 599\n",
      "Training for channel: CADC0873, segment: 601\n",
      "End Train for channel: CADC0873, segment: 601\n",
      "Training for channel: CADC0873, segment: 603\n",
      "End Train for channel: CADC0873, segment: 603\n",
      "Training for channel: CADC0873, segment: 604\n",
      "End Train for channel: CADC0873, segment: 604\n",
      "Training for channel: CADC0873, segment: 606\n",
      "End Train for channel: CADC0873, segment: 606\n",
      "Training for channel: CADC0873, segment: 607\n",
      "End Train for channel: CADC0873, segment: 607\n",
      "Training for channel: CADC0873, segment: 608\n",
      "End Train for channel: CADC0873, segment: 608\n",
      "Training for channel: CADC0873, segment: 609\n",
      "End Train for channel: CADC0873, segment: 609\n",
      "Training for channel: CADC0873, segment: 612\n",
      "End Train for channel: CADC0873, segment: 612\n",
      "Training for channel: CADC0873, segment: 613\n",
      "End Train for channel: CADC0873, segment: 613\n",
      "Training for channel: CADC0873, segment: 617\n",
      "End Train for channel: CADC0873, segment: 617\n",
      "Training for channel: CADC0873, segment: 618\n",
      "End Train for channel: CADC0873, segment: 618\n",
      "Training for channel: CADC0873, segment: 619\n",
      "End Train for channel: CADC0873, segment: 619\n",
      "Training for channel: CADC0873, segment: 620\n",
      "End Train for channel: CADC0873, segment: 620\n",
      "Training for channel: CADC0873, segment: 621\n",
      "End Train for channel: CADC0873, segment: 621\n",
      "Training for channel: CADC0873, segment: 622\n",
      "End Train for channel: CADC0873, segment: 622\n",
      "Training for channel: CADC0873, segment: 624\n",
      "End Train for channel: CADC0873, segment: 624\n",
      "Training for channel: CADC0873, segment: 625\n",
      "End Train for channel: CADC0873, segment: 625\n",
      "Training for channel: CADC0873, segment: 626\n",
      "End Train for channel: CADC0873, segment: 626\n",
      "Training for channel: CADC0873, segment: 629\n",
      "End Train for channel: CADC0873, segment: 629\n",
      "Training for channel: CADC0873, segment: 631\n",
      "End Train for channel: CADC0873, segment: 631\n",
      "Training for channel: CADC0873, segment: 634\n",
      "End Train for channel: CADC0873, segment: 634\n",
      "Training for channel: CADC0873, segment: 635\n",
      "End Train for channel: CADC0873, segment: 635\n",
      "Training for channel: CADC0873, segment: 636\n",
      "End Train for channel: CADC0873, segment: 636\n",
      "Training for channel: CADC0873, segment: 637\n",
      "End Train for channel: CADC0873, segment: 637\n",
      "Training for channel: CADC0873, segment: 639\n",
      "End Train for channel: CADC0873, segment: 639\n",
      "Training for channel: CADC0873, segment: 640\n",
      "End Train for channel: CADC0873, segment: 640\n",
      "Training for channel: CADC0873, segment: 641\n",
      "End Train for channel: CADC0873, segment: 641\n",
      "Training for channel: CADC0873, segment: 642\n",
      "End Train for channel: CADC0873, segment: 642\n",
      "Training for channel: CADC0873, segment: 643\n",
      "End Train for channel: CADC0873, segment: 643\n",
      "Training for channel: CADC0873, segment: 644\n",
      "End Train for channel: CADC0873, segment: 644\n",
      "Training for channel: CADC0873, segment: 645\n",
      "End Train for channel: CADC0873, segment: 645\n",
      "Training for channel: CADC0873, segment: 646\n",
      "End Train for channel: CADC0873, segment: 646\n",
      "Training for channel: CADC0873, segment: 648\n",
      "End Train for channel: CADC0873, segment: 648\n",
      "Training for channel: CADC0873, segment: 649\n",
      "End Train for channel: CADC0873, segment: 649\n",
      "Training for channel: CADC0873, segment: 650\n",
      "End Train for channel: CADC0873, segment: 650\n",
      "Training for channel: CADC0873, segment: 651\n",
      "End Train for channel: CADC0873, segment: 651\n",
      "Training for channel: CADC0873, segment: 652\n",
      "End Train for channel: CADC0873, segment: 652\n",
      "Training for channel: CADC0873, segment: 653\n",
      "End Train for channel: CADC0873, segment: 653\n",
      "Training for channel: CADC0873, segment: 654\n",
      "End Train for channel: CADC0873, segment: 654\n",
      "Training for channel: CADC0873, segment: 656\n",
      "End Train for channel: CADC0873, segment: 656\n",
      "Training for channel: CADC0873, segment: 657\n",
      "End Train for channel: CADC0873, segment: 657\n",
      "Training for channel: CADC0873, segment: 658\n",
      "End Train for channel: CADC0873, segment: 658\n",
      "Training for channel: CADC0873, segment: 659\n",
      "End Train for channel: CADC0873, segment: 659\n",
      "Training for channel: CADC0873, segment: 660\n",
      "End Train for channel: CADC0873, segment: 660\n",
      "Training for channel: CADC0873, segment: 661\n",
      "End Train for channel: CADC0873, segment: 661\n",
      "Training for channel: CADC0873, segment: 662\n",
      "End Train for channel: CADC0873, segment: 662\n",
      "Training for channel: CADC0873, segment: 1013\n",
      "End Train for channel: CADC0873, segment: 1013\n",
      "Training for channel: CADC0873, segment: 1014\n",
      "End Train for channel: CADC0873, segment: 1014\n",
      "Training for channel: CADC0873, segment: 1015\n",
      "End Train for channel: CADC0873, segment: 1015\n",
      "Training for channel: CADC0873, segment: 1018\n",
      "End Train for channel: CADC0873, segment: 1018\n",
      "Training for channel: CADC0873, segment: 1019\n",
      "End Train for channel: CADC0873, segment: 1019\n",
      "Training for channel: CADC0873, segment: 1020\n",
      "End Train for channel: CADC0873, segment: 1020\n",
      "Training for channel: CADC0873, segment: 1021\n",
      "End Train for channel: CADC0873, segment: 1021\n",
      "Training for channel: CADC0873, segment: 1022\n",
      "End Train for channel: CADC0873, segment: 1022\n",
      "Training for channel: CADC0873, segment: 1023\n",
      "End Train for channel: CADC0873, segment: 1023\n",
      "Training for channel: CADC0873, segment: 1025\n",
      "End Train for channel: CADC0873, segment: 1025\n",
      "Training for channel: CADC0873, segment: 1026\n",
      "End Train for channel: CADC0873, segment: 1026\n",
      "Training for channel: CADC0873, segment: 1027\n",
      "End Train for channel: CADC0873, segment: 1027\n",
      "Training for channel: CADC0873, segment: 1028\n",
      "End Train for channel: CADC0873, segment: 1028\n",
      "Training for channel: CADC0873, segment: 1029\n",
      "End Train for channel: CADC0873, segment: 1029\n",
      "Training for channel: CADC0873, segment: 1031\n",
      "End Train for channel: CADC0873, segment: 1031\n",
      "Training for channel: CADC0873, segment: 1032\n",
      "End Train for channel: CADC0873, segment: 1032\n",
      "Training for channel: CADC0873, segment: 1033\n",
      "End Train for channel: CADC0873, segment: 1033\n",
      "Training for channel: CADC0873, segment: 1034\n",
      "End Train for channel: CADC0873, segment: 1034\n",
      "Training for channel: CADC0873, segment: 1035\n",
      "End Train for channel: CADC0873, segment: 1035\n",
      "Training for channel: CADC0873, segment: 1036\n",
      "End Train for channel: CADC0873, segment: 1036\n",
      "Training for channel: CADC0873, segment: 1171\n",
      "End Train for channel: CADC0873, segment: 1171\n",
      "Training for channel: CADC0873, segment: 1172\n",
      "End Train for channel: CADC0873, segment: 1172\n",
      "Training for channel: CADC0873, segment: 1173\n",
      "End Train for channel: CADC0873, segment: 1173\n",
      "Training for channel: CADC0873, segment: 1174\n",
      "End Train for channel: CADC0873, segment: 1174\n",
      "Training for channel: CADC0873, segment: 1175\n",
      "End Train for channel: CADC0873, segment: 1175\n",
      "Training for channel: CADC0873, segment: 1178\n",
      "End Train for channel: CADC0873, segment: 1178\n",
      "Training for channel: CADC0873, segment: 1179\n",
      "End Train for channel: CADC0873, segment: 1179\n",
      "Training for channel: CADC0873, segment: 1180\n",
      "End Train for channel: CADC0873, segment: 1180\n",
      "Training for channel: CADC0873, segment: 1181\n",
      "End Train for channel: CADC0873, segment: 1181\n",
      "Training for channel: CADC0873, segment: 1185\n",
      "End Train for channel: CADC0873, segment: 1185\n",
      "Training for channel: CADC0873, segment: 1186\n",
      "End Train for channel: CADC0873, segment: 1186\n",
      "Training for channel: CADC0873, segment: 1187\n",
      "End Train for channel: CADC0873, segment: 1187\n",
      "Training for channel: CADC0873, segment: 1188\n",
      "End Train for channel: CADC0873, segment: 1188\n",
      "Training for channel: CADC0873, segment: 1191\n",
      "End Train for channel: CADC0873, segment: 1191\n",
      "Training for channel: CADC0873, segment: 1192\n",
      "End Train for channel: CADC0873, segment: 1192\n",
      "Training for channel: CADC0873, segment: 1193\n",
      "End Train for channel: CADC0873, segment: 1193\n",
      "Training for channel: CADC0873, segment: 1195\n",
      "End Train for channel: CADC0873, segment: 1195\n",
      "Training for channel: CADC0873, segment: 1196\n",
      "End Train for channel: CADC0873, segment: 1196\n",
      "Training for channel: CADC0873, segment: 1197\n",
      "End Train for channel: CADC0873, segment: 1197\n",
      "Training for channel: CADC0873, segment: 1199\n",
      "End Train for channel: CADC0873, segment: 1199\n",
      "Training for channel: CADC0873, segment: 1200\n",
      "End Train for channel: CADC0873, segment: 1200\n",
      "Training for channel: CADC0873, segment: 1202\n",
      "End Train for channel: CADC0873, segment: 1202\n",
      "Training for channel: CADC0873, segment: 1207\n",
      "End Train for channel: CADC0873, segment: 1207\n",
      "Training for channel: CADC0873, segment: 1208\n",
      "End Train for channel: CADC0873, segment: 1208\n",
      "Training for channel: CADC0873, segment: 1209\n",
      "End Train for channel: CADC0873, segment: 1209\n",
      "Training for channel: CADC0873, segment: 1210\n",
      "End Train for channel: CADC0873, segment: 1210\n",
      "Training for channel: CADC0873, segment: 1211\n",
      "End Train for channel: CADC0873, segment: 1211\n",
      "Training for channel: CADC0873, segment: 1212\n",
      "End Train for channel: CADC0873, segment: 1212\n",
      "Training for channel: CADC0873, segment: 1213\n",
      "End Train for channel: CADC0873, segment: 1213\n",
      "Training for channel: CADC0873, segment: 1214\n",
      "End Train for channel: CADC0873, segment: 1214\n",
      "Training for channel: CADC0873, segment: 1216\n",
      "End Train for channel: CADC0873, segment: 1216\n",
      "Training for channel: CADC0873, segment: 1217\n",
      "End Train for channel: CADC0873, segment: 1217\n",
      "Training for channel: CADC0873, segment: 1218\n",
      "End Train for channel: CADC0873, segment: 1218\n",
      "Training for channel: CADC0873, segment: 1219\n",
      "End Train for channel: CADC0873, segment: 1219\n",
      "Training for channel: CADC0873, segment: 1220\n",
      "End Train for channel: CADC0873, segment: 1220\n",
      "Training for channel: CADC0873, segment: 1222\n",
      "End Train for channel: CADC0873, segment: 1222\n",
      "Training for channel: CADC0873, segment: 1224\n",
      "End Train for channel: CADC0873, segment: 1224\n",
      "Training for channel: CADC0873, segment: 1225\n",
      "End Train for channel: CADC0873, segment: 1225\n",
      "Training for channel: CADC0873, segment: 1226\n",
      "End Train for channel: CADC0873, segment: 1226\n",
      "Training for channel: CADC0873, segment: 1227\n",
      "End Train for channel: CADC0873, segment: 1227\n",
      "Training for channel: CADC0873, segment: 1228\n",
      "End Train for channel: CADC0873, segment: 1228\n",
      "Training for channel: CADC0873, segment: 1229\n",
      "End Train for channel: CADC0873, segment: 1229\n",
      "Training for channel: CADC0873, segment: 1230\n",
      "End Train for channel: CADC0873, segment: 1230\n",
      "Training for channel: CADC0873, segment: 1231\n",
      "End Train for channel: CADC0873, segment: 1231\n",
      "Training for channel: CADC0873, segment: 1232\n",
      "End Train for channel: CADC0873, segment: 1232\n",
      "Training for channel: CADC0873, segment: 1234\n",
      "End Train for channel: CADC0873, segment: 1234\n",
      "Training for channel: CADC0873, segment: 1235\n",
      "End Train for channel: CADC0873, segment: 1235\n",
      "Training for channel: CADC0873, segment: 1236\n",
      "End Train for channel: CADC0873, segment: 1236\n",
      "Training for channel: CADC0873, segment: 1237\n",
      "End Train for channel: CADC0873, segment: 1237\n",
      "Training for channel: CADC0873, segment: 1238\n",
      "End Train for channel: CADC0873, segment: 1238\n",
      "Training for channel: CADC0873, segment: 1239\n",
      "End Train for channel: CADC0873, segment: 1239\n",
      "Training for channel: CADC0873, segment: 1241\n",
      "End Train for channel: CADC0873, segment: 1241\n",
      "Training for channel: CADC0873, segment: 1243\n",
      "End Train for channel: CADC0873, segment: 1243\n",
      "Training for channel: CADC0873, segment: 1244\n",
      "End Train for channel: CADC0873, segment: 1244\n",
      "Training for channel: CADC0873, segment: 1245\n",
      "End Train for channel: CADC0873, segment: 1245\n",
      "Training for channel: CADC0873, segment: 1246\n",
      "End Train for channel: CADC0873, segment: 1246\n",
      "Training for channel: CADC0873, segment: 1247\n",
      "End Train for channel: CADC0873, segment: 1247\n",
      "Training for channel: CADC0873, segment: 1248\n",
      "End Train for channel: CADC0873, segment: 1248\n",
      "Training for channel: CADC0873, segment: 1249\n",
      "End Train for channel: CADC0873, segment: 1249\n",
      "Training for channel: CADC0873, segment: 1250\n",
      "End Train for channel: CADC0873, segment: 1250\n",
      "Training for channel: CADC0873, segment: 1251\n",
      "End Train for channel: CADC0873, segment: 1251\n",
      "Training for channel: CADC0873, segment: 1252\n",
      "End Train for channel: CADC0873, segment: 1252\n",
      "Training for channel: CADC0873, segment: 1254\n",
      "End Train for channel: CADC0873, segment: 1254\n",
      "Training for channel: CADC0873, segment: 1255\n",
      "End Train for channel: CADC0873, segment: 1255\n",
      "Training for channel: CADC0873, segment: 1256\n",
      "End Train for channel: CADC0873, segment: 1256\n",
      "Training for channel: CADC0873, segment: 1258\n",
      "End Train for channel: CADC0873, segment: 1258\n",
      "Training for channel: CADC0873, segment: 1260\n",
      "End Train for channel: CADC0873, segment: 1260\n",
      "Training for channel: CADC0873, segment: 1261\n",
      "End Train for channel: CADC0873, segment: 1261\n",
      "Training for channel: CADC0873, segment: 1263\n",
      "End Train for channel: CADC0873, segment: 1263\n",
      "Training for channel: CADC0873, segment: 1264\n",
      "End Train for channel: CADC0873, segment: 1264\n",
      "Training for channel: CADC0873, segment: 1265\n",
      "End Train for channel: CADC0873, segment: 1265\n",
      "Training for channel: CADC0873, segment: 1266\n",
      "End Train for channel: CADC0873, segment: 1266\n",
      "Training for channel: CADC0873, segment: 1268\n",
      "End Train for channel: CADC0873, segment: 1268\n",
      "Training for channel: CADC0873, segment: 1269\n",
      "End Train for channel: CADC0873, segment: 1269\n",
      "Training for channel: CADC0873, segment: 1270\n",
      "End Train for channel: CADC0873, segment: 1270\n",
      "Training for channel: CADC0873, segment: 1271\n",
      "End Train for channel: CADC0873, segment: 1271\n",
      "Training for channel: CADC0873, segment: 1272\n",
      "End Train for channel: CADC0873, segment: 1272\n",
      "Training for channel: CADC0873, segment: 1274\n",
      "End Train for channel: CADC0873, segment: 1274\n",
      "Training for channel: CADC0873, segment: 1275\n",
      "End Train for channel: CADC0873, segment: 1275\n",
      "Training for channel: CADC0873, segment: 1277\n",
      "End Train for channel: CADC0873, segment: 1277\n",
      "Training for channel: CADC0873, segment: 1279\n",
      "End Train for channel: CADC0873, segment: 1279\n",
      "Training for channel: CADC0873, segment: 1280\n",
      "End Train for channel: CADC0873, segment: 1280\n",
      "Training for channel: CADC0873, segment: 1283\n",
      "End Train for channel: CADC0873, segment: 1283\n",
      "Training for channel: CADC0873, segment: 1284\n",
      "End Train for channel: CADC0873, segment: 1284\n",
      "Training for channel: CADC0873, segment: 1285\n",
      "End Train for channel: CADC0873, segment: 1285\n",
      "Training for channel: CADC0873, segment: 1287\n",
      "End Train for channel: CADC0873, segment: 1287\n",
      "Training for channel: CADC0873, segment: 1289\n",
      "End Train for channel: CADC0873, segment: 1289\n",
      "Training for channel: CADC0873, segment: 1290\n",
      "End Train for channel: CADC0873, segment: 1290\n",
      "Training for channel: CADC0873, segment: 1292\n",
      "End Train for channel: CADC0873, segment: 1292\n",
      "Training for channel: CADC0873, segment: 1294\n",
      "End Train for channel: CADC0873, segment: 1294\n",
      "Training for channel: CADC0873, segment: 1296\n",
      "End Train for channel: CADC0873, segment: 1296\n",
      "Training for channel: CADC0873, segment: 1297\n",
      "End Train for channel: CADC0873, segment: 1297\n",
      "Training for channel: CADC0873, segment: 1298\n",
      "End Train for channel: CADC0873, segment: 1298\n",
      "Training for channel: CADC0873, segment: 1299\n",
      "End Train for channel: CADC0873, segment: 1299\n",
      "Training for channel: CADC0873, segment: 1300\n",
      "End Train for channel: CADC0873, segment: 1300\n",
      "Training for channel: CADC0873, segment: 1301\n",
      "End Train for channel: CADC0873, segment: 1301\n",
      "Training for channel: CADC0873, segment: 1302\n",
      "End Train for channel: CADC0873, segment: 1302\n",
      "Training for channel: CADC0873, segment: 1303\n",
      "End Train for channel: CADC0873, segment: 1303\n",
      "Training for channel: CADC0873, segment: 1305\n",
      "End Train for channel: CADC0873, segment: 1305\n",
      "Training for channel: CADC0873, segment: 1306\n",
      "End Train for channel: CADC0873, segment: 1306\n",
      "Training for channel: CADC0873, segment: 1308\n",
      "End Train for channel: CADC0873, segment: 1308\n",
      "Training for channel: CADC0873, segment: 1310\n",
      "End Train for channel: CADC0873, segment: 1310\n",
      "Training for channel: CADC0873, segment: 1312\n",
      "End Train for channel: CADC0873, segment: 1312\n",
      "Training for channel: CADC0873, segment: 1314\n",
      "End Train for channel: CADC0873, segment: 1314\n",
      "Training for channel: CADC0873, segment: 1315\n",
      "End Train for channel: CADC0873, segment: 1315\n",
      "Training for channel: CADC0873, segment: 1317\n",
      "End Train for channel: CADC0873, segment: 1317\n",
      "Training for channel: CADC0873, segment: 1318\n",
      "End Train for channel: CADC0873, segment: 1318\n",
      "Training for channel: CADC0873, segment: 1319\n",
      "End Train for channel: CADC0873, segment: 1319\n",
      "Training for channel: CADC0873, segment: 1320\n",
      "End Train for channel: CADC0873, segment: 1320\n",
      "Training for channel: CADC0873, segment: 1321\n",
      "End Train for channel: CADC0873, segment: 1321\n",
      "Training for channel: CADC0873, segment: 1322\n",
      "End Train for channel: CADC0873, segment: 1322\n",
      "Training for channel: CADC0873, segment: 1323\n",
      "End Train for channel: CADC0873, segment: 1323\n",
      "Training for channel: CADC0873, segment: 1325\n",
      "End Train for channel: CADC0873, segment: 1325\n",
      "Training for channel: CADC0873, segment: 1326\n",
      "End Train for channel: CADC0873, segment: 1326\n",
      "Training for channel: CADC0873, segment: 1327\n",
      "End Train for channel: CADC0873, segment: 1327\n",
      "Training for channel: CADC0873, segment: 1328\n",
      "End Train for channel: CADC0873, segment: 1328\n",
      "Training for channel: CADC0873, segment: 1332\n",
      "End Train for channel: CADC0873, segment: 1332\n",
      "Training for channel: CADC0873, segment: 1333\n",
      "End Train for channel: CADC0873, segment: 1333\n",
      "Training for channel: CADC0873, segment: 1334\n",
      "End Train for channel: CADC0873, segment: 1334\n",
      "Training for channel: CADC0873, segment: 1335\n",
      "End Train for channel: CADC0873, segment: 1335\n",
      "Training for channel: CADC0873, segment: 1337\n",
      "End Train for channel: CADC0873, segment: 1337\n",
      "Training for channel: CADC0873, segment: 1339\n",
      "End Train for channel: CADC0873, segment: 1339\n",
      "Training for channel: CADC0873, segment: 1340\n",
      "End Train for channel: CADC0873, segment: 1340\n",
      "Training for channel: CADC0873, segment: 1342\n",
      "End Train for channel: CADC0873, segment: 1342\n",
      "Training for channel: CADC0873, segment: 1343\n",
      "End Train for channel: CADC0873, segment: 1343\n",
      "Training for channel: CADC0873, segment: 1344\n",
      "End Train for channel: CADC0873, segment: 1344\n",
      "Training for channel: CADC0873, segment: 1345\n",
      "End Train for channel: CADC0873, segment: 1345\n",
      "Training for channel: CADC0873, segment: 1347\n",
      "End Train for channel: CADC0873, segment: 1347\n",
      "Training for channel: CADC0873, segment: 1348\n",
      "End Train for channel: CADC0873, segment: 1348\n",
      "Training for channel: CADC0873, segment: 1349\n",
      "End Train for channel: CADC0873, segment: 1349\n",
      "Training for channel: CADC0873, segment: 1350\n",
      "End Train for channel: CADC0873, segment: 1350\n",
      "Training for channel: CADC0873, segment: 1351\n",
      "End Train for channel: CADC0873, segment: 1351\n",
      "Training for channel: CADC0873, segment: 1352\n",
      "End Train for channel: CADC0873, segment: 1352\n",
      "Training for channel: CADC0873, segment: 1354\n",
      "End Train for channel: CADC0873, segment: 1354\n",
      "Training for channel: CADC0873, segment: 1355\n",
      "End Train for channel: CADC0873, segment: 1355\n",
      "Training for channel: CADC0873, segment: 1356\n",
      "End Train for channel: CADC0873, segment: 1356\n",
      "Training for channel: CADC0873, segment: 1357\n",
      "End Train for channel: CADC0873, segment: 1357\n",
      "Training for channel: CADC0873, segment: 1358\n",
      "End Train for channel: CADC0873, segment: 1358\n",
      "Training for channel: CADC0873, segment: 1361\n",
      "End Train for channel: CADC0873, segment: 1361\n",
      "Training for channel: CADC0873, segment: 1362\n",
      "End Train for channel: CADC0873, segment: 1362\n",
      "Training for channel: CADC0873, segment: 1363\n",
      "End Train for channel: CADC0873, segment: 1363\n",
      "Training for channel: CADC0873, segment: 1365\n",
      "End Train for channel: CADC0873, segment: 1365\n",
      "Training for channel: CADC0873, segment: 1366\n",
      "End Train for channel: CADC0873, segment: 1366\n",
      "Training for channel: CADC0873, segment: 1367\n",
      "End Train for channel: CADC0873, segment: 1367\n",
      "Training for channel: CADC0873, segment: 1368\n",
      "End Train for channel: CADC0873, segment: 1368\n",
      "Training for channel: CADC0873, segment: 1369\n",
      "End Train for channel: CADC0873, segment: 1369\n",
      "Training for channel: CADC0873, segment: 1370\n",
      "End Train for channel: CADC0873, segment: 1370\n",
      "Training for channel: CADC0873, segment: 1371\n",
      "End Train for channel: CADC0873, segment: 1371\n",
      "Training for channel: CADC0873, segment: 1372\n",
      "End Train for channel: CADC0873, segment: 1372\n",
      "Training for channel: CADC0873, segment: 1375\n",
      "End Train for channel: CADC0873, segment: 1375\n",
      "Training for channel: CADC0873, segment: 1376\n",
      "End Train for channel: CADC0873, segment: 1376\n",
      "Training for channel: CADC0873, segment: 1377\n",
      "End Train for channel: CADC0873, segment: 1377\n",
      "Training for channel: CADC0873, segment: 1378\n",
      "End Train for channel: CADC0873, segment: 1378\n",
      "Training for channel: CADC0873, segment: 1379\n",
      "End Train for channel: CADC0873, segment: 1379\n",
      "Training for channel: CADC0873, segment: 1380\n",
      "End Train for channel: CADC0873, segment: 1380\n",
      "Training for channel: CADC0873, segment: 1382\n",
      "End Train for channel: CADC0873, segment: 1382\n",
      "Training for channel: CADC0873, segment: 1383\n",
      "End Train for channel: CADC0873, segment: 1383\n",
      "Training for channel: CADC0873, segment: 1385\n",
      "End Train for channel: CADC0873, segment: 1385\n",
      "Training for channel: CADC0873, segment: 1386\n",
      "End Train for channel: CADC0873, segment: 1386\n",
      "Training for channel: CADC0873, segment: 1387\n",
      "End Train for channel: CADC0873, segment: 1387\n",
      "Training for channel: CADC0873, segment: 1388\n",
      "End Train for channel: CADC0873, segment: 1388\n",
      "Training for channel: CADC0873, segment: 1390\n",
      "End Train for channel: CADC0873, segment: 1390\n",
      "Training for channel: CADC0873, segment: 1392\n",
      "End Train for channel: CADC0873, segment: 1392\n",
      "Training for channel: CADC0873, segment: 1393\n",
      "End Train for channel: CADC0873, segment: 1393\n",
      "Training for channel: CADC0873, segment: 1395\n",
      "End Train for channel: CADC0873, segment: 1395\n",
      "Training for channel: CADC0873, segment: 1396\n",
      "End Train for channel: CADC0873, segment: 1396\n",
      "Training for channel: CADC0873, segment: 1397\n",
      "End Train for channel: CADC0873, segment: 1397\n",
      "Training for channel: CADC0873, segment: 1398\n",
      "End Train for channel: CADC0873, segment: 1398\n",
      "Training for channel: CADC0873, segment: 1399\n",
      "End Train for channel: CADC0873, segment: 1399\n",
      "Training for channel: CADC0873, segment: 1400\n",
      "End Train for channel: CADC0873, segment: 1400\n",
      "Training for channel: CADC0873, segment: 1404\n",
      "End Train for channel: CADC0873, segment: 1404\n",
      "Training for channel: CADC0873, segment: 1406\n",
      "End Train for channel: CADC0873, segment: 1406\n",
      "Training for channel: CADC0873, segment: 1407\n",
      "End Train for channel: CADC0873, segment: 1407\n",
      "Training for channel: CADC0873, segment: 1409\n",
      "End Train for channel: CADC0873, segment: 1409\n",
      "Training for channel: CADC0873, segment: 1410\n",
      "End Train for channel: CADC0873, segment: 1410\n",
      "Training for channel: CADC0873, segment: 1413\n",
      "End Train for channel: CADC0873, segment: 1413\n",
      "Training for channel: CADC0873, segment: 1414\n",
      "End Train for channel: CADC0873, segment: 1414\n",
      "Training for channel: CADC0873, segment: 1415\n",
      "End Train for channel: CADC0873, segment: 1415\n",
      "Training for channel: CADC0873, segment: 1416\n",
      "End Train for channel: CADC0873, segment: 1416\n",
      "Training for channel: CADC0873, segment: 1417\n",
      "End Train for channel: CADC0873, segment: 1417\n",
      "Training for channel: CADC0873, segment: 1418\n",
      "End Train for channel: CADC0873, segment: 1418\n",
      "Training for channel: CADC0873, segment: 1419\n",
      "End Train for channel: CADC0873, segment: 1419\n",
      "Training for channel: CADC0873, segment: 1420\n",
      "End Train for channel: CADC0873, segment: 1420\n",
      "Training for channel: CADC0873, segment: 1421\n",
      "End Train for channel: CADC0873, segment: 1421\n",
      "Training for channel: CADC0873, segment: 1423\n",
      "End Train for channel: CADC0873, segment: 1423\n",
      "Training for channel: CADC0873, segment: 1424\n",
      "End Train for channel: CADC0873, segment: 1424\n",
      "Training for channel: CADC0873, segment: 1425\n",
      "End Train for channel: CADC0873, segment: 1425\n",
      "Training for channel: CADC0873, segment: 1426\n",
      "End Train for channel: CADC0873, segment: 1426\n",
      "Training for channel: CADC0873, segment: 1427\n",
      "End Train for channel: CADC0873, segment: 1427\n",
      "Training for channel: CADC0873, segment: 1428\n",
      "End Train for channel: CADC0873, segment: 1428\n",
      "Training for channel: CADC0873, segment: 1429\n",
      "End Train for channel: CADC0873, segment: 1429\n",
      "Training for channel: CADC0873, segment: 1431\n",
      "End Train for channel: CADC0873, segment: 1431\n",
      "Training for channel: CADC0873, segment: 1432\n",
      "End Train for channel: CADC0873, segment: 1432\n",
      "Training for channel: CADC0873, segment: 1433\n",
      "End Train for channel: CADC0873, segment: 1433\n",
      "Training for channel: CADC0873, segment: 1434\n",
      "End Train for channel: CADC0873, segment: 1434\n",
      "Training for channel: CADC0873, segment: 1435\n",
      "End Train for channel: CADC0873, segment: 1435\n",
      "Training for channel: CADC0873, segment: 1436\n",
      "End Train for channel: CADC0873, segment: 1436\n",
      "Training for channel: CADC0873, segment: 1438\n",
      "End Train for channel: CADC0873, segment: 1438\n",
      "Training for channel: CADC0873, segment: 1439\n",
      "End Train for channel: CADC0873, segment: 1439\n",
      "Training for channel: CADC0873, segment: 1440\n",
      "End Train for channel: CADC0873, segment: 1440\n",
      "Training for channel: CADC0873, segment: 1441\n",
      "End Train for channel: CADC0873, segment: 1441\n",
      "Training for channel: CADC0873, segment: 1442\n",
      "End Train for channel: CADC0873, segment: 1442\n",
      "Training for channel: CADC0873, segment: 1443\n",
      "End Train for channel: CADC0873, segment: 1443\n",
      "Training for channel: CADC0873, segment: 1444\n",
      "End Train for channel: CADC0873, segment: 1444\n",
      "Training for channel: CADC0873, segment: 1447\n",
      "End Train for channel: CADC0873, segment: 1447\n",
      "Training for channel: CADC0873, segment: 1448\n",
      "End Train for channel: CADC0873, segment: 1448\n",
      "Training for channel: CADC0873, segment: 1449\n",
      "End Train for channel: CADC0873, segment: 1449\n",
      "Training for channel: CADC0873, segment: 1450\n",
      "End Train for channel: CADC0873, segment: 1450\n",
      "Training for channel: CADC0873, segment: 1451\n",
      "End Train for channel: CADC0873, segment: 1451\n",
      "Training for channel: CADC0873, segment: 1452\n",
      "End Train for channel: CADC0873, segment: 1452\n",
      "Training for channel: CADC0873, segment: 1453\n",
      "End Train for channel: CADC0873, segment: 1453\n",
      "Training for channel: CADC0873, segment: 1454\n",
      "End Train for channel: CADC0873, segment: 1454\n",
      "Training for channel: CADC0873, segment: 1455\n",
      "End Train for channel: CADC0873, segment: 1455\n",
      "Training for channel: CADC0873, segment: 1457\n",
      "End Train for channel: CADC0873, segment: 1457\n",
      "Training for channel: CADC0873, segment: 1458\n",
      "End Train for channel: CADC0873, segment: 1458\n",
      "Training for channel: CADC0873, segment: 1459\n",
      "End Train for channel: CADC0873, segment: 1459\n",
      "Training for channel: CADC0873, segment: 1461\n",
      "End Train for channel: CADC0873, segment: 1461\n",
      "Training for channel: CADC0873, segment: 1463\n",
      "End Train for channel: CADC0873, segment: 1463\n",
      "Training for channel: CADC0873, segment: 1464\n",
      "End Train for channel: CADC0873, segment: 1464\n",
      "Training for channel: CADC0873, segment: 1467\n",
      "End Train for channel: CADC0873, segment: 1467\n",
      "Training for channel: CADC0873, segment: 1468\n",
      "End Train for channel: CADC0873, segment: 1468\n",
      "Training for channel: CADC0873, segment: 1469\n",
      "End Train for channel: CADC0873, segment: 1469\n",
      "Training for channel: CADC0873, segment: 1470\n",
      "End Train for channel: CADC0873, segment: 1470\n",
      "Training for channel: CADC0873, segment: 1474\n",
      "End Train for channel: CADC0873, segment: 1474\n",
      "Training for channel: CADC0873, segment: 1476\n",
      "End Train for channel: CADC0873, segment: 1476\n",
      "Training for channel: CADC0873, segment: 1479\n",
      "End Train for channel: CADC0873, segment: 1479\n",
      "Training for channel: CADC0873, segment: 1480\n",
      "End Train for channel: CADC0873, segment: 1480\n",
      "Training for channel: CADC0873, segment: 1481\n",
      "End Train for channel: CADC0873, segment: 1481\n",
      "Training for channel: CADC0873, segment: 1484\n",
      "End Train for channel: CADC0873, segment: 1484\n",
      "Training for channel: CADC0873, segment: 1485\n",
      "End Train for channel: CADC0873, segment: 1485\n",
      "Training for channel: CADC0873, segment: 1487\n",
      "End Train for channel: CADC0873, segment: 1487\n",
      "Training for channel: CADC0873, segment: 1489\n",
      "End Train for channel: CADC0873, segment: 1489\n",
      "Training for channel: CADC0873, segment: 1490\n",
      "End Train for channel: CADC0873, segment: 1490\n",
      "Training for channel: CADC0873, segment: 1491\n",
      "End Train for channel: CADC0873, segment: 1491\n",
      "Training for channel: CADC0873, segment: 1492\n",
      "End Train for channel: CADC0873, segment: 1492\n",
      "Training for channel: CADC0873, segment: 1496\n",
      "End Train for channel: CADC0873, segment: 1496\n",
      "Training for channel: CADC0873, segment: 1497\n",
      "End Train for channel: CADC0873, segment: 1497\n",
      "Training for channel: CADC0873, segment: 1499\n",
      "End Train for channel: CADC0873, segment: 1499\n",
      "Training for channel: CADC0873, segment: 1500\n",
      "End Train for channel: CADC0873, segment: 1500\n",
      "Training for channel: CADC0873, segment: 1502\n",
      "End Train for channel: CADC0873, segment: 1502\n",
      "Training for channel: CADC0873, segment: 1503\n",
      "End Train for channel: CADC0873, segment: 1503\n",
      "Training for channel: CADC0873, segment: 1504\n",
      "End Train for channel: CADC0873, segment: 1504\n",
      "Training for channel: CADC0873, segment: 1505\n",
      "End Train for channel: CADC0873, segment: 1505\n",
      "Training for channel: CADC0873, segment: 1506\n",
      "End Train for channel: CADC0873, segment: 1506\n",
      "Training for channel: CADC0873, segment: 1507\n",
      "End Train for channel: CADC0873, segment: 1507\n",
      "Training for channel: CADC0873, segment: 1508\n",
      "End Train for channel: CADC0873, segment: 1508\n",
      "Training for channel: CADC0873, segment: 1509\n",
      "End Train for channel: CADC0873, segment: 1509\n",
      "Training for channel: CADC0873, segment: 1510\n",
      "End Train for channel: CADC0873, segment: 1510\n",
      "Training for channel: CADC0873, segment: 1513\n",
      "End Train for channel: CADC0873, segment: 1513\n",
      "Training for channel: CADC0873, segment: 1514\n",
      "End Train for channel: CADC0873, segment: 1514\n",
      "Training for channel: CADC0873, segment: 1515\n",
      "End Train for channel: CADC0873, segment: 1515\n",
      "Training for channel: CADC0873, segment: 1516\n",
      "End Train for channel: CADC0873, segment: 1516\n",
      "Training for channel: CADC0873, segment: 1517\n",
      "End Train for channel: CADC0873, segment: 1517\n",
      "Training for channel: CADC0873, segment: 1519\n",
      "End Train for channel: CADC0873, segment: 1519\n",
      "Training for channel: CADC0886, segment: 810\n",
      "End Train for channel: CADC0886, segment: 810\n",
      "Training for channel: CADC0886, segment: 811\n",
      "End Train for channel: CADC0886, segment: 811\n",
      "Training for channel: CADC0886, segment: 812\n",
      "End Train for channel: CADC0886, segment: 812\n",
      "Training for channel: CADC0886, segment: 815\n",
      "End Train for channel: CADC0886, segment: 815\n",
      "Training for channel: CADC0886, segment: 816\n",
      "End Train for channel: CADC0886, segment: 816\n",
      "Training for channel: CADC0886, segment: 818\n",
      "End Train for channel: CADC0886, segment: 818\n",
      "Training for channel: CADC0886, segment: 819\n",
      "End Train for channel: CADC0886, segment: 819\n",
      "Training for channel: CADC0888, segment: 1037\n",
      "End Train for channel: CADC0888, segment: 1037\n",
      "Training for channel: CADC0888, segment: 1040\n",
      "End Train for channel: CADC0888, segment: 1040\n",
      "Training for channel: CADC0888, segment: 1042\n",
      "End Train for channel: CADC0888, segment: 1042\n",
      "Training for channel: CADC0888, segment: 1043\n",
      "End Train for channel: CADC0888, segment: 1043\n",
      "Training for channel: CADC0888, segment: 1044\n",
      "End Train for channel: CADC0888, segment: 1044\n",
      "Training for channel: CADC0888, segment: 1045\n",
      "End Train for channel: CADC0888, segment: 1045\n",
      "Training for channel: CADC0888, segment: 1046\n",
      "End Train for channel: CADC0888, segment: 1046\n",
      "Training for channel: CADC0888, segment: 1048\n",
      "End Train for channel: CADC0888, segment: 1048\n",
      "Training for channel: CADC0888, segment: 1049\n",
      "End Train for channel: CADC0888, segment: 1049\n",
      "Training for channel: CADC0888, segment: 1050\n",
      "End Train for channel: CADC0888, segment: 1050\n",
      "Training for channel: CADC0888, segment: 1051\n",
      "End Train for channel: CADC0888, segment: 1051\n",
      "Training for channel: CADC0888, segment: 1052\n",
      "End Train for channel: CADC0888, segment: 1052\n",
      "Training for channel: CADC0888, segment: 1055\n",
      "End Train for channel: CADC0888, segment: 1055\n",
      "Training for channel: CADC0888, segment: 1056\n",
      "End Train for channel: CADC0888, segment: 1056\n",
      "Training for channel: CADC0888, segment: 1057\n",
      "End Train for channel: CADC0888, segment: 1057\n",
      "Training for channel: CADC0888, segment: 1059\n",
      "End Train for channel: CADC0888, segment: 1059\n",
      "Training for channel: CADC0888, segment: 1060\n",
      "End Train for channel: CADC0888, segment: 1060\n",
      "Training for channel: CADC0888, segment: 1061\n",
      "End Train for channel: CADC0888, segment: 1061\n",
      "Training for channel: CADC0888, segment: 1062\n",
      "End Train for channel: CADC0888, segment: 1062\n",
      "Training for channel: CADC0888, segment: 1063\n",
      "End Train for channel: CADC0888, segment: 1063\n",
      "Training for channel: CADC0888, segment: 1064\n",
      "End Train for channel: CADC0888, segment: 1064\n",
      "Training for channel: CADC0888, segment: 1065\n",
      "End Train for channel: CADC0888, segment: 1065\n",
      "Training for channel: CADC0888, segment: 1067\n",
      "End Train for channel: CADC0888, segment: 1067\n",
      "Training for channel: CADC0888, segment: 1069\n",
      "End Train for channel: CADC0888, segment: 1069\n",
      "Training for channel: CADC0888, segment: 1070\n",
      "End Train for channel: CADC0888, segment: 1070\n",
      "Training for channel: CADC0888, segment: 1071\n",
      "End Train for channel: CADC0888, segment: 1071\n",
      "Training for channel: CADC0888, segment: 1073\n",
      "End Train for channel: CADC0888, segment: 1073\n",
      "Training for channel: CADC0888, segment: 1074\n",
      "End Train for channel: CADC0888, segment: 1074\n",
      "Training for channel: CADC0888, segment: 1075\n",
      "End Train for channel: CADC0888, segment: 1075\n",
      "Training for channel: CADC0888, segment: 1076\n",
      "End Train for channel: CADC0888, segment: 1076\n",
      "Training for channel: CADC0888, segment: 1077\n",
      "End Train for channel: CADC0888, segment: 1077\n",
      "Training for channel: CADC0888, segment: 1078\n",
      "End Train for channel: CADC0888, segment: 1078\n",
      "Training for channel: CADC0888, segment: 1080\n",
      "End Train for channel: CADC0888, segment: 1080\n",
      "Training for channel: CADC0888, segment: 1081\n",
      "End Train for channel: CADC0888, segment: 1081\n",
      "Training for channel: CADC0888, segment: 1082\n",
      "End Train for channel: CADC0888, segment: 1082\n",
      "Training for channel: CADC0888, segment: 1083\n",
      "End Train for channel: CADC0888, segment: 1083\n",
      "Training for channel: CADC0888, segment: 1084\n",
      "End Train for channel: CADC0888, segment: 1084\n",
      "Training for channel: CADC0888, segment: 1086\n",
      "End Train for channel: CADC0888, segment: 1086\n",
      "Training for channel: CADC0888, segment: 1087\n",
      "End Train for channel: CADC0888, segment: 1087\n",
      "Training for channel: CADC0888, segment: 1088\n",
      "End Train for channel: CADC0888, segment: 1088\n",
      "Training for channel: CADC0888, segment: 1089\n",
      "End Train for channel: CADC0888, segment: 1089\n",
      "Training for channel: CADC0888, segment: 1090\n",
      "End Train for channel: CADC0888, segment: 1090\n",
      "Training for channel: CADC0888, segment: 1091\n",
      "End Train for channel: CADC0888, segment: 1091\n",
      "Training for channel: CADC0888, segment: 1092\n",
      "End Train for channel: CADC0888, segment: 1092\n",
      "Training for channel: CADC0888, segment: 1093\n",
      "End Train for channel: CADC0888, segment: 1093\n",
      "Training for channel: CADC0888, segment: 1094\n",
      "End Train for channel: CADC0888, segment: 1094\n",
      "Training for channel: CADC0888, segment: 1520\n",
      "End Train for channel: CADC0888, segment: 1520\n",
      "Training for channel: CADC0888, segment: 1521\n",
      "End Train for channel: CADC0888, segment: 1521\n",
      "Training for channel: CADC0888, segment: 1523\n",
      "End Train for channel: CADC0888, segment: 1523\n",
      "Training for channel: CADC0888, segment: 1526\n",
      "End Train for channel: CADC0888, segment: 1526\n",
      "Training for channel: CADC0888, segment: 1528\n",
      "End Train for channel: CADC0888, segment: 1528\n",
      "Training for channel: CADC0888, segment: 1529\n",
      "End Train for channel: CADC0888, segment: 1529\n",
      "Training for channel: CADC0888, segment: 1530\n",
      "End Train for channel: CADC0888, segment: 1530\n",
      "Training for channel: CADC0888, segment: 1531\n",
      "End Train for channel: CADC0888, segment: 1531\n",
      "Training for channel: CADC0888, segment: 1532\n",
      "End Train for channel: CADC0888, segment: 1532\n",
      "Training for channel: CADC0888, segment: 1533\n",
      "End Train for channel: CADC0888, segment: 1533\n",
      "Training for channel: CADC0888, segment: 1534\n",
      "End Train for channel: CADC0888, segment: 1534\n",
      "Training for channel: CADC0888, segment: 1535\n",
      "End Train for channel: CADC0888, segment: 1535\n",
      "Training for channel: CADC0888, segment: 1536\n",
      "End Train for channel: CADC0888, segment: 1536\n",
      "Training for channel: CADC0888, segment: 1537\n",
      "End Train for channel: CADC0888, segment: 1537\n",
      "Training for channel: CADC0888, segment: 1538\n",
      "End Train for channel: CADC0888, segment: 1538\n",
      "Training for channel: CADC0888, segment: 1539\n",
      "End Train for channel: CADC0888, segment: 1539\n",
      "Training for channel: CADC0888, segment: 1540\n",
      "End Train for channel: CADC0888, segment: 1540\n",
      "Training for channel: CADC0888, segment: 1541\n",
      "End Train for channel: CADC0888, segment: 1541\n",
      "Training for channel: CADC0888, segment: 1543\n",
      "End Train for channel: CADC0888, segment: 1543\n",
      "Training for channel: CADC0888, segment: 1544\n",
      "End Train for channel: CADC0888, segment: 1544\n",
      "Training for channel: CADC0888, segment: 1545\n",
      "End Train for channel: CADC0888, segment: 1545\n",
      "Training for channel: CADC0888, segment: 1546\n",
      "End Train for channel: CADC0888, segment: 1546\n",
      "Training for channel: CADC0888, segment: 1547\n",
      "End Train for channel: CADC0888, segment: 1547\n",
      "Training for channel: CADC0888, segment: 1548\n",
      "End Train for channel: CADC0888, segment: 1548\n",
      "Training for channel: CADC0888, segment: 1552\n",
      "End Train for channel: CADC0888, segment: 1552\n",
      "Training for channel: CADC0888, segment: 1553\n",
      "End Train for channel: CADC0888, segment: 1553\n",
      "Training for channel: CADC0888, segment: 1555\n",
      "End Train for channel: CADC0888, segment: 1555\n",
      "Training for channel: CADC0888, segment: 1556\n",
      "End Train for channel: CADC0888, segment: 1556\n",
      "Training for channel: CADC0888, segment: 1557\n",
      "End Train for channel: CADC0888, segment: 1557\n",
      "Training for channel: CADC0888, segment: 1559\n",
      "End Train for channel: CADC0888, segment: 1559\n",
      "Training for channel: CADC0888, segment: 1561\n",
      "End Train for channel: CADC0888, segment: 1561\n",
      "Training for channel: CADC0888, segment: 1563\n",
      "End Train for channel: CADC0888, segment: 1563\n",
      "Training for channel: CADC0888, segment: 1564\n",
      "End Train for channel: CADC0888, segment: 1564\n",
      "Training for channel: CADC0888, segment: 1565\n",
      "End Train for channel: CADC0888, segment: 1565\n",
      "Training for channel: CADC0888, segment: 1566\n",
      "End Train for channel: CADC0888, segment: 1566\n",
      "Training for channel: CADC0888, segment: 1567\n",
      "End Train for channel: CADC0888, segment: 1567\n",
      "Training for channel: CADC0888, segment: 1568\n",
      "End Train for channel: CADC0888, segment: 1568\n",
      "Training for channel: CADC0888, segment: 1570\n",
      "End Train for channel: CADC0888, segment: 1570\n",
      "Training for channel: CADC0888, segment: 1572\n",
      "End Train for channel: CADC0888, segment: 1572\n",
      "Training for channel: CADC0888, segment: 1576\n",
      "End Train for channel: CADC0888, segment: 1576\n",
      "Training for channel: CADC0888, segment: 1577\n",
      "End Train for channel: CADC0888, segment: 1577\n",
      "Training for channel: CADC0888, segment: 1578\n",
      "End Train for channel: CADC0888, segment: 1578\n",
      "Training for channel: CADC0888, segment: 1581\n",
      "End Train for channel: CADC0888, segment: 1581\n",
      "Training for channel: CADC0888, segment: 1582\n",
      "End Train for channel: CADC0888, segment: 1582\n",
      "Training for channel: CADC0888, segment: 1583\n",
      "End Train for channel: CADC0888, segment: 1583\n",
      "Training for channel: CADC0888, segment: 1586\n",
      "End Train for channel: CADC0888, segment: 1586\n",
      "Training for channel: CADC0888, segment: 1589\n",
      "End Train for channel: CADC0888, segment: 1589\n",
      "Training for channel: CADC0888, segment: 1590\n",
      "End Train for channel: CADC0888, segment: 1590\n",
      "Training for channel: CADC0888, segment: 1592\n",
      "End Train for channel: CADC0888, segment: 1592\n",
      "Training for channel: CADC0888, segment: 1593\n",
      "End Train for channel: CADC0888, segment: 1593\n",
      "Training for channel: CADC0888, segment: 1594\n",
      "End Train for channel: CADC0888, segment: 1594\n",
      "Training for channel: CADC0888, segment: 1596\n",
      "End Train for channel: CADC0888, segment: 1596\n",
      "Training for channel: CADC0888, segment: 1597\n",
      "End Train for channel: CADC0888, segment: 1597\n",
      "Training for channel: CADC0888, segment: 1598\n",
      "End Train for channel: CADC0888, segment: 1598\n",
      "Training for channel: CADC0888, segment: 1599\n",
      "End Train for channel: CADC0888, segment: 1599\n",
      "Training for channel: CADC0888, segment: 1602\n",
      "End Train for channel: CADC0888, segment: 1602\n",
      "Training for channel: CADC0888, segment: 1604\n",
      "End Train for channel: CADC0888, segment: 1604\n",
      "Training for channel: CADC0888, segment: 1605\n",
      "End Train for channel: CADC0888, segment: 1605\n",
      "Training for channel: CADC0888, segment: 1606\n",
      "End Train for channel: CADC0888, segment: 1606\n",
      "Training for channel: CADC0888, segment: 1607\n",
      "End Train for channel: CADC0888, segment: 1607\n",
      "Training for channel: CADC0888, segment: 1608\n",
      "End Train for channel: CADC0888, segment: 1608\n",
      "Training for channel: CADC0888, segment: 1609\n",
      "End Train for channel: CADC0888, segment: 1609\n",
      "Training for channel: CADC0888, segment: 1610\n",
      "End Train for channel: CADC0888, segment: 1610\n",
      "Training for channel: CADC0888, segment: 1611\n",
      "End Train for channel: CADC0888, segment: 1611\n",
      "Training for channel: CADC0888, segment: 1612\n",
      "End Train for channel: CADC0888, segment: 1612\n",
      "Training for channel: CADC0888, segment: 1615\n",
      "End Train for channel: CADC0888, segment: 1615\n",
      "Training for channel: CADC0888, segment: 1616\n",
      "End Train for channel: CADC0888, segment: 1616\n",
      "Training for channel: CADC0888, segment: 1619\n",
      "End Train for channel: CADC0888, segment: 1619\n",
      "Training for channel: CADC0888, segment: 1621\n",
      "End Train for channel: CADC0888, segment: 1621\n",
      "Training for channel: CADC0888, segment: 1622\n",
      "End Train for channel: CADC0888, segment: 1622\n",
      "Training for channel: CADC0888, segment: 1623\n",
      "End Train for channel: CADC0888, segment: 1623\n",
      "Training for channel: CADC0888, segment: 1624\n",
      "End Train for channel: CADC0888, segment: 1624\n",
      "Training for channel: CADC0888, segment: 1625\n",
      "End Train for channel: CADC0888, segment: 1625\n",
      "Training for channel: CADC0888, segment: 1626\n",
      "End Train for channel: CADC0888, segment: 1626\n",
      "Training for channel: CADC0888, segment: 1627\n",
      "End Train for channel: CADC0888, segment: 1627\n",
      "Training for channel: CADC0888, segment: 1628\n",
      "End Train for channel: CADC0888, segment: 1628\n",
      "Training for channel: CADC0888, segment: 1629\n",
      "End Train for channel: CADC0888, segment: 1629\n",
      "Training for channel: CADC0888, segment: 1630\n",
      "End Train for channel: CADC0888, segment: 1630\n",
      "Training for channel: CADC0888, segment: 1631\n",
      "End Train for channel: CADC0888, segment: 1631\n",
      "Training for channel: CADC0888, segment: 1632\n",
      "End Train for channel: CADC0888, segment: 1632\n",
      "Training for channel: CADC0888, segment: 1634\n",
      "End Train for channel: CADC0888, segment: 1634\n",
      "Training for channel: CADC0888, segment: 1635\n",
      "End Train for channel: CADC0888, segment: 1635\n",
      "Training for channel: CADC0888, segment: 1636\n",
      "End Train for channel: CADC0888, segment: 1636\n",
      "Training for channel: CADC0888, segment: 1637\n",
      "End Train for channel: CADC0888, segment: 1637\n",
      "Training for channel: CADC0888, segment: 1638\n",
      "End Train for channel: CADC0888, segment: 1638\n",
      "Training for channel: CADC0888, segment: 1640\n",
      "End Train for channel: CADC0888, segment: 1640\n",
      "Training for channel: CADC0888, segment: 1641\n",
      "End Train for channel: CADC0888, segment: 1641\n",
      "Training for channel: CADC0888, segment: 1642\n",
      "End Train for channel: CADC0888, segment: 1642\n",
      "Training for channel: CADC0888, segment: 1644\n",
      "End Train for channel: CADC0888, segment: 1644\n",
      "Training for channel: CADC0888, segment: 1645\n",
      "End Train for channel: CADC0888, segment: 1645\n",
      "Training for channel: CADC0888, segment: 1646\n",
      "End Train for channel: CADC0888, segment: 1646\n",
      "Training for channel: CADC0888, segment: 1647\n",
      "End Train for channel: CADC0888, segment: 1647\n",
      "Training for channel: CADC0888, segment: 1648\n",
      "End Train for channel: CADC0888, segment: 1648\n",
      "Training for channel: CADC0888, segment: 1650\n",
      "End Train for channel: CADC0888, segment: 1650\n",
      "Training for channel: CADC0888, segment: 1651\n",
      "End Train for channel: CADC0888, segment: 1651\n",
      "Training for channel: CADC0888, segment: 1652\n",
      "End Train for channel: CADC0888, segment: 1652\n",
      "Training for channel: CADC0888, segment: 1653\n",
      "End Train for channel: CADC0888, segment: 1653\n",
      "Training for channel: CADC0888, segment: 1654\n",
      "End Train for channel: CADC0888, segment: 1654\n",
      "Training for channel: CADC0888, segment: 1655\n",
      "End Train for channel: CADC0888, segment: 1655\n",
      "Training for channel: CADC0888, segment: 1656\n",
      "End Train for channel: CADC0888, segment: 1656\n",
      "Training for channel: CADC0888, segment: 1658\n",
      "End Train for channel: CADC0888, segment: 1658\n",
      "Training for channel: CADC0888, segment: 1660\n",
      "End Train for channel: CADC0888, segment: 1660\n",
      "Training for channel: CADC0888, segment: 1661\n",
      "End Train for channel: CADC0888, segment: 1661\n",
      "Training for channel: CADC0888, segment: 1662\n",
      "End Train for channel: CADC0888, segment: 1662\n",
      "Training for channel: CADC0888, segment: 1663\n",
      "End Train for channel: CADC0888, segment: 1663\n",
      "Training for channel: CADC0888, segment: 1664\n",
      "End Train for channel: CADC0888, segment: 1664\n",
      "Training for channel: CADC0888, segment: 1668\n",
      "End Train for channel: CADC0888, segment: 1668\n",
      "Training for channel: CADC0888, segment: 1670\n",
      "End Train for channel: CADC0888, segment: 1670\n",
      "Training for channel: CADC0888, segment: 1671\n",
      "End Train for channel: CADC0888, segment: 1671\n",
      "Training for channel: CADC0888, segment: 1672\n",
      "End Train for channel: CADC0888, segment: 1672\n",
      "Training for channel: CADC0888, segment: 1673\n",
      "End Train for channel: CADC0888, segment: 1673\n",
      "Training for channel: CADC0888, segment: 1674\n",
      "End Train for channel: CADC0888, segment: 1674\n",
      "Training for channel: CADC0888, segment: 1675\n",
      "End Train for channel: CADC0888, segment: 1675\n",
      "Training for channel: CADC0888, segment: 1677\n",
      "End Train for channel: CADC0888, segment: 1677\n",
      "Training for channel: CADC0888, segment: 1678\n",
      "End Train for channel: CADC0888, segment: 1678\n",
      "Training for channel: CADC0888, segment: 1679\n",
      "End Train for channel: CADC0888, segment: 1679\n",
      "Training for channel: CADC0888, segment: 1680\n",
      "End Train for channel: CADC0888, segment: 1680\n",
      "Training for channel: CADC0888, segment: 1681\n",
      "End Train for channel: CADC0888, segment: 1681\n",
      "Training for channel: CADC0888, segment: 1682\n",
      "End Train for channel: CADC0888, segment: 1682\n",
      "Training for channel: CADC0888, segment: 1683\n",
      "End Train for channel: CADC0888, segment: 1683\n",
      "Training for channel: CADC0888, segment: 1684\n",
      "End Train for channel: CADC0888, segment: 1684\n",
      "Training for channel: CADC0888, segment: 1687\n",
      "End Train for channel: CADC0888, segment: 1687\n",
      "Training for channel: CADC0888, segment: 1688\n",
      "End Train for channel: CADC0888, segment: 1688\n",
      "Training for channel: CADC0888, segment: 1689\n",
      "End Train for channel: CADC0888, segment: 1689\n",
      "Training for channel: CADC0888, segment: 1690\n",
      "End Train for channel: CADC0888, segment: 1690\n",
      "Training for channel: CADC0888, segment: 1691\n",
      "End Train for channel: CADC0888, segment: 1691\n",
      "Training for channel: CADC0888, segment: 1692\n",
      "End Train for channel: CADC0888, segment: 1692\n",
      "Training for channel: CADC0888, segment: 1693\n",
      "End Train for channel: CADC0888, segment: 1693\n",
      "Training for channel: CADC0888, segment: 1694\n",
      "End Train for channel: CADC0888, segment: 1694\n",
      "Training for channel: CADC0888, segment: 1695\n",
      "End Train for channel: CADC0888, segment: 1695\n",
      "Training for channel: CADC0888, segment: 1696\n",
      "End Train for channel: CADC0888, segment: 1696\n",
      "Training for channel: CADC0888, segment: 1697\n",
      "End Train for channel: CADC0888, segment: 1697\n",
      "Training for channel: CADC0888, segment: 1698\n",
      "End Train for channel: CADC0888, segment: 1698\n",
      "Training for channel: CADC0888, segment: 1701\n",
      "End Train for channel: CADC0888, segment: 1701\n",
      "Training for channel: CADC0888, segment: 1702\n",
      "End Train for channel: CADC0888, segment: 1702\n",
      "Training for channel: CADC0888, segment: 1703\n",
      "End Train for channel: CADC0888, segment: 1703\n",
      "Training for channel: CADC0888, segment: 1705\n",
      "End Train for channel: CADC0888, segment: 1705\n",
      "Training for channel: CADC0888, segment: 1706\n",
      "End Train for channel: CADC0888, segment: 1706\n",
      "Training for channel: CADC0888, segment: 1707\n",
      "End Train for channel: CADC0888, segment: 1707\n",
      "Training for channel: CADC0888, segment: 1708\n",
      "End Train for channel: CADC0888, segment: 1708\n",
      "Training for channel: CADC0888, segment: 1711\n",
      "End Train for channel: CADC0888, segment: 1711\n",
      "Training for channel: CADC0888, segment: 1713\n",
      "End Train for channel: CADC0888, segment: 1713\n",
      "Training for channel: CADC0894, segment: 1095\n",
      "End Train for channel: CADC0894, segment: 1095\n",
      "Training for channel: CADC0894, segment: 1096\n",
      "End Train for channel: CADC0894, segment: 1096\n",
      "Training for channel: CADC0894, segment: 1097\n",
      "End Train for channel: CADC0894, segment: 1097\n",
      "Training for channel: CADC0894, segment: 1098\n",
      "End Train for channel: CADC0894, segment: 1098\n",
      "Training for channel: CADC0894, segment: 1099\n",
      "End Train for channel: CADC0894, segment: 1099\n",
      "Training for channel: CADC0894, segment: 1100\n",
      "End Train for channel: CADC0894, segment: 1100\n",
      "Training for channel: CADC0894, segment: 1101\n",
      "End Train for channel: CADC0894, segment: 1101\n",
      "Training for channel: CADC0894, segment: 1103\n",
      "End Train for channel: CADC0894, segment: 1103\n",
      "Training for channel: CADC0894, segment: 1104\n",
      "End Train for channel: CADC0894, segment: 1104\n",
      "Training for channel: CADC0894, segment: 1106\n",
      "End Train for channel: CADC0894, segment: 1106\n",
      "Training for channel: CADC0894, segment: 1107\n",
      "End Train for channel: CADC0894, segment: 1107\n",
      "Training for channel: CADC0894, segment: 1108\n",
      "End Train for channel: CADC0894, segment: 1108\n",
      "Training for channel: CADC0894, segment: 1109\n",
      "End Train for channel: CADC0894, segment: 1109\n",
      "Training for channel: CADC0894, segment: 1110\n",
      "End Train for channel: CADC0894, segment: 1110\n",
      "Training for channel: CADC0894, segment: 1111\n",
      "End Train for channel: CADC0894, segment: 1111\n",
      "Training for channel: CADC0894, segment: 1113\n",
      "End Train for channel: CADC0894, segment: 1113\n",
      "Training for channel: CADC0894, segment: 1114\n",
      "End Train for channel: CADC0894, segment: 1114\n",
      "Training for channel: CADC0894, segment: 1115\n",
      "End Train for channel: CADC0894, segment: 1115\n",
      "Training for channel: CADC0894, segment: 1117\n",
      "End Train for channel: CADC0894, segment: 1117\n",
      "Training for channel: CADC0894, segment: 1118\n",
      "End Train for channel: CADC0894, segment: 1118\n",
      "Training for channel: CADC0894, segment: 1119\n",
      "End Train for channel: CADC0894, segment: 1119\n",
      "Training for channel: CADC0894, segment: 1121\n",
      "End Train for channel: CADC0894, segment: 1121\n",
      "Training for channel: CADC0894, segment: 1122\n",
      "End Train for channel: CADC0894, segment: 1122\n",
      "Training for channel: CADC0894, segment: 1124\n",
      "End Train for channel: CADC0894, segment: 1124\n",
      "Training for channel: CADC0894, segment: 1125\n",
      "End Train for channel: CADC0894, segment: 1125\n",
      "Training for channel: CADC0894, segment: 1127\n",
      "End Train for channel: CADC0894, segment: 1127\n",
      "Training for channel: CADC0894, segment: 1128\n",
      "End Train for channel: CADC0894, segment: 1128\n",
      "Training for channel: CADC0894, segment: 1129\n",
      "End Train for channel: CADC0894, segment: 1129\n",
      "Training for channel: CADC0894, segment: 1130\n",
      "End Train for channel: CADC0894, segment: 1130\n",
      "Training for channel: CADC0894, segment: 1131\n",
      "End Train for channel: CADC0894, segment: 1131\n",
      "Training for channel: CADC0894, segment: 1134\n",
      "End Train for channel: CADC0894, segment: 1134\n",
      "Training for channel: CADC0894, segment: 1135\n",
      "End Train for channel: CADC0894, segment: 1135\n",
      "Training for channel: CADC0894, segment: 1136\n",
      "End Train for channel: CADC0894, segment: 1136\n",
      "Training for channel: CADC0894, segment: 1137\n",
      "End Train for channel: CADC0894, segment: 1137\n",
      "Training for channel: CADC0894, segment: 1138\n",
      "End Train for channel: CADC0894, segment: 1138\n",
      "Training for channel: CADC0894, segment: 1139\n",
      "End Train for channel: CADC0894, segment: 1139\n",
      "Training for channel: CADC0894, segment: 1140\n",
      "End Train for channel: CADC0894, segment: 1140\n",
      "Training for channel: CADC0894, segment: 1141\n",
      "End Train for channel: CADC0894, segment: 1141\n",
      "Training for channel: CADC0894, segment: 1142\n",
      "End Train for channel: CADC0894, segment: 1142\n",
      "Training for channel: CADC0894, segment: 1143\n",
      "End Train for channel: CADC0894, segment: 1143\n",
      "Training for channel: CADC0894, segment: 1144\n",
      "End Train for channel: CADC0894, segment: 1144\n",
      "Training for channel: CADC0894, segment: 1145\n",
      "End Train for channel: CADC0894, segment: 1145\n",
      "Training for channel: CADC0894, segment: 1146\n",
      "End Train for channel: CADC0894, segment: 1146\n",
      "Training for channel: CADC0894, segment: 1147\n",
      "End Train for channel: CADC0894, segment: 1147\n",
      "Training for channel: CADC0894, segment: 1148\n",
      "End Train for channel: CADC0894, segment: 1148\n",
      "Training for channel: CADC0894, segment: 1149\n",
      "End Train for channel: CADC0894, segment: 1149\n",
      "Training for channel: CADC0894, segment: 1150\n",
      "End Train for channel: CADC0894, segment: 1150\n",
      "Training for channel: CADC0894, segment: 1151\n",
      "End Train for channel: CADC0894, segment: 1151\n",
      "Training for channel: CADC0894, segment: 1152\n",
      "End Train for channel: CADC0894, segment: 1152\n",
      "Training for channel: CADC0894, segment: 1153\n",
      "End Train for channel: CADC0894, segment: 1153\n",
      "Training for channel: CADC0894, segment: 1154\n",
      "End Train for channel: CADC0894, segment: 1154\n",
      "Training for channel: CADC0894, segment: 1155\n",
      "End Train for channel: CADC0894, segment: 1155\n",
      "Training for channel: CADC0894, segment: 1157\n",
      "End Train for channel: CADC0894, segment: 1157\n",
      "Training for channel: CADC0894, segment: 1159\n",
      "End Train for channel: CADC0894, segment: 1159\n",
      "Training for channel: CADC0894, segment: 1160\n",
      "End Train for channel: CADC0894, segment: 1160\n",
      "Training for channel: CADC0894, segment: 1161\n",
      "End Train for channel: CADC0894, segment: 1161\n",
      "Training for channel: CADC0894, segment: 1162\n",
      "End Train for channel: CADC0894, segment: 1162\n",
      "Training for channel: CADC0894, segment: 1163\n",
      "End Train for channel: CADC0894, segment: 1163\n",
      "Training for channel: CADC0894, segment: 1164\n",
      "End Train for channel: CADC0894, segment: 1164\n",
      "Training for channel: CADC0894, segment: 1165\n",
      "End Train for channel: CADC0894, segment: 1165\n",
      "Training for channel: CADC0894, segment: 1167\n",
      "End Train for channel: CADC0894, segment: 1167\n",
      "Training for channel: CADC0894, segment: 1169\n",
      "End Train for channel: CADC0894, segment: 1169\n",
      "Training for channel: CADC0894, segment: 1729\n",
      "End Train for channel: CADC0894, segment: 1729\n",
      "Training for channel: CADC0894, segment: 1730\n",
      "End Train for channel: CADC0894, segment: 1730\n",
      "Training for channel: CADC0894, segment: 1731\n",
      "End Train for channel: CADC0894, segment: 1731\n",
      "Training for channel: CADC0894, segment: 1733\n",
      "End Train for channel: CADC0894, segment: 1733\n",
      "Training for channel: CADC0894, segment: 1736\n",
      "End Train for channel: CADC0894, segment: 1736\n",
      "Training for channel: CADC0894, segment: 1737\n",
      "End Train for channel: CADC0894, segment: 1737\n",
      "Training for channel: CADC0894, segment: 1739\n",
      "End Train for channel: CADC0894, segment: 1739\n",
      "Training for channel: CADC0894, segment: 1740\n",
      "End Train for channel: CADC0894, segment: 1740\n",
      "Training for channel: CADC0894, segment: 1741\n",
      "End Train for channel: CADC0894, segment: 1741\n",
      "Training for channel: CADC0894, segment: 1742\n",
      "End Train for channel: CADC0894, segment: 1742\n",
      "Training for channel: CADC0894, segment: 1743\n",
      "End Train for channel: CADC0894, segment: 1743\n",
      "Training for channel: CADC0894, segment: 1745\n",
      "End Train for channel: CADC0894, segment: 1745\n",
      "Training for channel: CADC0894, segment: 1746\n",
      "End Train for channel: CADC0894, segment: 1746\n",
      "Training for channel: CADC0894, segment: 1747\n",
      "End Train for channel: CADC0894, segment: 1747\n",
      "Training for channel: CADC0894, segment: 1749\n",
      "End Train for channel: CADC0894, segment: 1749\n",
      "Training for channel: CADC0894, segment: 1750\n",
      "End Train for channel: CADC0894, segment: 1750\n",
      "Training for channel: CADC0894, segment: 1752\n",
      "End Train for channel: CADC0894, segment: 1752\n",
      "Training for channel: CADC0894, segment: 1753\n",
      "End Train for channel: CADC0894, segment: 1753\n",
      "Training for channel: CADC0894, segment: 1754\n",
      "End Train for channel: CADC0894, segment: 1754\n",
      "Training for channel: CADC0894, segment: 1755\n",
      "End Train for channel: CADC0894, segment: 1755\n",
      "Training for channel: CADC0894, segment: 1758\n",
      "End Train for channel: CADC0894, segment: 1758\n",
      "Training for channel: CADC0894, segment: 1760\n",
      "End Train for channel: CADC0894, segment: 1760\n",
      "Training for channel: CADC0894, segment: 1762\n",
      "End Train for channel: CADC0894, segment: 1762\n",
      "Training for channel: CADC0894, segment: 1765\n",
      "End Train for channel: CADC0894, segment: 1765\n",
      "Training for channel: CADC0894, segment: 1766\n",
      "End Train for channel: CADC0894, segment: 1766\n",
      "Training for channel: CADC0894, segment: 1767\n",
      "End Train for channel: CADC0894, segment: 1767\n",
      "Training for channel: CADC0894, segment: 1768\n",
      "End Train for channel: CADC0894, segment: 1768\n",
      "Training for channel: CADC0894, segment: 1769\n",
      "End Train for channel: CADC0894, segment: 1769\n",
      "Training for channel: CADC0894, segment: 1770\n",
      "End Train for channel: CADC0894, segment: 1770\n",
      "Training for channel: CADC0894, segment: 1772\n",
      "End Train for channel: CADC0894, segment: 1772\n",
      "Training for channel: CADC0894, segment: 1773\n",
      "End Train for channel: CADC0894, segment: 1773\n",
      "Training for channel: CADC0894, segment: 1774\n",
      "End Train for channel: CADC0894, segment: 1774\n",
      "Training for channel: CADC0894, segment: 1775\n",
      "End Train for channel: CADC0894, segment: 1775\n",
      "Training for channel: CADC0894, segment: 1776\n",
      "End Train for channel: CADC0894, segment: 1776\n",
      "Training for channel: CADC0894, segment: 1777\n",
      "End Train for channel: CADC0894, segment: 1777\n",
      "Training for channel: CADC0894, segment: 1778\n",
      "End Train for channel: CADC0894, segment: 1778\n",
      "Training for channel: CADC0894, segment: 1779\n",
      "End Train for channel: CADC0894, segment: 1779\n",
      "Training for channel: CADC0894, segment: 1780\n",
      "End Train for channel: CADC0894, segment: 1780\n",
      "Training for channel: CADC0894, segment: 1781\n",
      "End Train for channel: CADC0894, segment: 1781\n",
      "Training for channel: CADC0894, segment: 1783\n",
      "End Train for channel: CADC0894, segment: 1783\n",
      "Training for channel: CADC0894, segment: 1784\n",
      "End Train for channel: CADC0894, segment: 1784\n",
      "Training for channel: CADC0894, segment: 1785\n",
      "End Train for channel: CADC0894, segment: 1785\n",
      "Training for channel: CADC0894, segment: 1786\n",
      "End Train for channel: CADC0894, segment: 1786\n",
      "Training for channel: CADC0894, segment: 1787\n",
      "End Train for channel: CADC0894, segment: 1787\n",
      "Training for channel: CADC0894, segment: 1789\n",
      "End Train for channel: CADC0894, segment: 1789\n",
      "Training for channel: CADC0894, segment: 1790\n",
      "End Train for channel: CADC0894, segment: 1790\n",
      "Training for channel: CADC0894, segment: 1791\n",
      "End Train for channel: CADC0894, segment: 1791\n",
      "Training for channel: CADC0894, segment: 1792\n",
      "End Train for channel: CADC0894, segment: 1792\n",
      "Training for channel: CADC0894, segment: 1794\n",
      "End Train for channel: CADC0894, segment: 1794\n",
      "Training for channel: CADC0890, segment: 1714\n",
      "End Train for channel: CADC0890, segment: 1714\n",
      "Training for channel: CADC0890, segment: 1715\n",
      "End Train for channel: CADC0890, segment: 1715\n",
      "Training for channel: CADC0890, segment: 1717\n",
      "End Train for channel: CADC0890, segment: 1717\n",
      "Training for channel: CADC0890, segment: 1718\n",
      "End Train for channel: CADC0890, segment: 1718\n",
      "Training for channel: CADC0890, segment: 1719\n",
      "End Train for channel: CADC0890, segment: 1719\n",
      "Training for channel: CADC0890, segment: 1720\n",
      "End Train for channel: CADC0890, segment: 1720\n",
      "Training for channel: CADC0890, segment: 1721\n",
      "End Train for channel: CADC0890, segment: 1721\n",
      "Training for channel: CADC0890, segment: 1722\n",
      "End Train for channel: CADC0890, segment: 1722\n",
      "Training for channel: CADC0890, segment: 1723\n",
      "End Train for channel: CADC0890, segment: 1723\n",
      "Training for channel: CADC0890, segment: 1724\n",
      "End Train for channel: CADC0890, segment: 1724\n",
      "Training for channel: CADC0890, segment: 1726\n",
      "End Train for channel: CADC0890, segment: 1726\n",
      "Training for channel: CADC0890, segment: 1727\n",
      "End Train for channel: CADC0890, segment: 1727\n",
      "[[-2.14870e-05]\n",
      " [-2.05077e-05]\n",
      " [-2.10633e-05]\n",
      " ...\n",
      " [ 0.00000e+00]\n",
      " [ 0.00000e+00]\n",
      " [ 0.00000e+00]]\n",
      "(1, 20)\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples_fit, but n_neighbors = 5, n_samples_fit = 1, n_samples = 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m prova_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(prova)  \u001b[38;5;66;03m# Unisci tutti i dati accumulati in un singolo array\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(prova_combined)\n\u001b[1;32m---> 46\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mrockad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprova_combined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScores for channel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchannel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, segment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msegment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m, scores)\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\RockadFunction.py:265\u001b[0m, in \u001b[0;36mROCKAD.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28mprint\u001b[39m(Xtp_scaled\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28mprint\u001b[39m((Xtp_scaled\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m100000000\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m))\n\u001b[1;32m--> 265\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mbagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtp_scaled\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m    267\u001b[0m     y_scores[:, idx] \u001b[38;5;241m=\u001b[39m scores\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# Average the scores to get the final score for each time series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\RockadFunction.py:128\u001b[0m, in \u001b[0;36mNN.predict_proba\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 128\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m     scores \u001b[38;5;241m=\u001b[39m scores[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:834\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m         inequality_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors <= n_samples_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 834\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    835\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minequality_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    836\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_neighbors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_samples_fit = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples_fit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    837\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# include n_samples for common tests\u001b[39;00m\n\u001b[0;32m    838\u001b[0m     )\n\u001b[0;32m    840\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    841\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples_fit, but n_neighbors = 5, n_samples_fit = 1, n_samples = 1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from RockadFunction import ROCKAD, NearestNeighborOCC, NN\n",
    "\n",
    "features = [\n",
    "    \"channel\",\n",
    "    \"segment\",\n",
    "    \"value\",\n",
    "    \"anomaly\"\n",
    "]\n",
    "RANDOM_STATE = 42\n",
    "prova = []\n",
    "dfSegment = pd.read_csv(\"data/segments.csv\", index_col=\"timestamp\")\n",
    "\n",
    "# Itera su ogni canale unico\n",
    "for channel in dfSegment[\"channel\"].unique():\n",
    "    # Itera su ogni segmento unico per il canale corrente\n",
    "    for segment in dfSegment[dfSegment[\"channel\"] == channel][\"segment\"].unique():\n",
    "       \n",
    "        mask = (dfSegment[\"train\"] == 1) & (dfSegment[\"channel\"] == channel) & (dfSegment[\"segment\"] == segment)\n",
    "        \n",
    "        # Filtra i dati in base alla maschera\n",
    "        X_trainS, y_trainS = dfSegment.loc[mask, features], dfSegment.loc[mask, \"anomaly\"]\n",
    "        \n",
    "        if not X_trainS.empty:\n",
    "            print(f\"Training for channel: {channel}, segment: {segment}\")\n",
    "            \n",
    "            # Estrai i valori di input per il fit\n",
    "            X_train_values = X_trainS[[\"value\"]].reset_index(drop=True).values  # Estrai solo 'value'\n",
    "            \n",
    "            rockad = ROCKAD(n_estimators=10, n_kernels=10, random_state=RANDOM_STATE)\n",
    "            \n",
    "            # Fai il fit del modello per il canale e segmento correnti\n",
    "            rockad.fit(X_train_values)\n",
    "            print(f\"End Train for channel: {channel}, segment: {segment}\")\n",
    "\n",
    "            prova.append(X_train_values)\n",
    "\n",
    "            # Ulteriori operazioni come la predizione delle anomalie\n",
    "            # decision_func = NearestNeighborOCC().fit(scores)\n",
    "            # predictions = decision_func.predict(scores)\n",
    "            # print(\"Predictions: \", predictions)\n",
    "\n",
    "prova_combined = np.vstack(prova)  # Unisci tutti i dati accumulati in un singolo array\n",
    "print(prova_combined)\n",
    "scores = rockad.predict_proba(prova_combined)\n",
    "print(f\"Scores for channel: {channel}, segment: {segment}: \", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5264a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1594,)\n",
      "(1594, 18)\n",
      "(1273, 18)\n",
      "(1273, 18)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "X_normal_train = X_train[y_train == 0]\n",
    "print(X_normal_train.shape)\n",
    "print(X_normal_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2409f2d8",
   "metadata": {},
   "source": [
    "## Rilevamento di anomalie SUPERVISED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53ffb220",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "No matching definition for argument type(s) pyobject, Tuple(array(float64, 1d, C), array(int32, 1d, C), array(float64, 1d, C), array(int32, 1d, C), array(int32, 1d, C))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Applica i kernel alle serie temporali\u001b[39;00m\n\u001b[0;32m     13\u001b[0m features_train \u001b[38;5;241m=\u001b[39m apply_kernels(X_train2, kernels)\n\u001b[1;32m---> 14\u001b[0m features_test \u001b[38;5;241m=\u001b[39m \u001b[43mapply_kernels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Addestramento del modello supervisionato\u001b[39;00m\n\u001b[0;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBOD(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mSEED)\n",
      "File \u001b[1;32mc:\\Users\\franc\\OneDrive - University of Pisa\\Università\\Tesi\\OPS-SAT-AD\\Paper_OPS-SAT_Python\\.venv\\Lib\\site-packages\\numba\\core\\dispatcher.py:658\u001b[0m, in \u001b[0;36m_DispatcherBase._explain_matching_error\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    655\u001b[0m args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypeof_pyval(a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m    656\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo matching definition for argument type(s) \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    657\u001b[0m        \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, args)))\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[1;31mTypeError\u001b[0m: No matching definition for argument type(s) pyobject, Tuple(array(float64, 1d, C), array(int32, 1d, C), array(float64, 1d, C), array(int32, 1d, C), array(int32, 1d, C))"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyod.models.xgbod import XGBOD\n",
    "\n",
    "from rocket_functions import generate_kernels, apply_kernels\n",
    "\n",
    "# Genera kernel convoluzionali casuali\n",
    "input_length = X_train.shape[1]\n",
    "num_kernels = 1000 # Valore standard\n",
    "kernels = generate_kernels(input_length, num_kernels)\n",
    "\n",
    "# Applica i kernel alle serie temporali\n",
    "features_train = apply_kernels(X_train2, kernels)\n",
    "features_test = apply_kernels(X_test, kernels)\n",
    "\n",
    "# Addestramento del modello supervisionato\n",
    "model = XGBOD(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=SEED)\n",
    "model.fit(features_train, y_train)\n",
    "\n",
    "# Predizione delle anomalie nei dati di test\n",
    "y_pred = model.predict(features_test)\n",
    "y_proba = model.predict_proba(features_test)\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "print(\"Predizioni nel test set:\", y_pred)\n",
    "\n",
    "# Eseguiamo la valutazione delle metriche\n",
    "metrics = evaluate_metrics(y_test, y_pred, y_proba=y_proba)\n",
    "print(\"Metriche di valutazione:\\n\", metrics)\n",
    "\n",
    "# Scaled -> {'Accuracy': 0.6, 'Precision': 0.7, 'Recall': 0.583, 'F1': 0.636, 'MCC': 0.204, 'AUC_PR': 0.632, 'AUC_ROC': 0.542}\n",
    "# Non Scaled -> {'Accuracy': 0.7, 'Precision': 0.75, 'Recall': 0.75, 'F1': 0.75, 'MCC': 0.375, 'AUC_PR': 0.712, 'AUC_ROC': 0.656}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8036570a",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4756a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predizioni nel test set: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0\n",
      " 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0]\n",
      "Metriche di valutazione:\n",
      " {'Accuracy': 0.843, 'Precision': 0.742, 'Recall': 0.407, 'F1': 0.526, 'MCC': 0.47, 'AUC_PR': 0.612, 'AUC_ROC': 0.806, 'PREC_N_SCORES': 0.531}\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.knn import KNN\n",
    "\n",
    "from rocket_functions import generate_kernels, apply_kernels\n",
    "\n",
    "# Genera kernel convoluzionali casuali\n",
    "input_length = X_train.shape[1]\n",
    "num_kernels = 1000\n",
    "kernels = generate_kernels(input_length, num_kernels)\n",
    "\n",
    "# Applica i kernel alle serie temporali\n",
    "features_train = apply_kernels(X_train2, kernels)\n",
    "features_test = apply_kernels(X_test2, kernels)\n",
    "\n",
    "\n",
    "# Addestramento del modello supervisionato\n",
    "model = KNN()\n",
    "model.fit(features_train)\n",
    "\n",
    "# Predizione delle anomalie nei dati di test\n",
    "y_pred = model.predict(features_test)\n",
    "y_proba = model.decision_function(features_test)\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "print(\"Predizioni nel test set:\", y_pred)\n",
    "\n",
    "# Eseguiamo la valutazione delle metriche\n",
    "metrics = evaluate_metrics(y_test, y_pred, y_proba)\n",
    "print(\"Metriche di valutazione:\\n\", metrics)\n",
    "# {'Accuracy': 0.845, 'Precision': 0.763, 'Recall': 0.398, 'F1': 0.523, 'MCC': 0.475, 'AUC_PR': 0.619, 'AUC_ROC': 0.811, 'PREC_N_SCORES': 0.54}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0eed09",
   "metadata": {},
   "source": [
    "### Regressione Logistica -> Classificatore lineare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d2b43ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predizioni nel test set: [0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 1\n",
      " 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1\n",
      " 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0\n",
      " 0 0 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0\n",
      " 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0]\n",
      "Metriche di valutazione:\n",
      " {'Accuracy': 0.972, 'Precision': 0.945, 'Recall': 0.92, 'F1': 0.933, 'MCC': 0.915, 'AUC_PR': 0.975, 'AUC_ROC': 0.993, 'PREC_N_SCORES': 0.92}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from rocket_functions import generate_kernels, apply_kernels\n",
    "\n",
    "# Genera kernel convoluzionali casuali\n",
    "input_length = X_train.shape[1]\n",
    "num_kernels = 1000\n",
    "kernels = generate_kernels(input_length, num_kernels)\n",
    "\n",
    "# Applica i kernel alle serie temporali\n",
    "features_train = apply_kernels(X_train2, kernels)\n",
    "features_test = apply_kernels(X_test2, kernels)\n",
    "\n",
    "\n",
    "# Addestramento del modello supervisionato\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(features_train, y_train)\n",
    "\n",
    "# Predizione delle anomalie nei dati di test\n",
    "y_pred = model.predict(features_test)\n",
    "y_proba = model.decision_function(features_test)\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "print(\"Predizioni nel test set:\", y_pred)\n",
    "\n",
    "# Eseguiamo la valutazione delle metriche\n",
    "metrics = evaluate_metrics(y_test, y_pred, y_proba)\n",
    "print(\"Metriche di valutazione:\\n\", metrics)\n",
    "# {'Accuracy': 0.977, 'Precision': 0.972, 'Recall': 0.92, 'F1': 0.945, 'MCC': 0.932, 'AUC_PR': 0.962, 'AUC_ROC': 0.984, 'PREC_N_SCORES': 0.929}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a539711",
   "metadata": {},
   "source": [
    "### Prova con Dettagli dal GitHub del Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5ee46bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predizioni nel test set: [0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0\n",
      " 0 1 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Metriche di valutazione:\n",
      " {'Accuracy': 0.879, 'Precision': 0.98, 'Recall': 0.442, 'F1': 0.61, 'MCC': 0.611, 'AUC_PR': 0.932, 'AUC_ROC': 0.965, 'PREC_N_SCORES': 0.92}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from rocket_functions import generate_kernels, apply_kernels\n",
    "\n",
    "def detect_anomalies_with_threshold(scores, threshold):\n",
    "    return (scores > threshold).astype(int)\n",
    "\n",
    "\n",
    "# Genera kernel convoluzionali casuali\n",
    "input_length = X_train.shape[1]\n",
    "num_kernels = 1000\n",
    "kernels = generate_kernels(input_length, num_kernels)\n",
    "\n",
    "# Applica i kernel alle serie temporali\n",
    "features_train = apply_kernels(X_train2, kernels)\n",
    "features_test = apply_kernels(X_test2, kernels)\n",
    "\n",
    "\n",
    "# Addestramento del modello supervisionato\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(features_train, y_train)\n",
    "\n",
    "# Predizione delle anomalie nei dati di test\n",
    "anomaly_scores_test = model.predict(features_test)\n",
    "anomaly_scores_train = model.predict(features_train)\n",
    "\n",
    "# Rilevamento delle anomalie\n",
    "threshold = np.percentile(anomaly_scores_train , 95)\n",
    "anomaly_labels_train = detect_anomalies_with_threshold(anomaly_scores_train , threshold)\n",
    "anomaly_labels_test = detect_anomalies_with_threshold(anomaly_scores_test , threshold)\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "print(\"Predizioni nel test set:\", anomaly_labels_test)\n",
    "\n",
    "# Eseguiamo la valutazione delle metriche\n",
    "metrics = evaluate_metrics(y_test, anomaly_labels_test, y_proba=anomaly_scores_test)\n",
    "print(\"Metriche di valutazione:\\n\", metrics)\n",
    "#  {'Accuracy': 0.888, 'Precision': 0.966, 'Recall': 0.496, 'F1': 0.655, 'MCC': 0.644, 'AUC_PR': 0.922, 'AUC_ROC': 0.962, 'PREC_N_SCORES': 0.912}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4501c69b",
   "metadata": {},
   "source": [
    "## LogisticClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5c5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predizioni nel test set: [0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1\n",
      " 0 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1\n",
      " 0 1 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0\n",
      " 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0\n",
      " 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 1\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Metriche di valutazione:\n",
      " {'Accuracy': 0.968, 'Precision': 0.953, 'Recall': 0.894, 'F1': 0.922, 'MCC': 0.903, 'AUC_PR': 0.966, 'AUC_ROC': 0.99, 'PREC_N_SCORES': 0.912}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from scipy.special import softmax\n",
    "\n",
    "from rocket_functions import generate_kernels, apply_kernels\n",
    "\n",
    "# Genera kernel convoluzionali casuali\n",
    "input_length = X_train.shape[1]\n",
    "num_kernels = 1000\n",
    "kernels = generate_kernels(input_length, num_kernels)\n",
    "\n",
    "# Applica i kernel alle serie temporali\n",
    "features_train = apply_kernels(X_train2, kernels)\n",
    "features_test = apply_kernels(X_test2, kernels)\n",
    "\n",
    "\n",
    "# Addestramento del modello supervisionato\n",
    "model = RidgeClassifierCV(alphas = np.logspace(-3, 3, 10))\n",
    "model.fit(features_train, y_train)\n",
    "\n",
    "# Predizione delle anomalie nei dati di test\n",
    "y_pred = model.predict(features_test)\n",
    "\n",
    "# Per separare multiclasse o monoclasse\n",
    "if  len(np.unique(y_test)) > 2:\n",
    "    y_proba = softmax(model.decision_function(features_test), axis=1)\n",
    "else:\n",
    "    y_proba = softmax(model.decision_function(features_test), axis=0)\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "print(\"Predizioni nel test set:\", y_pred)\n",
    "\n",
    "# Eseguiamo la valutazione delle metriche\n",
    "metrics = evaluate_metrics(y_test, y_pred, y_proba)\n",
    "print(\"Metriche di valutazione:\\n\", metrics)\n",
    "# {'Accuracy': 0.977, 'Precision': 0.972, 'Recall': 0.92, 'F1': 0.945, 'MCC': 0.932, 'AUC_PR': 0.962, 'AUC_ROC': 0.984, 'PREC_N_SCORES': 0.929}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6522d8c",
   "metadata": {},
   "source": [
    "# Test Rocket su NASA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a60ddcf",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "12609375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentuale di anomalie rilevate: 5.442176870748299\n",
      "Predizioni nel test set: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Predizioni nel test set: [ 27.39075515   6.73818551  30.98061762  21.36254965 118.34842727\n",
      "  12.07022744   4.98496023  15.30422813  11.66501984  28.08199317\n",
      "  15.84377621  19.2439204   15.15385179  26.62659354  32.54609538\n",
      "  44.63017342  46.03431525 201.55029622  14.89469191  24.63798363\n",
      "  39.08084855  10.79138293  13.23960034  25.4978436    9.74804133\n",
      "  17.665933    38.41646069 110.33655827  17.14146976  18.12435952\n",
      "  15.23798035 134.38722751   9.80981152  10.14225774  13.24224582\n",
      "  44.64392651  23.93383161  31.14978035  26.30618643  58.97880914\n",
      " 256.54798443   5.00440866  17.56927001  10.38270909  23.51199476\n",
      "  29.23675036  18.2885722    7.25394565  29.35229715  47.75608828\n",
      "  32.53691265  23.13234831  12.90875764  16.27963897  15.51566091\n",
      "  34.8221541   43.27771038  20.41988484   9.43933266  21.78916297\n",
      "  11.08380393  15.00102139  47.09357615  24.73439982  18.6808173\n",
      "  15.54429839  12.89903513  15.34119823  58.99959658  21.24731258\n",
      "  52.47152103   5.04404884  25.37441872  17.31002875   7.80313828\n",
      "  27.12066133  21.59329188  54.2720251    5.99765956  40.37541571\n",
      "  71.70672513  34.60341887  29.60177417  23.51241972  29.13324889\n",
      "   5.1670687   41.32155465  20.93160649  19.7450106   18.73722616\n",
      "   4.19552265  33.76765016  13.05573392   6.01490899  75.18196284\n",
      "  19.54929879  30.13474744  12.33259961  12.96383691  11.01478879\n",
      "  35.85475611  15.67839818   9.84445533  25.47453667  61.4445626\n",
      "  15.92541468  12.85212405  22.73149215  24.50339561   5.71785793\n",
      "  22.93328884  32.81111956  52.06910195  67.74476534  12.06244534\n",
      "  23.62886823   8.21759986  18.10202591  13.01418666  12.74664066\n",
      "  12.51575089  16.22201373  28.56556514   6.07506586  28.86648755\n",
      "  26.83282384  19.73917451  20.68428281  24.71082228  19.22723837\n",
      "  29.35821834  31.29230033  17.0386849   35.10177352  18.80669952\n",
      " 100.37102376  13.13668731  14.62999349  45.06436473  18.33637233\n",
      "  15.95079793   7.90718247  67.80369265  11.83782526  26.35865129\n",
      "  12.68149733  10.76208867]\n"
     ]
    }
   ],
   "source": [
    "from pyod.models.knn import KNN\n",
    "import numpy as np\n",
    "\n",
    "from rocket_functions import generate_kernels, apply_kernels\n",
    "\n",
    "# Genera kernel convoluzionali casuali\n",
    "input_length = X_train.shape[1]\n",
    "num_kernels = 1000\n",
    "kernels = generate_kernels(input_length, num_kernels)\n",
    "\n",
    "# Applica i kernel alle serie temporali\n",
    "features_train = apply_kernels(X_trainNASA2, kernels)\n",
    "features_test = apply_kernels(X_testNASA2, kernels)\n",
    "\n",
    "# RImozioni valori infiniti\n",
    "features_train = np.nan_to_num(features_train, nan=0.0, posinf=np.finfo(np.float32).max, neginf=np.finfo(np.float32).min)\n",
    "features_test= np.nan_to_num(features_test, nan=0.0, posinf=np.finfo(np.float32).max, neginf=np.finfo(np.float32).min)\n",
    "\n",
    "# Addestramento del modello supervisionato\n",
    "model = KNN()\n",
    "model.fit(features_train)\n",
    "\n",
    "# Predizione delle anomalie nei dati di test\n",
    "y_pred = model.predict(features_test)\n",
    "y_proba = model.decision_function(features_test)\n",
    "\n",
    "threshold = np.percentile(y_proba, 95)  # Soglia al 95° percentile\n",
    "predicted_anomalies = y_proba > threshold\n",
    "print(\"Percentuale di anomalie rilevate:\", predicted_anomalies.mean() * 100)\n",
    "\n",
    "# Visualizzazione dei risultati\n",
    "print(\"Predizioni nel test set:\", y_pred)\n",
    "print(\"Predizioni nel test set:\", y_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a49c544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ci sono NaN: False\n",
      "Ci sono infiniti: True\n",
      "Massimo valore: 54.03164194612088\n",
      "Minimo valore: -inf\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Ci sono NaN:\", np.isnan(features_train).any())\n",
    "print(\"Ci sono infiniti:\", np.isinf(features_train).any())\n",
    "print(\"Massimo valore:\", np.max(features_train))\n",
    "print(\"Minimo valore:\", np.min(features_train))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
