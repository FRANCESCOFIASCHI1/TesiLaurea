\chapter{Valutazione Modelli}
In questo capitolo andremo ad analizzare gli algoritmi di nostro interesse, ossia XGBOD, ROCKET e ROCKAD.
Questi algoritmi lavorano con le timeseries, le quali sono una sequenza di dati registrati ad intervalli di tempo consecutivi. Ogni punto della serie è associato ad un timestamp il quale indica il momento in cui è stato registrato.

\section{XGBOD}
XGBOD (eXtreme Gradient Boosting for Outlier Detection) è una struttura composta in tre fasi:
\begin{enumerate}
    \item Generazione di nuove rappresentazioni di dati: vengono applicati vari metodi di rilevamento di anomalie non supervisionati ai dati originali per ottenere punteggi di anomalie, questi rappresentano la nuova vista dei dati;
    \item Seleziona i punteggi rilevanti: i punteggi ottenuti nella fase precedente vengono filtrati per usare sollo quelli utili, quest'ultimi sono combinati con le caratteristiche iniziali creando un nuovo spazio delle caratteristiche arricchito;
    \item Addestramento del modello XGBoost: viene addestrato il modello XGBoost su questo nuovo spazio delle caratteristiche e le previsioni determinano se ogni dato è un'anomalia o no.
\end{enumerate}
Utilizziamo XGBOD invece che XGBoost direttamente perché quest'ultimo, essendo un modello supervisionato, ha bisogno di dati etichettati e soprattutto con anomalie rare non facili da etichettare.

XGBOD aggiunge una parte di preprocessing aumenta le informazioni del set di dati con punteggi di anomalie ed utilizza metodi di rilevamento non supervisionato come Isolation Forest, Local Outlier Factor, ecc..

\subsection{XGBoost}
Il modello XGBoost di tipo supervisionato, si sviluppa con un processo iterativo di addestramento di alberi decisionali deboli (alberi decisionali poco profondi e quindi poco accurati), questi vengono combinati tra di loro portando un miglioramento progressivo delle prestazioni del modello.

XGBoost è composto da pochi passi ma ripetuti iterativamente: come primo passo vengono calcolati i residui, la differenza tra le previsioni iniziali ed i valori reali; questi sono i valori che vogliamo ridurre. Con questi valori il modello addestra un insieme di alberi decisionali deboli, dove ognuno cerca di correggere questi valori migliorando le previsioni del modello precedente. Tutti gli alberi vengono aggiunti al modello complessivo di XGBoost, che aggiorna le sue previsioni combinando tutti gli alberi precedentemente costruiti.

Per regolare tutto questo processo, sono applicate internamente tecniche di limitazione e regolazione per evitare un overfitting del modello. All'interno di XGBoost è presente anche una metrica chiamata \textit{tasso di apprendimento} che permette di decidere quanto un albero incide sul risultato finale, minimizzando così gli errori di percorso.

\subsection{Risultati ottenuti}
Qui sono elencati i risultati ottenuti effettuando varie prove con parametri diversi per ottimizzare XGBOD ed ottenere il miglior compromesso tra efficienza ed efficacia.
\pagebreak
\input{Tabelle/TabellaXGBOD}

LEGENDA:
\begin{itemize}
    \item M+P: significa più modelli e parametri
    \item Grid: gridsearch con modelli
    \item EarlyStop: ossia viene utilizzato un meccanismo di EarlyStop che ferma l'esecuzione dell'algoritmo quando gli iperparametri non migliorano più per una numero definito di cicli.
\end{itemize}

Dalla Tabella \ref{tab:XGBOD_table} possiamo vedere che il miglior risultato è quello che utilizza più modelli per l'addestramento ed i parametri modificati al fine di efficientare l'esecuzione. Oltre ad avere dei risultati ottimi l'esecuzione rimane praticamente istantanea sul nostro dataset di esempio OPS\textunderscore SAT.

\section{Rocket}
Rocket è un algoritmo convoluzionale, anche detti reti neurali convoluzionali (CNN), questi lavorano su dati con una struttura a griglia come immagini e serie temporali e sono progettati per riconoscere pattern all'interno dei dati tramite operazioni di convoluzione.
Vengono utilizzati i kernel\footnote{Matrice di pesi usata per eseguire operazioni di filtraggio per estrarre caratteristiche specifiche, opera tramite moltiplicazioni}, che operando sui dati in input estraggono caratteristiche locali dei dati (features), in questa fase possono essere applicate tecniche di centratura, ovvero aggiungere dei bordi attorno all'input così da mantenere le dimensioni dopo aver applicato il kernel, questo si chiama padding.

Ci sono tecniche applicabile a rocket come il pooling che ha lo scopo di ridurre la dimensione e quindi a rendere l'algoritmo meno sensibile alle traslazioni. In merito a questo vediamo le due tecniche più utilizzate:
\begin{itemize}
    \item Max Pooling: prende solo il valore massimo in una finestra specifica riducendo la dimensione dell'input
    \item Avarege Pooling: riduce la dimensione prendendo la media dei valori in una finestra
\end{itemize}

In conclusione abbiamo il passaggio per gli strati; i dati vengono appiattiti (flattering) fatti passare attraverso uno o più strati completamente connessi per la classificazione o la regressione, in modo da ottenere il risultato desiderato.

Rocket in particolare utilizza i kernel convoluzionali casuali, generandone un gran numero con parametri scelti casualmente, come lunghezza del kernel e pesi.
Questi kernel filtrano i dati delle serie temporali producendo una serie di features. Utilizzando tecniche di pooling viste in precedenza otteniamo statistiche riassuntive da queste features.
Questa procedura viene ripetuta per tutti i kernel, portando ad un enorme quantità di caratteristiche e quindi una maggiore possibilità di estrarre tutti i pattern comuni.

Le caratteristiche estratte vengono poi date in input ad algoritmi di classificazione, tipicamente una regressione logistica data la sua scalabilità e velocità su grandi dataset.
L'algoritmo viene addestrato su queste caratteristiche per effettuare la classificazione delle serie temporali.

\subsection{Aspetti Tecnici}
Per implementare Rocket abbiamo usato le funzioni che il relativo paper$^\text{{\cite{paper_rocket}}}$ ci aveva fornito:
\begin{lstlisting}[language=Python]
def generate_kernels(input_length, num_kernels)
def apply_kernel(X,weights, length, bias, dilation, padding)
def apply_kernels(X, kernels)
\end{lstlisting}
I parametri più importanti sono:
\begin{itemize}
    \item Numero di kernel (num\textunderscore kernels): rappresenta il numero di kernel casuali da generare, il valore predefinito è 10000, un numero maggiore di kernel tende a migliorare l'accuratezza della classificazione ma di conseguenza aumenta la complessità e quindi il tempo di calcolo;
    \item Lunghezza del kernel (input\textunderscore length): rappresenta la lunghezza del singolo kernel, questa è casuale e determina quanto della serie temporale viene considerato durante la convoluzione;
    \item Dilatazione: è un parametro che controlla la distanza tra i punti analizzati nel kernel, rocket usa varie dilatazioni per catturare caratteristiche a diverse scale temporali;
    \item Padding: determina come vengono gestiti i bordi delle serie temporali durante la fase di convoluzione.
\end{itemize} 

I vantaggi di ROCKET sono:
\begin{itemize}
    \item Efficienza computazionale elevata: è progettato per essere estremamente veloce e scalabile in modo che possa gestire grandi dataset in tempi ristretti;
    \item Robustezza: dato che si basa su kernel casuali, consente di generalizzare bene su nuovi problemi senza la necessità di perfezionare gli iperparametri;
    Semplicità: rocket permette di usare un solo iperparametro, ossia il numero di kernel, riducendo così la complessità associata al perfezionamento rispetto ad altri metodi di classificazione delle serie temporali.
\end{itemize}

\subsection{Test Effettuati}
Come primo aspetto abbiamo eseguito in locale gli esperimenti del paper di ROCKET per avere una validazione empirica dell'algoritmo ottenendo gli stessi risultati della tabella del paper$^{\text{\cite{paper_rocket}}}$, successivamente abbiamo provato la nostra implementazione sui medesimi dataset ottenendo i risultati della Tabella \ref{tab:Rocket_paper}.
\input{Tabelle/TabellaRocketPaper}
\pagebreak
Nei risultati che osserveremo successivamente nella Tabella \ref{tab:RocketOPS_SAT}, sono state effettuate molte prove con varie modalità, una unsepervised quindi usando ROCKET per estrarre una grande quantità di caratteristiche e tramite una threshold fare la classificazione senza aver effettuato un training con le etichette dei risultati.
Una threshold è una soglia, che indica il valore di riferimento per decidere quando una predizione deve essere classificata come positiva  o negativa, in questo caso quando un valore deve essere considerato o no anomalo.
La seconda modalità che abbiamo osservato è supervised effettuando quindi il training sulle features trovate da rocket passando però le etichette delle classificazioni.
Per questo abbiamo utilizzato vari algoritmi supervised per analizzare le varie performance e trovare il migliore.
Abbiamo anche osservato una modalità ibrida, ossia al posto dell'utilizzo di una threshold o un algoritmo supervised abbiamo puntato su uno unsupervised (KNN) facendo il trining sulle feaures e restituendo delle prediction e delle classificazioni.

\texttt{RidgeClassifierCV}: è il modello usato nella demo del paper di rocket ed abbiamo riscontrato metriche migliori anche nei nostri test.
\input{Tabelle/RocketOPS-SAT}

\pagebreak

\subsection{Implementazione}

Riportiamo qui il codice dell'implementazione degli algoritmi più importanti:
il primo rappresenta rocket con la threshold come decision function:
\lstinputlisting{listings/Capitolo4/RocketThreshold.py}
La seconda implementazione è quella relativa a rocket con RidgeClassifierCV:
\lstinputlisting{listings/Capitolo4/RocketRidgeClassifierCV.py}

% ===============================================================================
% ================================= ROCKAD ======================================
% ===============================================================================

\section{ROCKAD}
ROCKAD (Random Convolutional Kernel Transform Anomaly Detector) è un algoritmo basato su ROCKET per la classificazione di anomalie su serie temporali.
\subsection{Funzionamento}
La logica dietro a questo algoritmo è l'utilizzo di ROCKET come estrattore di caratteristiche non supervisionato e addestrare un singolo KNN o un insieme combinato di più KNN (detto ensemble di KNN).

In modo più dettagliato ROCKAD è diviso in tre passaggi fondamentali:
\begin{enumerate}
    \item Estrazione di caratteristiche: tramite ROCKET, spiegato precedentemente, ricaviamo le caratteristiche delle timeseries
    \item Trasformazione: le caratteristiche estratte vengono poi trasformate utilizzando un power trasformer
    \item Rilevamento anomalie: per concludere viene addestrato un insieme di KNN sulle caratteristiche estratte per estrarre dei punteggi di anomalia (score) per le serie temporali che serviranno successivamente per calcolare le predizioni.
\end{enumerate}

I parametri principali sono tre: il numero di kernel convoluzionali (il valore predefinito è 10000), il numero di estimatori di tipo KNN (valore predefinito 10) e il numero di vicini che vengono utilizzati per calcolare il punteggio di anomalia (valore predefinito 5).

Oltre alla classe ROCKAD è necessario importare anche la classe NearestNeighborOCC, che implementa un classificatore di anomalie basato su il nodo prossimo più vicino.
Questo è un metodo aggiuntivo per il rilevamento delle anomalie, il quale ha un funzionamento diverso da KNN dato che, invece di utilizzare la distanza media dai $k$ vicini più prossimi, NearestNeighborOCC calcola un punteggio di anomalia basato sul rapporto tra due distanze: la distanza tra la timeseries analizzata e il suo vicino prossimo e la distanza tra il vicino più prossimo e il suo vicino più prossimo.
Se il risultato di questo rapporto fosse inferiore o uguale ad $1$, la timeseries viene classificata come normale, altrimenti viene classificata come anomala.

In conclusione NearestNeighborOCC aggiunge un ulteriore passaggio di analisi per la classificazione il quale permette ti aumentare la robustezza e accuratezza nel rilevamento delle anomalie.
\subsection{Validazione}
Nel paper relativo a ROCKAD$^{\text{\cite{rockad_paper}}}$ sono paragonati i risultati ottenuti con il suo uso e il confronto con gli altri algoritmi. Nel nostro caso, come per  ROCKET, validiamo l'algoritmo con i dati presenti nella Tabella \ref{tab:rockad_paper_table}, per poi concentrarci sulla sua applicazione sui nostri dataset di riferimento

\input{Tabelle/TabellaRockadPaper}

\subsection{Test Effettuati}
Come prima cosa per poter ottenere i risultati sul datsaet OPS\textunderscore SAT bisogna manipolare i dati per renderli compatibili con ROCKAD.
I dati accettati dai metodi \texttt{fit} e \texttt{predict\textunderscore proba} sono di tipo \texttt{numpy.array}.

Siamo partiti da estrarre i dati grezzi provenienti da OPS-SAT nel file \texttt{segments.csv}, eseguendo un preprocessing per strutturarli in modo tale che abbiano una forma del tipo  \texttt{(numero esempi, numero di features, lunghezza sequenza)}. Nel nostro caso abbiamo fissato la lunghezza della sequenza a $250$ e il numero di features ad 1 per avere la compatibilità con ROCKAD, quindi eseguendo la funzione \texttt{.shape} dovrebbe risultare $(347, 1, 250)$.

I dati processati vengono poi passati a \texttt{ROCKAD}, suddivisi in due parti: una per il fitting del modello e l'altra per calcolare gli \texttt{score-train} e gli \texttt{score-test}. Questi punteggi vengono successivamente utilizzati rispettivamente per il training e la predizione dell'algoritmo \texttt{NearestNeighborOCC}, al fine di calcolare le predizioni e confrontarle con i \textit{ground\textunderscore truth}.

% Mettere l'errore e la risoluzione del problema???

Il codice del preprocessing è diviso in due: la parte riguardande i dati di training
\lstinputlisting{listings/Capitolo4/PreprocessingTrain.py}
e la parte corrispondente ai dati di test
\lstinputlisting{listings/Capitolo4/PreprocessingTest.py}
